{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "2017-7-9-Training_Monitoring.ipynb의 사본",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tykimos/Keras/blob/master/2017_7_9_Training_Monitoring_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex9164TrbkMr",
        "colab_type": "raw"
      },
      "source": [
        "---\n",
        "layout: post\n",
        "title:  \"학습과정 살펴보기\"\n",
        "author: 김태영\n",
        "date:   2017-07-09 23:00:00\n",
        "categories: Lecture\n",
        "comments: true\n",
        "image: http://tykimos.github.io/warehouse/2017-7-9-Training_Monitoring_1.png\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqqWqG8sbkM4",
        "colab_type": "text"
      },
      "source": [
        "케라스로 딥러닝 모델 개발할 때, 가장 많이 보게 되는 것이 fit 함수가 화면에 찍어주는 로그입니다. 이 로그에 포함된 수치들은 학습이 제대로 되고 있는 지, 학습을 그만할 지 등 판단하는 중요한 척도가 됩니다. 수치 자체도 큰 의미가 있지만 수치들이 에포코마다 바뀌는 변화 추이를 보는 것이 중요하기 때문에 그래프로 표시하여 보는 것이 더 직관적입니다. 이러한 수치를 그래프로 보기 위해 케라스에서 제공하는 기능을 이용하는 방법, 텐서보드와 연동하여 보는 방법, 콜백함수를 직접 만들어서 사용하는 방법에 대해서 알아보겠습니다.\n",
        "\n",
        "* 히스토리 기능 사용하기\n",
        "* 텐서보드와 연동하기\n",
        "* 직접 콜백함수 만들어보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJjweIcgbkM5",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### 히스토리 기능 사용하기\n",
        "\n",
        "케라스에서 학습시킬 때 fit() 함수를 사용합니다. 이 함수의 반환 값으로 히스토리 객체를 얻을 수 있는데, 이 객체는 다음의 정보를 담고 있습니다. \n",
        "\n",
        "* 매 에포크 마다의 훈련 손실값 (loss) \n",
        "* 매 에포크 마다의 훈련 정확도 (acc)\n",
        "* 매 에포크 마다의 검증 손실값 (val_loss)\n",
        "* 매 에포크 마다의 검증 정확도 (val_acc)\n",
        "\n",
        "히스토리 기능은 케라스의 모든 모델에 탑재되어 있으므로 별도의 설정없이 fit() 함수의 반환으로 쉽게 얻을 수 있습니다. 사용법은 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYgSMGJVbkM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
        "\n",
        "print(hist.history['loss'])\n",
        "print(hist.history['acc'])\n",
        "print(hist.history['val_loss'])\n",
        "print(hist.history['val_acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzcbiyvObkNC",
        "colab_type": "text"
      },
      "source": [
        "수치들은 각 에포크마다 해당 값이 추가되므로 배열 형태로 저장되어 있습니다. 이러한 수치들을 매 에포크마다 변화되는 추이를 그래프로 표시하여 비교하면서 보면 학습 상태를 직관적으로 이해하기 쉽습니다. 아래 코드와 같이 matplotlib 패키지를 이용하면 하나의 그래프로 쉽게 표시할 수 있습니다.  \n",
        "\n",
        "- train_loss(노란색) : 훈련 손실값이며 x축은 에포크 수, 좌측 y축은 손실값을 나타냅니다.\n",
        "- val_loss(빨간색) : 검증 손실값이며 x축은 에포크 수, 좌측 y축은 손실값을 나타냅니다.\n",
        "- train_acc(파란색) : 훈련 정확도이며 x축은 에포크 수, 우측 y축은 정확도를 나타냅니다.\n",
        "- val_acc(녹색) : 검증 정확도이며 x축은 에포크 수, 우측 y축은 정확도를 나타냅니다.\n",
        "\n",
        "좌측 세로축은 손실값을 표시하고, 우측 세로축은 정확도를 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPPt-hQtbkND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqnlPJjTbkNJ",
        "colab_type": "text"
      },
      "source": [
        "손글씨 데이터셋인 MNIST를 다층 퍼셉트론 모델로 학습시키는 간단한 예제로 테스트 해보겠습니다. 전체 코드는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngczqCuybkNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07c1cbf6-3856-4549-baa0-cc69b0a23d94"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "# 1. 데이터셋 생성하기\n",
        "\n",
        "# 훈련셋과 시험셋 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 훈련셋과 검증셋 분리\n",
        "x_val = x_train[50000:]\n",
        "y_val = y_train[50000:]\n",
        "x_train = x_train[:50000]\n",
        "y_train = y_train[:50000]\n",
        "\n",
        "# 데이터셋 전처리\n",
        "x_train = x_train.reshape(50000, 784).astype('float32') / 255.0\n",
        "x_val = x_val.reshape(10000, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "\n",
        "# 훈련셋과 검증셋 고르기\n",
        "train_rand_idxs = np.random.choice(50000, 700)\n",
        "val_rand_idxs = np.random.choice(10000, 300)\n",
        "x_train = x_train[train_rand_idxs]\n",
        "y_train = y_train[train_rand_idxs]\n",
        "x_val = x_val[val_rand_idxs]\n",
        "y_val = y_val[val_rand_idxs]\n",
        "\n",
        "# 라벨데이터 원핫인코딩 (one-hot encoding) 처리\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_val = np_utils.to_categorical(y_val)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "hist = model.fit(x_train, y_train, epochs=1000, batch_size=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 2.2932 - accuracy: 0.1243 - val_loss: 2.2788 - val_accuracy: 0.1333\n",
            "Epoch 2/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2508 - accuracy: 0.1500 - val_loss: 2.2478 - val_accuracy: 0.1200\n",
            "Epoch 3/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1997 - accuracy: 0.1343 - val_loss: 2.1974 - val_accuracy: 0.1433\n",
            "Epoch 4/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1352 - accuracy: 0.1714 - val_loss: 2.1427 - val_accuracy: 0.1900\n",
            "Epoch 5/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0759 - accuracy: 0.2100 - val_loss: 2.0988 - val_accuracy: 0.2033\n",
            "Epoch 6/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0228 - accuracy: 0.2100 - val_loss: 2.0605 - val_accuracy: 0.2000\n",
            "Epoch 7/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9763 - accuracy: 0.2257 - val_loss: 2.0250 - val_accuracy: 0.2367\n",
            "Epoch 8/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9341 - accuracy: 0.2957 - val_loss: 1.9896 - val_accuracy: 0.2700\n",
            "Epoch 9/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8936 - accuracy: 0.3229 - val_loss: 1.9591 - val_accuracy: 0.2900\n",
            "Epoch 10/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8564 - accuracy: 0.3357 - val_loss: 1.9317 - val_accuracy: 0.3000\n",
            "Epoch 11/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8224 - accuracy: 0.3400 - val_loss: 1.9053 - val_accuracy: 0.3033\n",
            "Epoch 12/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7915 - accuracy: 0.3443 - val_loss: 1.8822 - val_accuracy: 0.3000\n",
            "Epoch 13/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7613 - accuracy: 0.3486 - val_loss: 1.8582 - val_accuracy: 0.3100\n",
            "Epoch 14/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7330 - accuracy: 0.3586 - val_loss: 1.8379 - val_accuracy: 0.3267\n",
            "Epoch 15/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7082 - accuracy: 0.3643 - val_loss: 1.8186 - val_accuracy: 0.3367\n",
            "Epoch 16/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.6832 - accuracy: 0.3729 - val_loss: 1.8060 - val_accuracy: 0.3300\n",
            "Epoch 17/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.6604 - accuracy: 0.3771 - val_loss: 1.7829 - val_accuracy: 0.3667\n",
            "Epoch 18/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.6400 - accuracy: 0.4186 - val_loss: 1.7690 - val_accuracy: 0.3567\n",
            "Epoch 19/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.6183 - accuracy: 0.4214 - val_loss: 1.7475 - val_accuracy: 0.3400\n",
            "Epoch 20/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5989 - accuracy: 0.4357 - val_loss: 1.7365 - val_accuracy: 0.3767\n",
            "Epoch 21/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5817 - accuracy: 0.4357 - val_loss: 1.7204 - val_accuracy: 0.3933\n",
            "Epoch 22/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5644 - accuracy: 0.4371 - val_loss: 1.7060 - val_accuracy: 0.4100\n",
            "Epoch 23/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5482 - accuracy: 0.4486 - val_loss: 1.6938 - val_accuracy: 0.4233\n",
            "Epoch 24/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5333 - accuracy: 0.4614 - val_loss: 1.6803 - val_accuracy: 0.4167\n",
            "Epoch 25/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5179 - accuracy: 0.4657 - val_loss: 1.6704 - val_accuracy: 0.4133\n",
            "Epoch 26/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5029 - accuracy: 0.4729 - val_loss: 1.6644 - val_accuracy: 0.4200\n",
            "Epoch 27/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4906 - accuracy: 0.4600 - val_loss: 1.6497 - val_accuracy: 0.4300\n",
            "Epoch 28/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4769 - accuracy: 0.4771 - val_loss: 1.6412 - val_accuracy: 0.4300\n",
            "Epoch 29/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4644 - accuracy: 0.4714 - val_loss: 1.6339 - val_accuracy: 0.4133\n",
            "Epoch 30/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4529 - accuracy: 0.4886 - val_loss: 1.6182 - val_accuracy: 0.4167\n",
            "Epoch 31/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4422 - accuracy: 0.4900 - val_loss: 1.6220 - val_accuracy: 0.4200\n",
            "Epoch 32/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4307 - accuracy: 0.4914 - val_loss: 1.5985 - val_accuracy: 0.4233\n",
            "Epoch 33/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4191 - accuracy: 0.4929 - val_loss: 1.5910 - val_accuracy: 0.4300\n",
            "Epoch 34/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4114 - accuracy: 0.5171 - val_loss: 1.5930 - val_accuracy: 0.4333\n",
            "Epoch 35/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4001 - accuracy: 0.5071 - val_loss: 1.5872 - val_accuracy: 0.4200\n",
            "Epoch 36/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3903 - accuracy: 0.5086 - val_loss: 1.5692 - val_accuracy: 0.4233\n",
            "Epoch 37/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3825 - accuracy: 0.5100 - val_loss: 1.5686 - val_accuracy: 0.4367\n",
            "Epoch 38/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3729 - accuracy: 0.5114 - val_loss: 1.5635 - val_accuracy: 0.4333\n",
            "Epoch 39/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3649 - accuracy: 0.5157 - val_loss: 1.5653 - val_accuracy: 0.4100\n",
            "Epoch 40/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3571 - accuracy: 0.5129 - val_loss: 1.5544 - val_accuracy: 0.4233\n",
            "Epoch 41/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3486 - accuracy: 0.5186 - val_loss: 1.5447 - val_accuracy: 0.4267\n",
            "Epoch 42/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3412 - accuracy: 0.5157 - val_loss: 1.5368 - val_accuracy: 0.4233\n",
            "Epoch 43/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3324 - accuracy: 0.5114 - val_loss: 1.5451 - val_accuracy: 0.4067\n",
            "Epoch 44/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3275 - accuracy: 0.5229 - val_loss: 1.5314 - val_accuracy: 0.4367\n",
            "Epoch 45/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3191 - accuracy: 0.5243 - val_loss: 1.5282 - val_accuracy: 0.4400\n",
            "Epoch 46/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3116 - accuracy: 0.5243 - val_loss: 1.5218 - val_accuracy: 0.4200\n",
            "Epoch 47/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3053 - accuracy: 0.5229 - val_loss: 1.5092 - val_accuracy: 0.4533\n",
            "Epoch 48/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2991 - accuracy: 0.5400 - val_loss: 1.5097 - val_accuracy: 0.4567\n",
            "Epoch 49/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2927 - accuracy: 0.5343 - val_loss: 1.5147 - val_accuracy: 0.4433\n",
            "Epoch 50/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2853 - accuracy: 0.5271 - val_loss: 1.4947 - val_accuracy: 0.4567\n",
            "Epoch 51/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 1.2800 - accuracy: 0.5429 - val_loss: 1.4979 - val_accuracy: 0.4533\n",
            "Epoch 52/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2747 - accuracy: 0.5300 - val_loss: 1.4916 - val_accuracy: 0.4533\n",
            "Epoch 53/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2690 - accuracy: 0.5400 - val_loss: 1.4869 - val_accuracy: 0.4467\n",
            "Epoch 54/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2631 - accuracy: 0.5357 - val_loss: 1.4867 - val_accuracy: 0.4567\n",
            "Epoch 55/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2568 - accuracy: 0.5357 - val_loss: 1.4848 - val_accuracy: 0.4433\n",
            "Epoch 56/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2503 - accuracy: 0.5529 - val_loss: 1.4807 - val_accuracy: 0.4500\n",
            "Epoch 57/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2455 - accuracy: 0.5443 - val_loss: 1.4787 - val_accuracy: 0.4567\n",
            "Epoch 58/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2410 - accuracy: 0.5457 - val_loss: 1.4731 - val_accuracy: 0.4433\n",
            "Epoch 59/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.5557 - val_loss: 1.4764 - val_accuracy: 0.4333\n",
            "Epoch 60/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2308 - accuracy: 0.5429 - val_loss: 1.4644 - val_accuracy: 0.4533\n",
            "Epoch 61/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2239 - accuracy: 0.5529 - val_loss: 1.4699 - val_accuracy: 0.4567\n",
            "Epoch 62/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2195 - accuracy: 0.5557 - val_loss: 1.4743 - val_accuracy: 0.4567\n",
            "Epoch 63/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2155 - accuracy: 0.5457 - val_loss: 1.4632 - val_accuracy: 0.4600\n",
            "Epoch 64/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2126 - accuracy: 0.5657 - val_loss: 1.4558 - val_accuracy: 0.4700\n",
            "Epoch 65/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2064 - accuracy: 0.5471 - val_loss: 1.4573 - val_accuracy: 0.4633\n",
            "Epoch 66/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2012 - accuracy: 0.5571 - val_loss: 1.4509 - val_accuracy: 0.4500\n",
            "Epoch 67/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1974 - accuracy: 0.5686 - val_loss: 1.4596 - val_accuracy: 0.4633\n",
            "Epoch 68/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1929 - accuracy: 0.5643 - val_loss: 1.4523 - val_accuracy: 0.4433\n",
            "Epoch 69/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1894 - accuracy: 0.5614 - val_loss: 1.4550 - val_accuracy: 0.4633\n",
            "Epoch 70/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1844 - accuracy: 0.5629 - val_loss: 1.4409 - val_accuracy: 0.4567\n",
            "Epoch 71/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1809 - accuracy: 0.5657 - val_loss: 1.4438 - val_accuracy: 0.4667\n",
            "Epoch 72/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1788 - accuracy: 0.5857 - val_loss: 1.4543 - val_accuracy: 0.4467\n",
            "Epoch 73/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1730 - accuracy: 0.5771 - val_loss: 1.4578 - val_accuracy: 0.4633\n",
            "Epoch 74/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 1.1675 - accuracy: 0.5814 - val_loss: 1.4469 - val_accuracy: 0.4700\n",
            "Epoch 75/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1645 - accuracy: 0.5814 - val_loss: 1.4392 - val_accuracy: 0.4567\n",
            "Epoch 76/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1633 - accuracy: 0.5700 - val_loss: 1.4452 - val_accuracy: 0.4667\n",
            "Epoch 77/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1573 - accuracy: 0.5786 - val_loss: 1.4372 - val_accuracy: 0.4733\n",
            "Epoch 78/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1542 - accuracy: 0.5729 - val_loss: 1.4478 - val_accuracy: 0.4700\n",
            "Epoch 79/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1489 - accuracy: 0.5886 - val_loss: 1.4526 - val_accuracy: 0.4333\n",
            "Epoch 80/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1494 - accuracy: 0.5800 - val_loss: 1.4499 - val_accuracy: 0.4667\n",
            "Epoch 81/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1460 - accuracy: 0.5729 - val_loss: 1.4451 - val_accuracy: 0.4633\n",
            "Epoch 82/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1413 - accuracy: 0.5929 - val_loss: 1.4478 - val_accuracy: 0.4533\n",
            "Epoch 83/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1379 - accuracy: 0.5743 - val_loss: 1.4507 - val_accuracy: 0.4633\n",
            "Epoch 84/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1370 - accuracy: 0.5971 - val_loss: 1.4358 - val_accuracy: 0.4633\n",
            "Epoch 85/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1302 - accuracy: 0.5914 - val_loss: 1.4347 - val_accuracy: 0.4467\n",
            "Epoch 86/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1275 - accuracy: 0.5900 - val_loss: 1.4468 - val_accuracy: 0.4600\n",
            "Epoch 87/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1246 - accuracy: 0.5814 - val_loss: 1.4394 - val_accuracy: 0.4600\n",
            "Epoch 88/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1214 - accuracy: 0.5871 - val_loss: 1.4429 - val_accuracy: 0.4733\n",
            "Epoch 89/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1182 - accuracy: 0.5986 - val_loss: 1.4326 - val_accuracy: 0.4700\n",
            "Epoch 90/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1137 - accuracy: 0.6014 - val_loss: 1.4350 - val_accuracy: 0.4567\n",
            "Epoch 91/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 1.1124 - accuracy: 0.5943 - val_loss: 1.4345 - val_accuracy: 0.4567\n",
            "Epoch 92/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1107 - accuracy: 0.6057 - val_loss: 1.4367 - val_accuracy: 0.4533\n",
            "Epoch 93/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1076 - accuracy: 0.5957 - val_loss: 1.4378 - val_accuracy: 0.4700\n",
            "Epoch 94/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1028 - accuracy: 0.6057 - val_loss: 1.4396 - val_accuracy: 0.4633\n",
            "Epoch 95/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0985 - accuracy: 0.5986 - val_loss: 1.4391 - val_accuracy: 0.4433\n",
            "Epoch 96/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0963 - accuracy: 0.6057 - val_loss: 1.4320 - val_accuracy: 0.4633\n",
            "Epoch 97/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0956 - accuracy: 0.6043 - val_loss: 1.4393 - val_accuracy: 0.4600\n",
            "Epoch 98/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0924 - accuracy: 0.6043 - val_loss: 1.4349 - val_accuracy: 0.4433\n",
            "Epoch 99/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0908 - accuracy: 0.5943 - val_loss: 1.4354 - val_accuracy: 0.4567\n",
            "Epoch 100/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0880 - accuracy: 0.6086 - val_loss: 1.4462 - val_accuracy: 0.4467\n",
            "Epoch 101/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0848 - accuracy: 0.6129 - val_loss: 1.4346 - val_accuracy: 0.4467\n",
            "Epoch 102/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0805 - accuracy: 0.6114 - val_loss: 1.4477 - val_accuracy: 0.4667\n",
            "Epoch 103/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0772 - accuracy: 0.6171 - val_loss: 1.4335 - val_accuracy: 0.4333\n",
            "Epoch 104/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0764 - accuracy: 0.6143 - val_loss: 1.4496 - val_accuracy: 0.4433\n",
            "Epoch 105/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 1.0759 - accuracy: 0.6043 - val_loss: 1.4458 - val_accuracy: 0.4433\n",
            "Epoch 106/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0696 - accuracy: 0.6071 - val_loss: 1.4348 - val_accuracy: 0.4633\n",
            "Epoch 107/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0669 - accuracy: 0.6057 - val_loss: 1.4448 - val_accuracy: 0.4500\n",
            "Epoch 108/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0670 - accuracy: 0.6114 - val_loss: 1.4401 - val_accuracy: 0.4433\n",
            "Epoch 109/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0659 - accuracy: 0.6129 - val_loss: 1.4350 - val_accuracy: 0.4533\n",
            "Epoch 110/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0631 - accuracy: 0.6100 - val_loss: 1.4387 - val_accuracy: 0.4633\n",
            "Epoch 111/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0584 - accuracy: 0.6171 - val_loss: 1.4529 - val_accuracy: 0.4500\n",
            "Epoch 112/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0568 - accuracy: 0.6100 - val_loss: 1.4415 - val_accuracy: 0.4400\n",
            "Epoch 113/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0543 - accuracy: 0.6157 - val_loss: 1.4525 - val_accuracy: 0.4433\n",
            "Epoch 114/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0490 - accuracy: 0.6229 - val_loss: 1.4367 - val_accuracy: 0.4333\n",
            "Epoch 115/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0517 - accuracy: 0.6214 - val_loss: 1.4393 - val_accuracy: 0.4567\n",
            "Epoch 116/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0493 - accuracy: 0.6186 - val_loss: 1.4412 - val_accuracy: 0.4667\n",
            "Epoch 117/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0469 - accuracy: 0.6129 - val_loss: 1.4404 - val_accuracy: 0.4500\n",
            "Epoch 118/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0434 - accuracy: 0.6129 - val_loss: 1.4394 - val_accuracy: 0.4633\n",
            "Epoch 119/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0381 - accuracy: 0.6271 - val_loss: 1.4324 - val_accuracy: 0.4567\n",
            "Epoch 120/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0392 - accuracy: 0.6186 - val_loss: 1.4423 - val_accuracy: 0.4533\n",
            "Epoch 121/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0369 - accuracy: 0.6129 - val_loss: 1.4467 - val_accuracy: 0.4533\n",
            "Epoch 122/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0341 - accuracy: 0.6200 - val_loss: 1.4471 - val_accuracy: 0.4333\n",
            "Epoch 123/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0333 - accuracy: 0.6214 - val_loss: 1.4364 - val_accuracy: 0.4600\n",
            "Epoch 124/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0308 - accuracy: 0.6129 - val_loss: 1.4349 - val_accuracy: 0.4700\n",
            "Epoch 125/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0282 - accuracy: 0.6171 - val_loss: 1.4410 - val_accuracy: 0.4567\n",
            "Epoch 126/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0262 - accuracy: 0.6100 - val_loss: 1.4426 - val_accuracy: 0.4667\n",
            "Epoch 127/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0238 - accuracy: 0.6300 - val_loss: 1.4477 - val_accuracy: 0.4700\n",
            "Epoch 128/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0226 - accuracy: 0.6214 - val_loss: 1.4418 - val_accuracy: 0.4667\n",
            "Epoch 129/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0195 - accuracy: 0.6200 - val_loss: 1.4461 - val_accuracy: 0.4500\n",
            "Epoch 130/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0190 - accuracy: 0.6214 - val_loss: 1.4416 - val_accuracy: 0.4733\n",
            "Epoch 131/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0151 - accuracy: 0.6257 - val_loss: 1.4450 - val_accuracy: 0.4633\n",
            "Epoch 132/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0147 - accuracy: 0.6200 - val_loss: 1.4474 - val_accuracy: 0.4667\n",
            "Epoch 133/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 1.0083 - accuracy: 0.6186 - val_loss: 1.4412 - val_accuracy: 0.4500\n",
            "Epoch 134/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0120 - accuracy: 0.6243 - val_loss: 1.4577 - val_accuracy: 0.4600\n",
            "Epoch 135/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0090 - accuracy: 0.6314 - val_loss: 1.4523 - val_accuracy: 0.4600\n",
            "Epoch 136/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0053 - accuracy: 0.6271 - val_loss: 1.4487 - val_accuracy: 0.4633\n",
            "Epoch 137/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0028 - accuracy: 0.6271 - val_loss: 1.4584 - val_accuracy: 0.4600\n",
            "Epoch 138/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0035 - accuracy: 0.6243 - val_loss: 1.4548 - val_accuracy: 0.4700\n",
            "Epoch 139/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.0002 - accuracy: 0.6186 - val_loss: 1.4407 - val_accuracy: 0.4733\n",
            "Epoch 140/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9961 - accuracy: 0.6357 - val_loss: 1.4532 - val_accuracy: 0.4600\n",
            "Epoch 141/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9947 - accuracy: 0.6286 - val_loss: 1.4678 - val_accuracy: 0.4600\n",
            "Epoch 142/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9958 - accuracy: 0.6271 - val_loss: 1.4454 - val_accuracy: 0.4767\n",
            "Epoch 143/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9906 - accuracy: 0.6371 - val_loss: 1.4437 - val_accuracy: 0.4767\n",
            "Epoch 144/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9931 - accuracy: 0.6214 - val_loss: 1.4549 - val_accuracy: 0.4700\n",
            "Epoch 145/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9875 - accuracy: 0.6214 - val_loss: 1.4636 - val_accuracy: 0.4367\n",
            "Epoch 146/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9896 - accuracy: 0.6371 - val_loss: 1.4518 - val_accuracy: 0.4700\n",
            "Epoch 147/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9855 - accuracy: 0.6343 - val_loss: 1.4654 - val_accuracy: 0.4600\n",
            "Epoch 148/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9840 - accuracy: 0.6257 - val_loss: 1.4529 - val_accuracy: 0.4600\n",
            "Epoch 149/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9842 - accuracy: 0.6214 - val_loss: 1.4695 - val_accuracy: 0.4600\n",
            "Epoch 150/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9809 - accuracy: 0.6386 - val_loss: 1.4665 - val_accuracy: 0.4600\n",
            "Epoch 151/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9792 - accuracy: 0.6314 - val_loss: 1.4532 - val_accuracy: 0.4633\n",
            "Epoch 152/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9795 - accuracy: 0.6400 - val_loss: 1.4577 - val_accuracy: 0.4633\n",
            "Epoch 153/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9770 - accuracy: 0.6457 - val_loss: 1.4554 - val_accuracy: 0.4667\n",
            "Epoch 154/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9767 - accuracy: 0.6243 - val_loss: 1.4625 - val_accuracy: 0.4633\n",
            "Epoch 155/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9728 - accuracy: 0.6414 - val_loss: 1.4568 - val_accuracy: 0.4700\n",
            "Epoch 156/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9697 - accuracy: 0.6386 - val_loss: 1.4588 - val_accuracy: 0.4667\n",
            "Epoch 157/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9713 - accuracy: 0.6443 - val_loss: 1.4634 - val_accuracy: 0.4633\n",
            "Epoch 158/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9680 - accuracy: 0.6457 - val_loss: 1.4715 - val_accuracy: 0.4633\n",
            "Epoch 159/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9661 - accuracy: 0.6386 - val_loss: 1.4677 - val_accuracy: 0.4700\n",
            "Epoch 160/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9682 - accuracy: 0.6429 - val_loss: 1.4623 - val_accuracy: 0.4800\n",
            "Epoch 161/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9632 - accuracy: 0.6414 - val_loss: 1.4850 - val_accuracy: 0.4567\n",
            "Epoch 162/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9628 - accuracy: 0.6414 - val_loss: 1.4639 - val_accuracy: 0.4733\n",
            "Epoch 163/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9596 - accuracy: 0.6414 - val_loss: 1.4788 - val_accuracy: 0.4633\n",
            "Epoch 164/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9574 - accuracy: 0.6357 - val_loss: 1.4659 - val_accuracy: 0.4767\n",
            "Epoch 165/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9577 - accuracy: 0.6457 - val_loss: 1.4683 - val_accuracy: 0.4733\n",
            "Epoch 166/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9563 - accuracy: 0.6414 - val_loss: 1.4756 - val_accuracy: 0.4667\n",
            "Epoch 167/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9551 - accuracy: 0.6443 - val_loss: 1.4717 - val_accuracy: 0.4733\n",
            "Epoch 168/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9494 - accuracy: 0.6571 - val_loss: 1.4666 - val_accuracy: 0.4700\n",
            "Epoch 169/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9499 - accuracy: 0.6386 - val_loss: 1.4703 - val_accuracy: 0.4667\n",
            "Epoch 170/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9513 - accuracy: 0.6400 - val_loss: 1.4730 - val_accuracy: 0.4800\n",
            "Epoch 171/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9483 - accuracy: 0.6486 - val_loss: 1.4762 - val_accuracy: 0.4733\n",
            "Epoch 172/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9462 - accuracy: 0.6386 - val_loss: 1.4736 - val_accuracy: 0.4800\n",
            "Epoch 173/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9444 - accuracy: 0.6429 - val_loss: 1.4740 - val_accuracy: 0.4800\n",
            "Epoch 174/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9445 - accuracy: 0.6443 - val_loss: 1.4728 - val_accuracy: 0.4867\n",
            "Epoch 175/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9418 - accuracy: 0.6571 - val_loss: 1.4743 - val_accuracy: 0.4667\n",
            "Epoch 176/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9414 - accuracy: 0.6471 - val_loss: 1.4818 - val_accuracy: 0.4733\n",
            "Epoch 177/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9388 - accuracy: 0.6543 - val_loss: 1.4844 - val_accuracy: 0.4833\n",
            "Epoch 178/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9386 - accuracy: 0.6514 - val_loss: 1.4863 - val_accuracy: 0.4733\n",
            "Epoch 179/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9347 - accuracy: 0.6471 - val_loss: 1.4868 - val_accuracy: 0.4700\n",
            "Epoch 180/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9345 - accuracy: 0.6529 - val_loss: 1.4885 - val_accuracy: 0.4867\n",
            "Epoch 181/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9348 - accuracy: 0.6557 - val_loss: 1.4839 - val_accuracy: 0.4733\n",
            "Epoch 182/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9322 - accuracy: 0.6429 - val_loss: 1.4869 - val_accuracy: 0.4633\n",
            "Epoch 183/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9314 - accuracy: 0.6500 - val_loss: 1.4828 - val_accuracy: 0.4867\n",
            "Epoch 184/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9290 - accuracy: 0.6486 - val_loss: 1.4760 - val_accuracy: 0.4600\n",
            "Epoch 185/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9271 - accuracy: 0.6571 - val_loss: 1.4840 - val_accuracy: 0.4733\n",
            "Epoch 186/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9274 - accuracy: 0.6529 - val_loss: 1.4702 - val_accuracy: 0.4800\n",
            "Epoch 187/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9272 - accuracy: 0.6443 - val_loss: 1.4910 - val_accuracy: 0.4700\n",
            "Epoch 188/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9238 - accuracy: 0.6557 - val_loss: 1.4941 - val_accuracy: 0.4733\n",
            "Epoch 189/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9255 - accuracy: 0.6571 - val_loss: 1.4895 - val_accuracy: 0.4833\n",
            "Epoch 190/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9226 - accuracy: 0.6529 - val_loss: 1.4885 - val_accuracy: 0.4833\n",
            "Epoch 191/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9212 - accuracy: 0.6586 - val_loss: 1.4961 - val_accuracy: 0.4800\n",
            "Epoch 192/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9175 - accuracy: 0.6586 - val_loss: 1.4898 - val_accuracy: 0.4600\n",
            "Epoch 193/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9172 - accuracy: 0.6543 - val_loss: 1.4980 - val_accuracy: 0.4733\n",
            "Epoch 194/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9154 - accuracy: 0.6614 - val_loss: 1.4893 - val_accuracy: 0.4800\n",
            "Epoch 195/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9149 - accuracy: 0.6614 - val_loss: 1.4955 - val_accuracy: 0.4867\n",
            "Epoch 196/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.6629 - val_loss: 1.5000 - val_accuracy: 0.4800\n",
            "Epoch 197/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9112 - accuracy: 0.6643 - val_loss: 1.5042 - val_accuracy: 0.4833\n",
            "Epoch 198/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9111 - accuracy: 0.6586 - val_loss: 1.5052 - val_accuracy: 0.4767\n",
            "Epoch 199/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9098 - accuracy: 0.6600 - val_loss: 1.5120 - val_accuracy: 0.4733\n",
            "Epoch 200/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9077 - accuracy: 0.6629 - val_loss: 1.5266 - val_accuracy: 0.4667\n",
            "Epoch 201/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9083 - accuracy: 0.6600 - val_loss: 1.4995 - val_accuracy: 0.4700\n",
            "Epoch 202/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9062 - accuracy: 0.6671 - val_loss: 1.5180 - val_accuracy: 0.4667\n",
            "Epoch 203/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9052 - accuracy: 0.6657 - val_loss: 1.4994 - val_accuracy: 0.4767\n",
            "Epoch 204/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9015 - accuracy: 0.6714 - val_loss: 1.5128 - val_accuracy: 0.4767\n",
            "Epoch 205/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9028 - accuracy: 0.6614 - val_loss: 1.5020 - val_accuracy: 0.4700\n",
            "Epoch 206/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.9011 - accuracy: 0.6600 - val_loss: 1.4994 - val_accuracy: 0.4833\n",
            "Epoch 207/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8981 - accuracy: 0.6771 - val_loss: 1.5014 - val_accuracy: 0.4667\n",
            "Epoch 208/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8975 - accuracy: 0.6700 - val_loss: 1.5122 - val_accuracy: 0.4600\n",
            "Epoch 209/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8971 - accuracy: 0.6700 - val_loss: 1.5058 - val_accuracy: 0.4700\n",
            "Epoch 210/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8984 - accuracy: 0.6629 - val_loss: 1.5188 - val_accuracy: 0.4733\n",
            "Epoch 211/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8937 - accuracy: 0.6657 - val_loss: 1.5276 - val_accuracy: 0.4700\n",
            "Epoch 212/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8914 - accuracy: 0.6686 - val_loss: 1.5062 - val_accuracy: 0.4700\n",
            "Epoch 213/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8931 - accuracy: 0.6629 - val_loss: 1.5355 - val_accuracy: 0.4633\n",
            "Epoch 214/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8906 - accuracy: 0.6757 - val_loss: 1.5209 - val_accuracy: 0.4700\n",
            "Epoch 215/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8897 - accuracy: 0.6700 - val_loss: 1.5229 - val_accuracy: 0.4600\n",
            "Epoch 216/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8872 - accuracy: 0.6686 - val_loss: 1.5221 - val_accuracy: 0.4800\n",
            "Epoch 217/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8864 - accuracy: 0.6786 - val_loss: 1.5331 - val_accuracy: 0.4700\n",
            "Epoch 218/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8864 - accuracy: 0.6671 - val_loss: 1.5124 - val_accuracy: 0.4633\n",
            "Epoch 219/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8861 - accuracy: 0.6786 - val_loss: 1.5211 - val_accuracy: 0.4733\n",
            "Epoch 220/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8857 - accuracy: 0.6814 - val_loss: 1.5302 - val_accuracy: 0.4767\n",
            "Epoch 221/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8848 - accuracy: 0.6771 - val_loss: 1.5151 - val_accuracy: 0.4667\n",
            "Epoch 222/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8818 - accuracy: 0.6800 - val_loss: 1.5243 - val_accuracy: 0.4700\n",
            "Epoch 223/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8795 - accuracy: 0.6786 - val_loss: 1.5106 - val_accuracy: 0.4600\n",
            "Epoch 224/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8789 - accuracy: 0.6829 - val_loss: 1.5194 - val_accuracy: 0.4600\n",
            "Epoch 225/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8801 - accuracy: 0.6786 - val_loss: 1.5246 - val_accuracy: 0.4733\n",
            "Epoch 226/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8770 - accuracy: 0.6743 - val_loss: 1.5362 - val_accuracy: 0.4700\n",
            "Epoch 227/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8749 - accuracy: 0.6743 - val_loss: 1.5195 - val_accuracy: 0.4767\n",
            "Epoch 228/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8775 - accuracy: 0.6771 - val_loss: 1.5340 - val_accuracy: 0.4733\n",
            "Epoch 229/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8746 - accuracy: 0.6800 - val_loss: 1.5287 - val_accuracy: 0.4533\n",
            "Epoch 230/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8725 - accuracy: 0.6900 - val_loss: 1.5159 - val_accuracy: 0.4600\n",
            "Epoch 231/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8730 - accuracy: 0.6814 - val_loss: 1.5360 - val_accuracy: 0.4667\n",
            "Epoch 232/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8701 - accuracy: 0.6829 - val_loss: 1.5351 - val_accuracy: 0.4567\n",
            "Epoch 233/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8699 - accuracy: 0.6886 - val_loss: 1.5282 - val_accuracy: 0.4633\n",
            "Epoch 234/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8695 - accuracy: 0.6800 - val_loss: 1.5308 - val_accuracy: 0.4667\n",
            "Epoch 235/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8670 - accuracy: 0.6929 - val_loss: 1.5311 - val_accuracy: 0.4633\n",
            "Epoch 236/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8659 - accuracy: 0.6871 - val_loss: 1.5345 - val_accuracy: 0.4700\n",
            "Epoch 237/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8651 - accuracy: 0.6857 - val_loss: 1.5373 - val_accuracy: 0.4733\n",
            "Epoch 238/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.6929 - val_loss: 1.5483 - val_accuracy: 0.4633\n",
            "Epoch 239/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8644 - accuracy: 0.6971 - val_loss: 1.5410 - val_accuracy: 0.4600\n",
            "Epoch 240/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8613 - accuracy: 0.6943 - val_loss: 1.5590 - val_accuracy: 0.4600\n",
            "Epoch 241/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8589 - accuracy: 0.6914 - val_loss: 1.5321 - val_accuracy: 0.4600\n",
            "Epoch 242/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8615 - accuracy: 0.6757 - val_loss: 1.5500 - val_accuracy: 0.4700\n",
            "Epoch 243/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8587 - accuracy: 0.6943 - val_loss: 1.5503 - val_accuracy: 0.4733\n",
            "Epoch 244/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8583 - accuracy: 0.6929 - val_loss: 1.5439 - val_accuracy: 0.4733\n",
            "Epoch 245/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8581 - accuracy: 0.6900 - val_loss: 1.5424 - val_accuracy: 0.4600\n",
            "Epoch 246/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8566 - accuracy: 0.6957 - val_loss: 1.5613 - val_accuracy: 0.4700\n",
            "Epoch 247/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8568 - accuracy: 0.6943 - val_loss: 1.5437 - val_accuracy: 0.4600\n",
            "Epoch 248/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8546 - accuracy: 0.6986 - val_loss: 1.5580 - val_accuracy: 0.4600\n",
            "Epoch 249/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8547 - accuracy: 0.6971 - val_loss: 1.5538 - val_accuracy: 0.4600\n",
            "Epoch 250/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8524 - accuracy: 0.6900 - val_loss: 1.5539 - val_accuracy: 0.4600\n",
            "Epoch 251/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8508 - accuracy: 0.6943 - val_loss: 1.5592 - val_accuracy: 0.4633\n",
            "Epoch 252/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8492 - accuracy: 0.6914 - val_loss: 1.5624 - val_accuracy: 0.4700\n",
            "Epoch 253/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8500 - accuracy: 0.6986 - val_loss: 1.5456 - val_accuracy: 0.4567\n",
            "Epoch 254/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8488 - accuracy: 0.7071 - val_loss: 1.5505 - val_accuracy: 0.4667\n",
            "Epoch 255/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8471 - accuracy: 0.7071 - val_loss: 1.5597 - val_accuracy: 0.4533\n",
            "Epoch 256/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8468 - accuracy: 0.7057 - val_loss: 1.5474 - val_accuracy: 0.4600\n",
            "Epoch 257/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8436 - accuracy: 0.7029 - val_loss: 1.5580 - val_accuracy: 0.4567\n",
            "Epoch 258/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8429 - accuracy: 0.6971 - val_loss: 1.5628 - val_accuracy: 0.4600\n",
            "Epoch 259/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8425 - accuracy: 0.7114 - val_loss: 1.5615 - val_accuracy: 0.4667\n",
            "Epoch 260/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8406 - accuracy: 0.6971 - val_loss: 1.5660 - val_accuracy: 0.4600\n",
            "Epoch 261/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8428 - accuracy: 0.7014 - val_loss: 1.5720 - val_accuracy: 0.4600\n",
            "Epoch 262/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8403 - accuracy: 0.7057 - val_loss: 1.5768 - val_accuracy: 0.4700\n",
            "Epoch 263/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8386 - accuracy: 0.7014 - val_loss: 1.5740 - val_accuracy: 0.4667\n",
            "Epoch 264/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8394 - accuracy: 0.7043 - val_loss: 1.5718 - val_accuracy: 0.4667\n",
            "Epoch 265/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8376 - accuracy: 0.7029 - val_loss: 1.5764 - val_accuracy: 0.4667\n",
            "Epoch 266/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8372 - accuracy: 0.7043 - val_loss: 1.5702 - val_accuracy: 0.4667\n",
            "Epoch 267/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8352 - accuracy: 0.7100 - val_loss: 1.5830 - val_accuracy: 0.4667\n",
            "Epoch 268/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.7129 - val_loss: 1.5857 - val_accuracy: 0.4667\n",
            "Epoch 269/1000\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.8340 - accuracy: 0.6986 - val_loss: 1.5694 - val_accuracy: 0.4533\n",
            "Epoch 270/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8343 - accuracy: 0.7100 - val_loss: 1.5774 - val_accuracy: 0.4600\n",
            "Epoch 271/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8339 - accuracy: 0.7114 - val_loss: 1.5872 - val_accuracy: 0.4667\n",
            "Epoch 272/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8276 - accuracy: 0.7071 - val_loss: 1.5814 - val_accuracy: 0.4633\n",
            "Epoch 273/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8302 - accuracy: 0.7086 - val_loss: 1.5888 - val_accuracy: 0.4533\n",
            "Epoch 274/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8298 - accuracy: 0.7143 - val_loss: 1.5997 - val_accuracy: 0.4600\n",
            "Epoch 275/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8293 - accuracy: 0.7057 - val_loss: 1.5758 - val_accuracy: 0.4567\n",
            "Epoch 276/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8271 - accuracy: 0.7157 - val_loss: 1.5955 - val_accuracy: 0.4733\n",
            "Epoch 277/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8249 - accuracy: 0.7086 - val_loss: 1.5804 - val_accuracy: 0.4600\n",
            "Epoch 278/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8242 - accuracy: 0.7129 - val_loss: 1.5728 - val_accuracy: 0.4433\n",
            "Epoch 279/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8245 - accuracy: 0.7143 - val_loss: 1.5803 - val_accuracy: 0.4533\n",
            "Epoch 280/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8232 - accuracy: 0.7100 - val_loss: 1.5798 - val_accuracy: 0.4667\n",
            "Epoch 281/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8208 - accuracy: 0.7200 - val_loss: 1.6053 - val_accuracy: 0.4667\n",
            "Epoch 282/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8233 - accuracy: 0.7057 - val_loss: 1.5944 - val_accuracy: 0.4667\n",
            "Epoch 283/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8211 - accuracy: 0.7100 - val_loss: 1.5879 - val_accuracy: 0.4567\n",
            "Epoch 284/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8195 - accuracy: 0.7229 - val_loss: 1.5934 - val_accuracy: 0.4500\n",
            "Epoch 285/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8198 - accuracy: 0.7157 - val_loss: 1.5942 - val_accuracy: 0.4467\n",
            "Epoch 286/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8181 - accuracy: 0.7171 - val_loss: 1.5865 - val_accuracy: 0.4467\n",
            "Epoch 287/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8176 - accuracy: 0.7186 - val_loss: 1.5925 - val_accuracy: 0.4567\n",
            "Epoch 288/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8161 - accuracy: 0.7229 - val_loss: 1.6081 - val_accuracy: 0.4600\n",
            "Epoch 289/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8171 - accuracy: 0.7129 - val_loss: 1.5911 - val_accuracy: 0.4500\n",
            "Epoch 290/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.7057 - val_loss: 1.5921 - val_accuracy: 0.4567\n",
            "Epoch 291/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8133 - accuracy: 0.7214 - val_loss: 1.6046 - val_accuracy: 0.4600\n",
            "Epoch 292/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8149 - accuracy: 0.7086 - val_loss: 1.5951 - val_accuracy: 0.4633\n",
            "Epoch 293/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8117 - accuracy: 0.7271 - val_loss: 1.6121 - val_accuracy: 0.4567\n",
            "Epoch 294/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8126 - accuracy: 0.7243 - val_loss: 1.6033 - val_accuracy: 0.4500\n",
            "Epoch 295/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8098 - accuracy: 0.7157 - val_loss: 1.6065 - val_accuracy: 0.4600\n",
            "Epoch 296/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8113 - accuracy: 0.7243 - val_loss: 1.6133 - val_accuracy: 0.4567\n",
            "Epoch 297/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8094 - accuracy: 0.7229 - val_loss: 1.6059 - val_accuracy: 0.4567\n",
            "Epoch 298/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8072 - accuracy: 0.7243 - val_loss: 1.6093 - val_accuracy: 0.4500\n",
            "Epoch 299/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8072 - accuracy: 0.7243 - val_loss: 1.6059 - val_accuracy: 0.4467\n",
            "Epoch 300/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8057 - accuracy: 0.7229 - val_loss: 1.6106 - val_accuracy: 0.4567\n",
            "Epoch 301/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8044 - accuracy: 0.7271 - val_loss: 1.6152 - val_accuracy: 0.4633\n",
            "Epoch 302/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8054 - accuracy: 0.7300 - val_loss: 1.6178 - val_accuracy: 0.4567\n",
            "Epoch 303/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8034 - accuracy: 0.7229 - val_loss: 1.6136 - val_accuracy: 0.4567\n",
            "Epoch 304/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8032 - accuracy: 0.7186 - val_loss: 1.6119 - val_accuracy: 0.4533\n",
            "Epoch 305/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8020 - accuracy: 0.7271 - val_loss: 1.6193 - val_accuracy: 0.4400\n",
            "Epoch 306/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8025 - accuracy: 0.7243 - val_loss: 1.6158 - val_accuracy: 0.4600\n",
            "Epoch 307/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.8024 - accuracy: 0.7186 - val_loss: 1.6322 - val_accuracy: 0.4667\n",
            "Epoch 308/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7998 - accuracy: 0.7271 - val_loss: 1.6156 - val_accuracy: 0.4500\n",
            "Epoch 309/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7996 - accuracy: 0.7314 - val_loss: 1.6042 - val_accuracy: 0.4500\n",
            "Epoch 310/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7954 - accuracy: 0.7243 - val_loss: 1.6286 - val_accuracy: 0.4567\n",
            "Epoch 311/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7989 - accuracy: 0.7186 - val_loss: 1.6183 - val_accuracy: 0.4500\n",
            "Epoch 312/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7967 - accuracy: 0.7286 - val_loss: 1.6471 - val_accuracy: 0.4467\n",
            "Epoch 313/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7971 - accuracy: 0.7243 - val_loss: 1.6343 - val_accuracy: 0.4500\n",
            "Epoch 314/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7949 - accuracy: 0.7314 - val_loss: 1.6274 - val_accuracy: 0.4533\n",
            "Epoch 315/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7945 - accuracy: 0.7214 - val_loss: 1.6205 - val_accuracy: 0.4433\n",
            "Epoch 316/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7921 - accuracy: 0.7286 - val_loss: 1.6317 - val_accuracy: 0.4600\n",
            "Epoch 317/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.7243 - val_loss: 1.6402 - val_accuracy: 0.4567\n",
            "Epoch 318/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7902 - accuracy: 0.7257 - val_loss: 1.6227 - val_accuracy: 0.4500\n",
            "Epoch 319/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7898 - accuracy: 0.7300 - val_loss: 1.6434 - val_accuracy: 0.4567\n",
            "Epoch 320/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7913 - accuracy: 0.7314 - val_loss: 1.6384 - val_accuracy: 0.4567\n",
            "Epoch 321/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.7286 - val_loss: 1.6386 - val_accuracy: 0.4567\n",
            "Epoch 322/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7904 - accuracy: 0.7357 - val_loss: 1.6298 - val_accuracy: 0.4400\n",
            "Epoch 323/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7886 - accuracy: 0.7386 - val_loss: 1.6534 - val_accuracy: 0.4500\n",
            "Epoch 324/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.7300 - val_loss: 1.6417 - val_accuracy: 0.4567\n",
            "Epoch 325/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7859 - accuracy: 0.7286 - val_loss: 1.6324 - val_accuracy: 0.4500\n",
            "Epoch 326/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7841 - accuracy: 0.7357 - val_loss: 1.6662 - val_accuracy: 0.4567\n",
            "Epoch 327/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7856 - accuracy: 0.7329 - val_loss: 1.6457 - val_accuracy: 0.4500\n",
            "Epoch 328/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7840 - accuracy: 0.7343 - val_loss: 1.6732 - val_accuracy: 0.4567\n",
            "Epoch 329/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7839 - accuracy: 0.7329 - val_loss: 1.6517 - val_accuracy: 0.4500\n",
            "Epoch 330/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7821 - accuracy: 0.7300 - val_loss: 1.6508 - val_accuracy: 0.4467\n",
            "Epoch 331/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7805 - accuracy: 0.7414 - val_loss: 1.6544 - val_accuracy: 0.4367\n",
            "Epoch 332/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7807 - accuracy: 0.7300 - val_loss: 1.6636 - val_accuracy: 0.4633\n",
            "Epoch 333/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7797 - accuracy: 0.7314 - val_loss: 1.6460 - val_accuracy: 0.4600\n",
            "Epoch 334/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7801 - accuracy: 0.7300 - val_loss: 1.6475 - val_accuracy: 0.4600\n",
            "Epoch 335/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7790 - accuracy: 0.7371 - val_loss: 1.6538 - val_accuracy: 0.4467\n",
            "Epoch 336/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7777 - accuracy: 0.7343 - val_loss: 1.6496 - val_accuracy: 0.4533\n",
            "Epoch 337/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7771 - accuracy: 0.7329 - val_loss: 1.6512 - val_accuracy: 0.4467\n",
            "Epoch 338/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7755 - accuracy: 0.7400 - val_loss: 1.6652 - val_accuracy: 0.4700\n",
            "Epoch 339/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7765 - accuracy: 0.7357 - val_loss: 1.6694 - val_accuracy: 0.4633\n",
            "Epoch 340/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7756 - accuracy: 0.7300 - val_loss: 1.6766 - val_accuracy: 0.4567\n",
            "Epoch 341/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7731 - accuracy: 0.7329 - val_loss: 1.6766 - val_accuracy: 0.4600\n",
            "Epoch 342/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7751 - accuracy: 0.7343 - val_loss: 1.6583 - val_accuracy: 0.4567\n",
            "Epoch 343/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7735 - accuracy: 0.7329 - val_loss: 1.6587 - val_accuracy: 0.4433\n",
            "Epoch 344/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.7300 - val_loss: 1.6669 - val_accuracy: 0.4500\n",
            "Epoch 345/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7731 - accuracy: 0.7314 - val_loss: 1.6721 - val_accuracy: 0.4500\n",
            "Epoch 346/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7688 - accuracy: 0.7429 - val_loss: 1.6674 - val_accuracy: 0.4500\n",
            "Epoch 347/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7704 - accuracy: 0.7414 - val_loss: 1.6774 - val_accuracy: 0.4500\n",
            "Epoch 348/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7689 - accuracy: 0.7414 - val_loss: 1.6631 - val_accuracy: 0.4533\n",
            "Epoch 349/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7690 - accuracy: 0.7400 - val_loss: 1.6785 - val_accuracy: 0.4533\n",
            "Epoch 350/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7673 - accuracy: 0.7386 - val_loss: 1.6709 - val_accuracy: 0.4500\n",
            "Epoch 351/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.7414 - val_loss: 1.7031 - val_accuracy: 0.4567\n",
            "Epoch 352/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7662 - accuracy: 0.7386 - val_loss: 1.6844 - val_accuracy: 0.4567\n",
            "Epoch 353/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7676 - accuracy: 0.7443 - val_loss: 1.6814 - val_accuracy: 0.4567\n",
            "Epoch 354/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.7357 - val_loss: 1.6746 - val_accuracy: 0.4533\n",
            "Epoch 355/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7654 - accuracy: 0.7371 - val_loss: 1.6788 - val_accuracy: 0.4400\n",
            "Epoch 356/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7626 - accuracy: 0.7414 - val_loss: 1.6885 - val_accuracy: 0.4600\n",
            "Epoch 357/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7627 - accuracy: 0.7400 - val_loss: 1.6735 - val_accuracy: 0.4533\n",
            "Epoch 358/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7612 - accuracy: 0.7386 - val_loss: 1.6850 - val_accuracy: 0.4400\n",
            "Epoch 359/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7629 - accuracy: 0.7386 - val_loss: 1.6785 - val_accuracy: 0.4567\n",
            "Epoch 360/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7617 - accuracy: 0.7429 - val_loss: 1.6908 - val_accuracy: 0.4600\n",
            "Epoch 361/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7610 - accuracy: 0.7386 - val_loss: 1.6948 - val_accuracy: 0.4533\n",
            "Epoch 362/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7593 - accuracy: 0.7486 - val_loss: 1.7018 - val_accuracy: 0.4600\n",
            "Epoch 363/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7594 - accuracy: 0.7471 - val_loss: 1.6837 - val_accuracy: 0.4633\n",
            "Epoch 364/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7576 - accuracy: 0.7471 - val_loss: 1.7135 - val_accuracy: 0.4633\n",
            "Epoch 365/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7581 - accuracy: 0.7429 - val_loss: 1.7169 - val_accuracy: 0.4500\n",
            "Epoch 366/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7561 - accuracy: 0.7443 - val_loss: 1.7132 - val_accuracy: 0.4533\n",
            "Epoch 367/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7545 - accuracy: 0.7486 - val_loss: 1.6850 - val_accuracy: 0.4533\n",
            "Epoch 368/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.7429 - val_loss: 1.7018 - val_accuracy: 0.4567\n",
            "Epoch 369/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7558 - accuracy: 0.7457 - val_loss: 1.6909 - val_accuracy: 0.4533\n",
            "Epoch 370/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7532 - accuracy: 0.7471 - val_loss: 1.7048 - val_accuracy: 0.4567\n",
            "Epoch 371/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7538 - accuracy: 0.7471 - val_loss: 1.7060 - val_accuracy: 0.4600\n",
            "Epoch 372/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7508 - accuracy: 0.7443 - val_loss: 1.7107 - val_accuracy: 0.4600\n",
            "Epoch 373/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7519 - accuracy: 0.7443 - val_loss: 1.6953 - val_accuracy: 0.4600\n",
            "Epoch 374/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7504 - accuracy: 0.7414 - val_loss: 1.7019 - val_accuracy: 0.4567\n",
            "Epoch 375/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.7471 - val_loss: 1.6982 - val_accuracy: 0.4500\n",
            "Epoch 376/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7513 - accuracy: 0.7429 - val_loss: 1.7038 - val_accuracy: 0.4600\n",
            "Epoch 377/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7502 - accuracy: 0.7443 - val_loss: 1.6967 - val_accuracy: 0.4433\n",
            "Epoch 378/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7491 - accuracy: 0.7400 - val_loss: 1.6968 - val_accuracy: 0.4600\n",
            "Epoch 379/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7494 - accuracy: 0.7500 - val_loss: 1.7133 - val_accuracy: 0.4633\n",
            "Epoch 380/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7467 - accuracy: 0.7514 - val_loss: 1.7063 - val_accuracy: 0.4433\n",
            "Epoch 381/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7467 - accuracy: 0.7443 - val_loss: 1.7033 - val_accuracy: 0.4500\n",
            "Epoch 382/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7458 - accuracy: 0.7457 - val_loss: 1.7149 - val_accuracy: 0.4567\n",
            "Epoch 383/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.7529 - val_loss: 1.7137 - val_accuracy: 0.4533\n",
            "Epoch 384/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7457 - accuracy: 0.7529 - val_loss: 1.7286 - val_accuracy: 0.4667\n",
            "Epoch 385/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7420 - accuracy: 0.7400 - val_loss: 1.7273 - val_accuracy: 0.4467\n",
            "Epoch 386/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7434 - accuracy: 0.7429 - val_loss: 1.7273 - val_accuracy: 0.4600\n",
            "Epoch 387/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.7514 - val_loss: 1.7122 - val_accuracy: 0.4600\n",
            "Epoch 388/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.7486 - val_loss: 1.7094 - val_accuracy: 0.4533\n",
            "Epoch 389/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7422 - accuracy: 0.7414 - val_loss: 1.7258 - val_accuracy: 0.4467\n",
            "Epoch 390/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7423 - accuracy: 0.7514 - val_loss: 1.7077 - val_accuracy: 0.4467\n",
            "Epoch 391/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7385 - accuracy: 0.7586 - val_loss: 1.7222 - val_accuracy: 0.4467\n",
            "Epoch 392/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7413 - accuracy: 0.7500 - val_loss: 1.7214 - val_accuracy: 0.4467\n",
            "Epoch 393/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7380 - accuracy: 0.7486 - val_loss: 1.7346 - val_accuracy: 0.4600\n",
            "Epoch 394/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7402 - accuracy: 0.7486 - val_loss: 1.7291 - val_accuracy: 0.4533\n",
            "Epoch 395/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.7500 - val_loss: 1.7286 - val_accuracy: 0.4467\n",
            "Epoch 396/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.7457 - val_loss: 1.7202 - val_accuracy: 0.4533\n",
            "Epoch 397/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7514 - val_loss: 1.7302 - val_accuracy: 0.4600\n",
            "Epoch 398/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.7529 - val_loss: 1.7460 - val_accuracy: 0.4567\n",
            "Epoch 399/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7342 - accuracy: 0.7557 - val_loss: 1.7382 - val_accuracy: 0.4533\n",
            "Epoch 400/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.7557 - val_loss: 1.7293 - val_accuracy: 0.4600\n",
            "Epoch 401/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7338 - accuracy: 0.7457 - val_loss: 1.7487 - val_accuracy: 0.4533\n",
            "Epoch 402/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.7614 - val_loss: 1.7206 - val_accuracy: 0.4500\n",
            "Epoch 403/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7320 - accuracy: 0.7514 - val_loss: 1.7525 - val_accuracy: 0.4500\n",
            "Epoch 404/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7321 - accuracy: 0.7486 - val_loss: 1.7589 - val_accuracy: 0.4600\n",
            "Epoch 405/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.7514 - val_loss: 1.7539 - val_accuracy: 0.4567\n",
            "Epoch 406/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.7586 - val_loss: 1.7527 - val_accuracy: 0.4600\n",
            "Epoch 407/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7316 - accuracy: 0.7514 - val_loss: 1.7285 - val_accuracy: 0.4500\n",
            "Epoch 408/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7289 - accuracy: 0.7514 - val_loss: 1.7545 - val_accuracy: 0.4567\n",
            "Epoch 409/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.7571 - val_loss: 1.7567 - val_accuracy: 0.4533\n",
            "Epoch 410/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.7557 - val_loss: 1.7490 - val_accuracy: 0.4500\n",
            "Epoch 411/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7272 - accuracy: 0.7514 - val_loss: 1.7575 - val_accuracy: 0.4533\n",
            "Epoch 412/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7259 - accuracy: 0.7586 - val_loss: 1.7482 - val_accuracy: 0.4567\n",
            "Epoch 413/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7280 - accuracy: 0.7500 - val_loss: 1.7508 - val_accuracy: 0.4500\n",
            "Epoch 414/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.7500 - val_loss: 1.7450 - val_accuracy: 0.4500\n",
            "Epoch 415/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7250 - accuracy: 0.7486 - val_loss: 1.7748 - val_accuracy: 0.4467\n",
            "Epoch 416/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7257 - accuracy: 0.7543 - val_loss: 1.7516 - val_accuracy: 0.4400\n",
            "Epoch 417/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7244 - accuracy: 0.7557 - val_loss: 1.7485 - val_accuracy: 0.4467\n",
            "Epoch 418/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.7514 - val_loss: 1.7734 - val_accuracy: 0.4467\n",
            "Epoch 419/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7209 - accuracy: 0.7457 - val_loss: 1.7467 - val_accuracy: 0.4467\n",
            "Epoch 420/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7219 - accuracy: 0.7629 - val_loss: 1.7512 - val_accuracy: 0.4367\n",
            "Epoch 421/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.7500 - val_loss: 1.7695 - val_accuracy: 0.4500\n",
            "Epoch 422/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7226 - accuracy: 0.7571 - val_loss: 1.7900 - val_accuracy: 0.4500\n",
            "Epoch 423/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.7557 - val_loss: 1.7581 - val_accuracy: 0.4467\n",
            "Epoch 424/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.7486 - val_loss: 1.7864 - val_accuracy: 0.4533\n",
            "Epoch 425/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.7190 - accuracy: 0.7600 - val_loss: 1.7880 - val_accuracy: 0.4433\n",
            "Epoch 426/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7205 - accuracy: 0.7557 - val_loss: 1.7789 - val_accuracy: 0.4567\n",
            "Epoch 427/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.7629 - val_loss: 1.7753 - val_accuracy: 0.4467\n",
            "Epoch 428/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7172 - accuracy: 0.7514 - val_loss: 1.7742 - val_accuracy: 0.4533\n",
            "Epoch 429/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7157 - accuracy: 0.7643 - val_loss: 1.7712 - val_accuracy: 0.4467\n",
            "Epoch 430/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7183 - accuracy: 0.7571 - val_loss: 1.7684 - val_accuracy: 0.4400\n",
            "Epoch 431/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7148 - accuracy: 0.7529 - val_loss: 1.7838 - val_accuracy: 0.4500\n",
            "Epoch 432/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.7165 - accuracy: 0.7600 - val_loss: 1.7593 - val_accuracy: 0.4500\n",
            "Epoch 433/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.7159 - accuracy: 0.7571 - val_loss: 1.7873 - val_accuracy: 0.4467\n",
            "Epoch 434/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.7543 - val_loss: 1.7703 - val_accuracy: 0.4433\n",
            "Epoch 435/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.7514 - val_loss: 1.7679 - val_accuracy: 0.4467\n",
            "Epoch 436/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7142 - accuracy: 0.7586 - val_loss: 1.7820 - val_accuracy: 0.4500\n",
            "Epoch 437/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7100 - accuracy: 0.7657 - val_loss: 1.8057 - val_accuracy: 0.4400\n",
            "Epoch 438/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.7557 - val_loss: 1.7689 - val_accuracy: 0.4467\n",
            "Epoch 439/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7120 - accuracy: 0.7500 - val_loss: 1.7744 - val_accuracy: 0.4400\n",
            "Epoch 440/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7126 - accuracy: 0.7586 - val_loss: 1.7955 - val_accuracy: 0.4467\n",
            "Epoch 441/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.7614 - val_loss: 1.7720 - val_accuracy: 0.4467\n",
            "Epoch 442/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.7614 - val_loss: 1.7789 - val_accuracy: 0.4500\n",
            "Epoch 443/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.7643 - val_loss: 1.7912 - val_accuracy: 0.4533\n",
            "Epoch 444/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7092 - accuracy: 0.7600 - val_loss: 1.7839 - val_accuracy: 0.4400\n",
            "Epoch 445/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7079 - accuracy: 0.7629 - val_loss: 1.7808 - val_accuracy: 0.4467\n",
            "Epoch 446/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.7671 - val_loss: 1.7902 - val_accuracy: 0.4433\n",
            "Epoch 447/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.7600 - val_loss: 1.7908 - val_accuracy: 0.4500\n",
            "Epoch 448/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7064 - accuracy: 0.7614 - val_loss: 1.8099 - val_accuracy: 0.4433\n",
            "Epoch 449/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.7629 - val_loss: 1.7994 - val_accuracy: 0.4500\n",
            "Epoch 450/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.7586 - val_loss: 1.7936 - val_accuracy: 0.4500\n",
            "Epoch 451/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7051 - accuracy: 0.7571 - val_loss: 1.7959 - val_accuracy: 0.4500\n",
            "Epoch 452/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7034 - accuracy: 0.7586 - val_loss: 1.7989 - val_accuracy: 0.4433\n",
            "Epoch 453/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.7629 - val_loss: 1.7816 - val_accuracy: 0.4400\n",
            "Epoch 454/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.7643 - val_loss: 1.7802 - val_accuracy: 0.4400\n",
            "Epoch 455/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.7657 - val_loss: 1.8034 - val_accuracy: 0.4467\n",
            "Epoch 456/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7029 - accuracy: 0.7629 - val_loss: 1.8196 - val_accuracy: 0.4433\n",
            "Epoch 457/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.7614 - val_loss: 1.8085 - val_accuracy: 0.4467\n",
            "Epoch 458/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7019 - accuracy: 0.7643 - val_loss: 1.8002 - val_accuracy: 0.4433\n",
            "Epoch 459/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.7643 - val_loss: 1.7909 - val_accuracy: 0.4400\n",
            "Epoch 460/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.7657 - val_loss: 1.8285 - val_accuracy: 0.4400\n",
            "Epoch 461/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.7643 - val_loss: 1.8104 - val_accuracy: 0.4500\n",
            "Epoch 462/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.7614 - val_loss: 1.8214 - val_accuracy: 0.4400\n",
            "Epoch 463/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.7629 - val_loss: 1.8279 - val_accuracy: 0.4433\n",
            "Epoch 464/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.7671 - val_loss: 1.8231 - val_accuracy: 0.4367\n",
            "Epoch 465/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.7600 - val_loss: 1.8281 - val_accuracy: 0.4433\n",
            "Epoch 466/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.7643 - val_loss: 1.8372 - val_accuracy: 0.4400\n",
            "Epoch 467/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.7686 - val_loss: 1.8068 - val_accuracy: 0.4367\n",
            "Epoch 468/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6970 - accuracy: 0.7643 - val_loss: 1.8005 - val_accuracy: 0.4367\n",
            "Epoch 469/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.7671 - val_loss: 1.8218 - val_accuracy: 0.4433\n",
            "Epoch 470/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.7629 - val_loss: 1.8311 - val_accuracy: 0.4433\n",
            "Epoch 471/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.7657 - val_loss: 1.8335 - val_accuracy: 0.4400\n",
            "Epoch 472/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.7600 - val_loss: 1.8226 - val_accuracy: 0.4433\n",
            "Epoch 473/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.7643 - val_loss: 1.8357 - val_accuracy: 0.4467\n",
            "Epoch 474/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6901 - accuracy: 0.7686 - val_loss: 1.8460 - val_accuracy: 0.4433\n",
            "Epoch 475/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6922 - accuracy: 0.7657 - val_loss: 1.8335 - val_accuracy: 0.4433\n",
            "Epoch 476/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.7600 - val_loss: 1.8425 - val_accuracy: 0.4400\n",
            "Epoch 477/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.7600 - val_loss: 1.8281 - val_accuracy: 0.4400\n",
            "Epoch 478/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.7657 - val_loss: 1.8255 - val_accuracy: 0.4467\n",
            "Epoch 479/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.7657 - val_loss: 1.8244 - val_accuracy: 0.4333\n",
            "Epoch 480/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.7629 - val_loss: 1.8285 - val_accuracy: 0.4367\n",
            "Epoch 481/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.7571 - val_loss: 1.8393 - val_accuracy: 0.4433\n",
            "Epoch 482/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.7657 - val_loss: 1.8405 - val_accuracy: 0.4400\n",
            "Epoch 483/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.7686 - val_loss: 1.8372 - val_accuracy: 0.4367\n",
            "Epoch 484/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.7629 - val_loss: 1.8238 - val_accuracy: 0.4367\n",
            "Epoch 485/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.7657 - val_loss: 1.8402 - val_accuracy: 0.4367\n",
            "Epoch 486/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.7571 - val_loss: 1.8253 - val_accuracy: 0.4433\n",
            "Epoch 487/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.7614 - val_loss: 1.8674 - val_accuracy: 0.4367\n",
            "Epoch 488/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.7729 - val_loss: 1.8339 - val_accuracy: 0.4367\n",
            "Epoch 489/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.7643 - val_loss: 1.8381 - val_accuracy: 0.4333\n",
            "Epoch 490/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.7657 - val_loss: 1.8415 - val_accuracy: 0.4367\n",
            "Epoch 491/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.7671 - val_loss: 1.8420 - val_accuracy: 0.4400\n",
            "Epoch 492/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.7714 - val_loss: 1.8453 - val_accuracy: 0.4333\n",
            "Epoch 493/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.7657 - val_loss: 1.8452 - val_accuracy: 0.4367\n",
            "Epoch 494/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.7729 - val_loss: 1.8505 - val_accuracy: 0.4367\n",
            "Epoch 495/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.7729 - val_loss: 1.8500 - val_accuracy: 0.4433\n",
            "Epoch 496/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.7643 - val_loss: 1.8632 - val_accuracy: 0.4533\n",
            "Epoch 497/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.7743 - val_loss: 1.8489 - val_accuracy: 0.4367\n",
            "Epoch 498/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.7643 - val_loss: 1.8490 - val_accuracy: 0.4400\n",
            "Epoch 499/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6797 - accuracy: 0.7686 - val_loss: 1.8447 - val_accuracy: 0.4333\n",
            "Epoch 500/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.7643 - val_loss: 1.8744 - val_accuracy: 0.4400\n",
            "Epoch 501/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.7714 - val_loss: 1.8397 - val_accuracy: 0.4400\n",
            "Epoch 502/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.7686 - val_loss: 1.8644 - val_accuracy: 0.4333\n",
            "Epoch 503/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.7671 - val_loss: 1.8409 - val_accuracy: 0.4433\n",
            "Epoch 504/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.7729 - val_loss: 1.8508 - val_accuracy: 0.4367\n",
            "Epoch 505/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6781 - accuracy: 0.7657 - val_loss: 1.8510 - val_accuracy: 0.4400\n",
            "Epoch 506/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6761 - accuracy: 0.7729 - val_loss: 1.8792 - val_accuracy: 0.4433\n",
            "Epoch 507/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.7671 - val_loss: 1.8683 - val_accuracy: 0.4367\n",
            "Epoch 508/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.7729 - val_loss: 1.8416 - val_accuracy: 0.4333\n",
            "Epoch 509/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.7671 - val_loss: 1.8645 - val_accuracy: 0.4333\n",
            "Epoch 510/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.7714 - val_loss: 1.8808 - val_accuracy: 0.4400\n",
            "Epoch 511/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.7700 - val_loss: 1.8513 - val_accuracy: 0.4467\n",
            "Epoch 512/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.7657 - val_loss: 1.8514 - val_accuracy: 0.4400\n",
            "Epoch 513/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.7657 - val_loss: 1.8872 - val_accuracy: 0.4333\n",
            "Epoch 514/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7686 - val_loss: 1.8546 - val_accuracy: 0.4400\n",
            "Epoch 515/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7686 - val_loss: 1.8818 - val_accuracy: 0.4367\n",
            "Epoch 516/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.7686 - val_loss: 1.8626 - val_accuracy: 0.4333\n",
            "Epoch 517/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7729 - val_loss: 1.8719 - val_accuracy: 0.4433\n",
            "Epoch 518/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.7671 - val_loss: 1.8916 - val_accuracy: 0.4367\n",
            "Epoch 519/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.7657 - val_loss: 1.9034 - val_accuracy: 0.4233\n",
            "Epoch 520/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.7700 - val_loss: 1.8891 - val_accuracy: 0.4367\n",
            "Epoch 521/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.7700 - val_loss: 1.8890 - val_accuracy: 0.4367\n",
            "Epoch 522/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.7714 - val_loss: 1.8845 - val_accuracy: 0.4367\n",
            "Epoch 523/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.7671 - val_loss: 1.8674 - val_accuracy: 0.4333\n",
            "Epoch 524/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.7771 - val_loss: 1.8680 - val_accuracy: 0.4333\n",
            "Epoch 525/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.7700 - val_loss: 1.8813 - val_accuracy: 0.4367\n",
            "Epoch 526/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7771 - val_loss: 1.8734 - val_accuracy: 0.4267\n",
            "Epoch 527/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.7729 - val_loss: 1.9013 - val_accuracy: 0.4333\n",
            "Epoch 528/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.7743 - val_loss: 1.8843 - val_accuracy: 0.4400\n",
            "Epoch 529/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7771 - val_loss: 1.8650 - val_accuracy: 0.4400\n",
            "Epoch 530/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.7729 - val_loss: 1.8919 - val_accuracy: 0.4433\n",
            "Epoch 531/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.7757 - val_loss: 1.9301 - val_accuracy: 0.4400\n",
            "Epoch 532/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.7686 - val_loss: 1.9117 - val_accuracy: 0.4533\n",
            "Epoch 533/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.7700 - val_loss: 1.8890 - val_accuracy: 0.4333\n",
            "Epoch 534/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.7657 - val_loss: 1.9108 - val_accuracy: 0.4333\n",
            "Epoch 535/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7671 - val_loss: 1.8944 - val_accuracy: 0.4433\n",
            "Epoch 536/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.7771 - val_loss: 1.9031 - val_accuracy: 0.4367\n",
            "Epoch 537/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7700 - val_loss: 1.9005 - val_accuracy: 0.4467\n",
            "Epoch 538/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.7729 - val_loss: 1.8916 - val_accuracy: 0.4333\n",
            "Epoch 539/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.7800 - val_loss: 1.8968 - val_accuracy: 0.4433\n",
            "Epoch 540/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.7700 - val_loss: 1.9074 - val_accuracy: 0.4400\n",
            "Epoch 541/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.7729 - val_loss: 1.9208 - val_accuracy: 0.4267\n",
            "Epoch 542/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.7714 - val_loss: 1.9037 - val_accuracy: 0.4300\n",
            "Epoch 543/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.7700 - val_loss: 1.8866 - val_accuracy: 0.4333\n",
            "Epoch 544/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.7714 - val_loss: 1.8954 - val_accuracy: 0.4433\n",
            "Epoch 545/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.7700 - val_loss: 1.9344 - val_accuracy: 0.4233\n",
            "Epoch 546/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.7743 - val_loss: 1.9103 - val_accuracy: 0.4267\n",
            "Epoch 547/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.7714 - val_loss: 1.9042 - val_accuracy: 0.4467\n",
            "Epoch 548/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7814 - val_loss: 1.9065 - val_accuracy: 0.4500\n",
            "Epoch 549/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.7814 - val_loss: 1.9026 - val_accuracy: 0.4400\n",
            "Epoch 550/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.7729 - val_loss: 1.9046 - val_accuracy: 0.4333\n",
            "Epoch 551/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.7700 - val_loss: 1.9276 - val_accuracy: 0.4367\n",
            "Epoch 552/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.7829 - val_loss: 1.9076 - val_accuracy: 0.4500\n",
            "Epoch 553/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.7700 - val_loss: 1.9195 - val_accuracy: 0.4467\n",
            "Epoch 554/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.7786 - val_loss: 1.9037 - val_accuracy: 0.4400\n",
            "Epoch 555/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.7800 - val_loss: 1.9107 - val_accuracy: 0.4367\n",
            "Epoch 556/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.7714 - val_loss: 1.9279 - val_accuracy: 0.4233\n",
            "Epoch 557/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.7843 - val_loss: 1.9246 - val_accuracy: 0.4533\n",
            "Epoch 558/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.7800 - val_loss: 1.9186 - val_accuracy: 0.4433\n",
            "Epoch 559/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.7800 - val_loss: 1.9274 - val_accuracy: 0.4367\n",
            "Epoch 560/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.7786 - val_loss: 1.9360 - val_accuracy: 0.4267\n",
            "Epoch 561/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.7814 - val_loss: 1.9105 - val_accuracy: 0.4400\n",
            "Epoch 562/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.7786 - val_loss: 1.9430 - val_accuracy: 0.4400\n",
            "Epoch 563/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.7829 - val_loss: 1.9045 - val_accuracy: 0.4467\n",
            "Epoch 564/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.7857 - val_loss: 1.9327 - val_accuracy: 0.4367\n",
            "Epoch 565/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.7786 - val_loss: 1.9370 - val_accuracy: 0.4367\n",
            "Epoch 566/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.7814 - val_loss: 1.9413 - val_accuracy: 0.4233\n",
            "Epoch 567/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7900 - val_loss: 1.9650 - val_accuracy: 0.4267\n",
            "Epoch 568/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7771 - val_loss: 1.9287 - val_accuracy: 0.4433\n",
            "Epoch 569/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.7829 - val_loss: 1.9277 - val_accuracy: 0.4467\n",
            "Epoch 570/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7786 - val_loss: 1.9634 - val_accuracy: 0.4267\n",
            "Epoch 571/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.7857 - val_loss: 1.9208 - val_accuracy: 0.4400\n",
            "Epoch 572/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7871 - val_loss: 1.9309 - val_accuracy: 0.4467\n",
            "Epoch 573/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.7829 - val_loss: 1.9525 - val_accuracy: 0.4233\n",
            "Epoch 574/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.7843 - val_loss: 1.9563 - val_accuracy: 0.4200\n",
            "Epoch 575/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7857 - val_loss: 1.9474 - val_accuracy: 0.4433\n",
            "Epoch 576/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.7800 - val_loss: 1.9703 - val_accuracy: 0.4233\n",
            "Epoch 577/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.7843 - val_loss: 1.9774 - val_accuracy: 0.4300\n",
            "Epoch 578/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.7814 - val_loss: 1.9588 - val_accuracy: 0.4500\n",
            "Epoch 579/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.7900 - val_loss: 1.9383 - val_accuracy: 0.4433\n",
            "Epoch 580/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.7800 - val_loss: 1.9526 - val_accuracy: 0.4467\n",
            "Epoch 581/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.7914 - val_loss: 1.9368 - val_accuracy: 0.4467\n",
            "Epoch 582/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.7857 - val_loss: 1.9655 - val_accuracy: 0.4267\n",
            "Epoch 583/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7900 - val_loss: 1.9449 - val_accuracy: 0.4467\n",
            "Epoch 584/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.7829 - val_loss: 1.9498 - val_accuracy: 0.4533\n",
            "Epoch 585/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6338 - accuracy: 0.7871 - val_loss: 1.9480 - val_accuracy: 0.4400\n",
            "Epoch 586/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.7914 - val_loss: 1.9618 - val_accuracy: 0.4367\n",
            "Epoch 587/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.7886 - val_loss: 1.9655 - val_accuracy: 0.4400\n",
            "Epoch 588/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.7914 - val_loss: 1.9476 - val_accuracy: 0.4367\n",
            "Epoch 589/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.7871 - val_loss: 1.9796 - val_accuracy: 0.4367\n",
            "Epoch 590/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.7871 - val_loss: 1.9724 - val_accuracy: 0.4333\n",
            "Epoch 591/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.7857 - val_loss: 1.9859 - val_accuracy: 0.4333\n",
            "Epoch 592/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.7843 - val_loss: 1.9617 - val_accuracy: 0.4500\n",
            "Epoch 593/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.7871 - val_loss: 1.9451 - val_accuracy: 0.4400\n",
            "Epoch 594/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.7957 - val_loss: 1.9853 - val_accuracy: 0.4433\n",
            "Epoch 595/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.7900 - val_loss: 1.9822 - val_accuracy: 0.4267\n",
            "Epoch 596/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.7886 - val_loss: 1.9639 - val_accuracy: 0.4400\n",
            "Epoch 597/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.7943 - val_loss: 1.9542 - val_accuracy: 0.4433\n",
            "Epoch 598/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.7871 - val_loss: 1.9638 - val_accuracy: 0.4500\n",
            "Epoch 599/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.7886 - val_loss: 1.9451 - val_accuracy: 0.4533\n",
            "Epoch 600/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.7914 - val_loss: 1.9744 - val_accuracy: 0.4467\n",
            "Epoch 601/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.7886 - val_loss: 1.9748 - val_accuracy: 0.4367\n",
            "Epoch 602/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.7900 - val_loss: 1.9984 - val_accuracy: 0.4267\n",
            "Epoch 603/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.7900 - val_loss: 1.9795 - val_accuracy: 0.4400\n",
            "Epoch 604/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.7957 - val_loss: 1.9743 - val_accuracy: 0.4333\n",
            "Epoch 605/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.7929 - val_loss: 1.9833 - val_accuracy: 0.4433\n",
            "Epoch 606/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.7900 - val_loss: 2.0014 - val_accuracy: 0.4433\n",
            "Epoch 607/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.7871 - val_loss: 1.9890 - val_accuracy: 0.4500\n",
            "Epoch 608/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.7871 - val_loss: 1.9924 - val_accuracy: 0.4467\n",
            "Epoch 609/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.7971 - val_loss: 1.9975 - val_accuracy: 0.4367\n",
            "Epoch 610/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.7914 - val_loss: 1.9737 - val_accuracy: 0.4500\n",
            "Epoch 611/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.7971 - val_loss: 2.0201 - val_accuracy: 0.4367\n",
            "Epoch 612/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.7943 - val_loss: 2.0057 - val_accuracy: 0.4300\n",
            "Epoch 613/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.7857 - val_loss: 1.9854 - val_accuracy: 0.4433\n",
            "Epoch 614/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.7971 - val_loss: 1.9919 - val_accuracy: 0.4500\n",
            "Epoch 615/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.7943 - val_loss: 1.9937 - val_accuracy: 0.4467\n",
            "Epoch 616/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.7986 - val_loss: 1.9737 - val_accuracy: 0.4433\n",
            "Epoch 617/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7886 - val_loss: 2.0124 - val_accuracy: 0.4333\n",
            "Epoch 618/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.7957 - val_loss: 2.0013 - val_accuracy: 0.4467\n",
            "Epoch 619/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.8014 - val_loss: 2.0054 - val_accuracy: 0.4300\n",
            "Epoch 620/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.7971 - val_loss: 1.9936 - val_accuracy: 0.4433\n",
            "Epoch 621/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.7971 - val_loss: 1.9788 - val_accuracy: 0.4467\n",
            "Epoch 622/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7986 - val_loss: 2.0109 - val_accuracy: 0.4267\n",
            "Epoch 623/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.7971 - val_loss: 1.9931 - val_accuracy: 0.4500\n",
            "Epoch 624/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.8029 - val_loss: 2.0155 - val_accuracy: 0.4233\n",
            "Epoch 625/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.8000 - val_loss: 2.0166 - val_accuracy: 0.4533\n",
            "Epoch 626/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.7971 - val_loss: 2.0058 - val_accuracy: 0.4300\n",
            "Epoch 627/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7900 - val_loss: 2.0098 - val_accuracy: 0.4533\n",
            "Epoch 628/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.7929 - val_loss: 2.0285 - val_accuracy: 0.4233\n",
            "Epoch 629/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.7971 - val_loss: 1.9890 - val_accuracy: 0.4467\n",
            "Epoch 630/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.7986 - val_loss: 2.0375 - val_accuracy: 0.4200\n",
            "Epoch 631/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.7943 - val_loss: 2.0030 - val_accuracy: 0.4533\n",
            "Epoch 632/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.7971 - val_loss: 2.0290 - val_accuracy: 0.4267\n",
            "Epoch 633/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7914 - val_loss: 2.0073 - val_accuracy: 0.4500\n",
            "Epoch 634/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.7943 - val_loss: 2.0027 - val_accuracy: 0.4567\n",
            "Epoch 635/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7914 - val_loss: 2.0657 - val_accuracy: 0.4267\n",
            "Epoch 636/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.7986 - val_loss: 2.0089 - val_accuracy: 0.4467\n",
            "Epoch 637/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.7957 - val_loss: 2.0278 - val_accuracy: 0.4300\n",
            "Epoch 638/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.7957 - val_loss: 2.0211 - val_accuracy: 0.4533\n",
            "Epoch 639/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.8029 - val_loss: 2.0241 - val_accuracy: 0.4367\n",
            "Epoch 640/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7957 - val_loss: 2.0217 - val_accuracy: 0.4400\n",
            "Epoch 641/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6065 - accuracy: 0.8014 - val_loss: 2.0379 - val_accuracy: 0.4467\n",
            "Epoch 642/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.7943 - val_loss: 2.0331 - val_accuracy: 0.4367\n",
            "Epoch 643/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.8000 - val_loss: 2.0290 - val_accuracy: 0.4433\n",
            "Epoch 644/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6058 - accuracy: 0.8014 - val_loss: 2.0283 - val_accuracy: 0.4333\n",
            "Epoch 645/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.7943 - val_loss: 2.0269 - val_accuracy: 0.4300\n",
            "Epoch 646/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.7971 - val_loss: 2.0057 - val_accuracy: 0.4433\n",
            "Epoch 647/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.7971 - val_loss: 2.0313 - val_accuracy: 0.4300\n",
            "Epoch 648/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.8071 - val_loss: 2.0117 - val_accuracy: 0.4333\n",
            "Epoch 649/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.7957 - val_loss: 2.0148 - val_accuracy: 0.4367\n",
            "Epoch 650/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.8014 - val_loss: 2.0385 - val_accuracy: 0.4267\n",
            "Epoch 651/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.8029 - val_loss: 2.0720 - val_accuracy: 0.4233\n",
            "Epoch 652/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.8000 - val_loss: 2.0384 - val_accuracy: 0.4233\n",
            "Epoch 653/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.8000 - val_loss: 2.0210 - val_accuracy: 0.4567\n",
            "Epoch 654/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.8014 - val_loss: 2.0473 - val_accuracy: 0.4300\n",
            "Epoch 655/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.8114 - val_loss: 2.0664 - val_accuracy: 0.4267\n",
            "Epoch 656/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.7971 - val_loss: 2.0205 - val_accuracy: 0.4533\n",
            "Epoch 657/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.7971 - val_loss: 2.0490 - val_accuracy: 0.4300\n",
            "Epoch 658/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7943 - val_loss: 2.0677 - val_accuracy: 0.4233\n",
            "Epoch 659/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.8086 - val_loss: 2.0470 - val_accuracy: 0.4567\n",
            "Epoch 660/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.8143 - val_loss: 2.0598 - val_accuracy: 0.4267\n",
            "Epoch 661/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.8071 - val_loss: 2.0741 - val_accuracy: 0.4233\n",
            "Epoch 662/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.8043 - val_loss: 2.0497 - val_accuracy: 0.4400\n",
            "Epoch 663/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.5984 - accuracy: 0.8057 - val_loss: 2.0418 - val_accuracy: 0.4367\n",
            "Epoch 664/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7986 - val_loss: 2.0390 - val_accuracy: 0.4467\n",
            "Epoch 665/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.8071 - val_loss: 2.0660 - val_accuracy: 0.4233\n",
            "Epoch 666/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.7971 - val_loss: 2.0813 - val_accuracy: 0.4267\n",
            "Epoch 667/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.7971 - val_loss: 2.0647 - val_accuracy: 0.4300\n",
            "Epoch 668/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.8014 - val_loss: 2.0518 - val_accuracy: 0.4433\n",
            "Epoch 669/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.8014 - val_loss: 2.0476 - val_accuracy: 0.4567\n",
            "Epoch 670/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.8114 - val_loss: 2.0736 - val_accuracy: 0.4300\n",
            "Epoch 671/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.8000 - val_loss: 2.0563 - val_accuracy: 0.4367\n",
            "Epoch 672/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.8057 - val_loss: 2.0321 - val_accuracy: 0.4467\n",
            "Epoch 673/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.8043 - val_loss: 2.0618 - val_accuracy: 0.4400\n",
            "Epoch 674/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.8086 - val_loss: 2.0693 - val_accuracy: 0.4367\n",
            "Epoch 675/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.8129 - val_loss: 2.0554 - val_accuracy: 0.4367\n",
            "Epoch 676/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.8086 - val_loss: 2.0772 - val_accuracy: 0.4400\n",
            "Epoch 677/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.8057 - val_loss: 2.0783 - val_accuracy: 0.4400\n",
            "Epoch 678/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.8071 - val_loss: 2.0703 - val_accuracy: 0.4300\n",
            "Epoch 679/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.8071 - val_loss: 2.0892 - val_accuracy: 0.4367\n",
            "Epoch 680/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.8043 - val_loss: 2.0986 - val_accuracy: 0.4400\n",
            "Epoch 681/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.8071 - val_loss: 2.0663 - val_accuracy: 0.4433\n",
            "Epoch 682/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.8157 - val_loss: 2.0871 - val_accuracy: 0.4367\n",
            "Epoch 683/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.8129 - val_loss: 2.0859 - val_accuracy: 0.4367\n",
            "Epoch 684/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.8100 - val_loss: 2.1278 - val_accuracy: 0.4167\n",
            "Epoch 685/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.8100 - val_loss: 2.0639 - val_accuracy: 0.4600\n",
            "Epoch 686/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.8157 - val_loss: 2.0689 - val_accuracy: 0.4500\n",
            "Epoch 687/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.8071 - val_loss: 2.0981 - val_accuracy: 0.4367\n",
            "Epoch 688/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.8129 - val_loss: 2.0766 - val_accuracy: 0.4367\n",
            "Epoch 689/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.8014 - val_loss: 2.1015 - val_accuracy: 0.4433\n",
            "Epoch 690/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.8086 - val_loss: 2.0967 - val_accuracy: 0.4333\n",
            "Epoch 691/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.8114 - val_loss: 2.0894 - val_accuracy: 0.4300\n",
            "Epoch 692/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.8171 - val_loss: 2.0948 - val_accuracy: 0.4467\n",
            "Epoch 693/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.8143 - val_loss: 2.0594 - val_accuracy: 0.4367\n",
            "Epoch 694/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.8100 - val_loss: 2.0649 - val_accuracy: 0.4567\n",
            "Epoch 695/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.8014 - val_loss: 2.1111 - val_accuracy: 0.4400\n",
            "Epoch 696/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.8086 - val_loss: 2.0863 - val_accuracy: 0.4433\n",
            "Epoch 697/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.8129 - val_loss: 2.0941 - val_accuracy: 0.4233\n",
            "Epoch 698/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.8086 - val_loss: 2.1258 - val_accuracy: 0.4367\n",
            "Epoch 699/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.8086 - val_loss: 2.0930 - val_accuracy: 0.4467\n",
            "Epoch 700/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.8100 - val_loss: 2.1001 - val_accuracy: 0.4400\n",
            "Epoch 701/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.8214 - val_loss: 2.1025 - val_accuracy: 0.4333\n",
            "Epoch 702/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.8129 - val_loss: 2.0720 - val_accuracy: 0.4500\n",
            "Epoch 703/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.8100 - val_loss: 2.0868 - val_accuracy: 0.4467\n",
            "Epoch 704/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.8186 - val_loss: 2.0821 - val_accuracy: 0.4500\n",
            "Epoch 705/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.8171 - val_loss: 2.1199 - val_accuracy: 0.4433\n",
            "Epoch 706/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.8129 - val_loss: 2.0869 - val_accuracy: 0.4467\n",
            "Epoch 707/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.8086 - val_loss: 2.0926 - val_accuracy: 0.4533\n",
            "Epoch 708/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.8171 - val_loss: 2.0865 - val_accuracy: 0.4400\n",
            "Epoch 709/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.8100 - val_loss: 2.1250 - val_accuracy: 0.4433\n",
            "Epoch 710/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.8086 - val_loss: 2.1151 - val_accuracy: 0.4400\n",
            "Epoch 711/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.8143 - val_loss: 2.1281 - val_accuracy: 0.4500\n",
            "Epoch 712/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.8143 - val_loss: 2.1282 - val_accuracy: 0.4367\n",
            "Epoch 713/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.8186 - val_loss: 2.1354 - val_accuracy: 0.4400\n",
            "Epoch 714/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.8214 - val_loss: 2.1293 - val_accuracy: 0.4367\n",
            "Epoch 715/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.8114 - val_loss: 2.1312 - val_accuracy: 0.4433\n",
            "Epoch 716/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.8200 - val_loss: 2.1163 - val_accuracy: 0.4367\n",
            "Epoch 717/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.8171 - val_loss: 2.1212 - val_accuracy: 0.4400\n",
            "Epoch 718/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.8100 - val_loss: 2.1190 - val_accuracy: 0.4467\n",
            "Epoch 719/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.8143 - val_loss: 2.1157 - val_accuracy: 0.4400\n",
            "Epoch 720/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.8086 - val_loss: 2.1132 - val_accuracy: 0.4367\n",
            "Epoch 721/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.8143 - val_loss: 2.1242 - val_accuracy: 0.4433\n",
            "Epoch 722/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.8129 - val_loss: 2.1125 - val_accuracy: 0.4400\n",
            "Epoch 723/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.8100 - val_loss: 2.1251 - val_accuracy: 0.4433\n",
            "Epoch 724/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.8129 - val_loss: 2.1265 - val_accuracy: 0.4467\n",
            "Epoch 725/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.8171 - val_loss: 2.1206 - val_accuracy: 0.4433\n",
            "Epoch 726/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.8186 - val_loss: 2.1148 - val_accuracy: 0.4433\n",
            "Epoch 727/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.8100 - val_loss: 2.1283 - val_accuracy: 0.4233\n",
            "Epoch 728/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.8171 - val_loss: 2.1626 - val_accuracy: 0.4367\n",
            "Epoch 729/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.8143 - val_loss: 2.1183 - val_accuracy: 0.4433\n",
            "Epoch 730/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.8229 - val_loss: 2.1105 - val_accuracy: 0.4467\n",
            "Epoch 731/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.8143 - val_loss: 2.1504 - val_accuracy: 0.4333\n",
            "Epoch 732/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.8143 - val_loss: 2.1734 - val_accuracy: 0.4267\n",
            "Epoch 733/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.8186 - val_loss: 2.1216 - val_accuracy: 0.4500\n",
            "Epoch 734/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.8157 - val_loss: 2.1220 - val_accuracy: 0.4433\n",
            "Epoch 735/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.8157 - val_loss: 2.1569 - val_accuracy: 0.4500\n",
            "Epoch 736/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.8257 - val_loss: 2.1256 - val_accuracy: 0.4400\n",
            "Epoch 737/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.8157 - val_loss: 2.1582 - val_accuracy: 0.4433\n",
            "Epoch 738/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.8157 - val_loss: 2.1498 - val_accuracy: 0.4533\n",
            "Epoch 739/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.8157 - val_loss: 2.1173 - val_accuracy: 0.4567\n",
            "Epoch 740/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.8143 - val_loss: 2.1545 - val_accuracy: 0.4400\n",
            "Epoch 741/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.8171 - val_loss: 2.1382 - val_accuracy: 0.4367\n",
            "Epoch 742/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.8157 - val_loss: 2.1603 - val_accuracy: 0.4433\n",
            "Epoch 743/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.8200 - val_loss: 2.1781 - val_accuracy: 0.4333\n",
            "Epoch 744/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.8186 - val_loss: 2.1542 - val_accuracy: 0.4500\n",
            "Epoch 745/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.8171 - val_loss: 2.1344 - val_accuracy: 0.4333\n",
            "Epoch 746/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.8143 - val_loss: 2.1451 - val_accuracy: 0.4467\n",
            "Epoch 747/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.8143 - val_loss: 2.1684 - val_accuracy: 0.4367\n",
            "Epoch 748/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.8271 - val_loss: 2.1403 - val_accuracy: 0.4433\n",
            "Epoch 749/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.8086 - val_loss: 2.2037 - val_accuracy: 0.4367\n",
            "Epoch 750/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.8171 - val_loss: 2.1485 - val_accuracy: 0.4333\n",
            "Epoch 751/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.8214 - val_loss: 2.1622 - val_accuracy: 0.4433\n",
            "Epoch 752/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.8257 - val_loss: 2.1554 - val_accuracy: 0.4167\n",
            "Epoch 753/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.8214 - val_loss: 2.1809 - val_accuracy: 0.4333\n",
            "Epoch 754/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.8186 - val_loss: 2.1761 - val_accuracy: 0.4433\n",
            "Epoch 755/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.8157 - val_loss: 2.1737 - val_accuracy: 0.4300\n",
            "Epoch 756/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.8243 - val_loss: 2.1778 - val_accuracy: 0.4433\n",
            "Epoch 757/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.8171 - val_loss: 2.1884 - val_accuracy: 0.4433\n",
            "Epoch 758/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.8243 - val_loss: 2.1630 - val_accuracy: 0.4267\n",
            "Epoch 759/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.8257 - val_loss: 2.1776 - val_accuracy: 0.4367\n",
            "Epoch 760/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.8214 - val_loss: 2.1620 - val_accuracy: 0.4433\n",
            "Epoch 761/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.8214 - val_loss: 2.2042 - val_accuracy: 0.4400\n",
            "Epoch 762/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.8086 - val_loss: 2.1866 - val_accuracy: 0.4467\n",
            "Epoch 763/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.8171 - val_loss: 2.1890 - val_accuracy: 0.4467\n",
            "Epoch 764/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.8214 - val_loss: 2.2004 - val_accuracy: 0.4533\n",
            "Epoch 765/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.8186 - val_loss: 2.1868 - val_accuracy: 0.4367\n",
            "Epoch 766/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.8257 - val_loss: 2.1847 - val_accuracy: 0.4467\n",
            "Epoch 767/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.8200 - val_loss: 2.1784 - val_accuracy: 0.4300\n",
            "Epoch 768/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.8171 - val_loss: 2.2103 - val_accuracy: 0.4433\n",
            "Epoch 769/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.8243 - val_loss: 2.2074 - val_accuracy: 0.4400\n",
            "Epoch 770/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.8271 - val_loss: 2.2179 - val_accuracy: 0.4500\n",
            "Epoch 771/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.8186 - val_loss: 2.2335 - val_accuracy: 0.4333\n",
            "Epoch 772/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.8243 - val_loss: 2.1873 - val_accuracy: 0.4400\n",
            "Epoch 773/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.8214 - val_loss: 2.2137 - val_accuracy: 0.4433\n",
            "Epoch 774/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.8229 - val_loss: 2.2140 - val_accuracy: 0.4400\n",
            "Epoch 775/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.8229 - val_loss: 2.1759 - val_accuracy: 0.4500\n",
            "Epoch 776/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.8314 - val_loss: 2.2208 - val_accuracy: 0.4467\n",
            "Epoch 777/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.8229 - val_loss: 2.2268 - val_accuracy: 0.4433\n",
            "Epoch 778/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.8229 - val_loss: 2.2060 - val_accuracy: 0.4467\n",
            "Epoch 779/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.8214 - val_loss: 2.2092 - val_accuracy: 0.4400\n",
            "Epoch 780/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.8300 - val_loss: 2.2560 - val_accuracy: 0.4533\n",
            "Epoch 781/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.8300 - val_loss: 2.2289 - val_accuracy: 0.4367\n",
            "Epoch 782/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.8200 - val_loss: 2.2042 - val_accuracy: 0.4433\n",
            "Epoch 783/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.8214 - val_loss: 2.2242 - val_accuracy: 0.4533\n",
            "Epoch 784/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.8329 - val_loss: 2.2274 - val_accuracy: 0.4433\n",
            "Epoch 785/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.8314 - val_loss: 2.2602 - val_accuracy: 0.4400\n",
            "Epoch 786/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.8314 - val_loss: 2.2128 - val_accuracy: 0.4333\n",
            "Epoch 787/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.8229 - val_loss: 2.2749 - val_accuracy: 0.4433\n",
            "Epoch 788/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.8257 - val_loss: 2.1931 - val_accuracy: 0.4367\n",
            "Epoch 789/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.8300 - val_loss: 2.2210 - val_accuracy: 0.4533\n",
            "Epoch 790/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.8329 - val_loss: 2.2316 - val_accuracy: 0.4533\n",
            "Epoch 791/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.8329 - val_loss: 2.2065 - val_accuracy: 0.4500\n",
            "Epoch 792/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.8329 - val_loss: 2.2089 - val_accuracy: 0.4433\n",
            "Epoch 793/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.8286 - val_loss: 2.2052 - val_accuracy: 0.4433\n",
            "Epoch 794/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.8271 - val_loss: 2.2288 - val_accuracy: 0.4367\n",
            "Epoch 795/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.8286 - val_loss: 2.2347 - val_accuracy: 0.4467\n",
            "Epoch 796/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.8314 - val_loss: 2.2244 - val_accuracy: 0.4467\n",
            "Epoch 797/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.8357 - val_loss: 2.2237 - val_accuracy: 0.4400\n",
            "Epoch 798/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.8343 - val_loss: 2.2278 - val_accuracy: 0.4433\n",
            "Epoch 799/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.8343 - val_loss: 2.2379 - val_accuracy: 0.4400\n",
            "Epoch 800/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.8271 - val_loss: 2.2466 - val_accuracy: 0.4533\n",
            "Epoch 801/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.8286 - val_loss: 2.2605 - val_accuracy: 0.4500\n",
            "Epoch 802/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.8343 - val_loss: 2.2359 - val_accuracy: 0.4467\n",
            "Epoch 803/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.8386 - val_loss: 2.2349 - val_accuracy: 0.4367\n",
            "Epoch 804/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.8271 - val_loss: 2.2351 - val_accuracy: 0.4500\n",
            "Epoch 805/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.8271 - val_loss: 2.2461 - val_accuracy: 0.4433\n",
            "Epoch 806/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.8271 - val_loss: 2.2375 - val_accuracy: 0.4467\n",
            "Epoch 807/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.8314 - val_loss: 2.2611 - val_accuracy: 0.4500\n",
            "Epoch 808/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.8329 - val_loss: 2.2591 - val_accuracy: 0.4467\n",
            "Epoch 809/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.8329 - val_loss: 2.2478 - val_accuracy: 0.4467\n",
            "Epoch 810/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.8257 - val_loss: 2.2581 - val_accuracy: 0.4467\n",
            "Epoch 811/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.8314 - val_loss: 2.2689 - val_accuracy: 0.4500\n",
            "Epoch 812/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.8357 - val_loss: 2.2484 - val_accuracy: 0.4467\n",
            "Epoch 813/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.8329 - val_loss: 2.2568 - val_accuracy: 0.4367\n",
            "Epoch 814/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.8271 - val_loss: 2.2742 - val_accuracy: 0.4400\n",
            "Epoch 815/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.8329 - val_loss: 2.2514 - val_accuracy: 0.4467\n",
            "Epoch 816/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.8357 - val_loss: 2.2454 - val_accuracy: 0.4467\n",
            "Epoch 817/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.8343 - val_loss: 2.2537 - val_accuracy: 0.4500\n",
            "Epoch 818/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.8386 - val_loss: 2.2460 - val_accuracy: 0.4567\n",
            "Epoch 819/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.8300 - val_loss: 2.2830 - val_accuracy: 0.4433\n",
            "Epoch 820/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.8400 - val_loss: 2.2826 - val_accuracy: 0.4433\n",
            "Epoch 821/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.8400 - val_loss: 2.2686 - val_accuracy: 0.4567\n",
            "Epoch 822/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.8386 - val_loss: 2.2407 - val_accuracy: 0.4300\n",
            "Epoch 823/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.8343 - val_loss: 2.2383 - val_accuracy: 0.4467\n",
            "Epoch 824/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.8357 - val_loss: 2.2802 - val_accuracy: 0.4500\n",
            "Epoch 825/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.8271 - val_loss: 2.2609 - val_accuracy: 0.4433\n",
            "Epoch 826/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.8400 - val_loss: 2.2857 - val_accuracy: 0.4333\n",
            "Epoch 827/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.8414 - val_loss: 2.2833 - val_accuracy: 0.4467\n",
            "Epoch 828/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.8386 - val_loss: 2.2944 - val_accuracy: 0.4500\n",
            "Epoch 829/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.8329 - val_loss: 2.2863 - val_accuracy: 0.4567\n",
            "Epoch 830/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.8471 - val_loss: 2.3170 - val_accuracy: 0.4300\n",
            "Epoch 831/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.8357 - val_loss: 2.2689 - val_accuracy: 0.4400\n",
            "Epoch 832/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.8371 - val_loss: 2.2784 - val_accuracy: 0.4467\n",
            "Epoch 833/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.8343 - val_loss: 2.2712 - val_accuracy: 0.4400\n",
            "Epoch 834/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.8371 - val_loss: 2.2920 - val_accuracy: 0.4433\n",
            "Epoch 835/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.8414 - val_loss: 2.3057 - val_accuracy: 0.4533\n",
            "Epoch 836/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8271 - val_loss: 2.3049 - val_accuracy: 0.4400\n",
            "Epoch 837/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.8357 - val_loss: 2.2969 - val_accuracy: 0.4433\n",
            "Epoch 838/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8400 - val_loss: 2.3186 - val_accuracy: 0.4333\n",
            "Epoch 839/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.8371 - val_loss: 2.2972 - val_accuracy: 0.4467\n",
            "Epoch 840/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.5332 - accuracy: 0.8371 - val_loss: 2.2947 - val_accuracy: 0.4433\n",
            "Epoch 841/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.8343 - val_loss: 2.3143 - val_accuracy: 0.4333\n",
            "Epoch 842/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.8371 - val_loss: 2.3053 - val_accuracy: 0.4400\n",
            "Epoch 843/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.8343 - val_loss: 2.2753 - val_accuracy: 0.4500\n",
            "Epoch 844/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.8357 - val_loss: 2.2831 - val_accuracy: 0.4367\n",
            "Epoch 845/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.8300 - val_loss: 2.2737 - val_accuracy: 0.4433\n",
            "Epoch 846/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.8414 - val_loss: 2.2910 - val_accuracy: 0.4433\n",
            "Epoch 847/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.8386 - val_loss: 2.3126 - val_accuracy: 0.4500\n",
            "Epoch 848/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.8329 - val_loss: 2.3236 - val_accuracy: 0.4533\n",
            "Epoch 849/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.8386 - val_loss: 2.3293 - val_accuracy: 0.4400\n",
            "Epoch 850/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.8414 - val_loss: 2.3395 - val_accuracy: 0.4433\n",
            "Epoch 851/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.8286 - val_loss: 2.3087 - val_accuracy: 0.4467\n",
            "Epoch 852/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.8386 - val_loss: 2.3128 - val_accuracy: 0.4300\n",
            "Epoch 853/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.8429 - val_loss: 2.2987 - val_accuracy: 0.4533\n",
            "Epoch 854/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.8414 - val_loss: 2.3122 - val_accuracy: 0.4367\n",
            "Epoch 855/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.8357 - val_loss: 2.3379 - val_accuracy: 0.4367\n",
            "Epoch 856/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.8371 - val_loss: 2.3426 - val_accuracy: 0.4333\n",
            "Epoch 857/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.8386 - val_loss: 2.2953 - val_accuracy: 0.4400\n",
            "Epoch 858/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.8343 - val_loss: 2.3265 - val_accuracy: 0.4333\n",
            "Epoch 859/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.8371 - val_loss: 2.3215 - val_accuracy: 0.4333\n",
            "Epoch 860/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.8429 - val_loss: 2.3303 - val_accuracy: 0.4467\n",
            "Epoch 861/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.8371 - val_loss: 2.3408 - val_accuracy: 0.4500\n",
            "Epoch 862/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.8343 - val_loss: 2.3252 - val_accuracy: 0.4467\n",
            "Epoch 863/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.8357 - val_loss: 2.3156 - val_accuracy: 0.4600\n",
            "Epoch 864/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.8457 - val_loss: 2.3480 - val_accuracy: 0.4400\n",
            "Epoch 865/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.8443 - val_loss: 2.3024 - val_accuracy: 0.4433\n",
            "Epoch 866/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.8429 - val_loss: 2.3202 - val_accuracy: 0.4567\n",
            "Epoch 867/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.8414 - val_loss: 2.3274 - val_accuracy: 0.4533\n",
            "Epoch 868/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.8429 - val_loss: 2.3664 - val_accuracy: 0.4400\n",
            "Epoch 869/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.8414 - val_loss: 2.3321 - val_accuracy: 0.4400\n",
            "Epoch 870/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.8414 - val_loss: 2.3161 - val_accuracy: 0.4567\n",
            "Epoch 871/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.8414 - val_loss: 2.3095 - val_accuracy: 0.4500\n",
            "Epoch 872/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.8400 - val_loss: 2.3423 - val_accuracy: 0.4533\n",
            "Epoch 873/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.8400 - val_loss: 2.3085 - val_accuracy: 0.4467\n",
            "Epoch 874/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.8343 - val_loss: 2.3243 - val_accuracy: 0.4467\n",
            "Epoch 875/1000\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.8386 - val_loss: 2.3567 - val_accuracy: 0.4400\n",
            "Epoch 876/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.8400 - val_loss: 2.3660 - val_accuracy: 0.4400\n",
            "Epoch 877/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.8486 - val_loss: 2.3666 - val_accuracy: 0.4367\n",
            "Epoch 878/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.8429 - val_loss: 2.3627 - val_accuracy: 0.4367\n",
            "Epoch 879/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.8457 - val_loss: 2.3268 - val_accuracy: 0.4533\n",
            "Epoch 880/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.8414 - val_loss: 2.3136 - val_accuracy: 0.4433\n",
            "Epoch 881/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.8443 - val_loss: 2.3609 - val_accuracy: 0.4467\n",
            "Epoch 882/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.8414 - val_loss: 2.3584 - val_accuracy: 0.4467\n",
            "Epoch 883/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.8414 - val_loss: 2.3874 - val_accuracy: 0.4400\n",
            "Epoch 884/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.8471 - val_loss: 2.3649 - val_accuracy: 0.4467\n",
            "Epoch 885/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.8443 - val_loss: 2.3480 - val_accuracy: 0.4300\n",
            "Epoch 886/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.8414 - val_loss: 2.3658 - val_accuracy: 0.4333\n",
            "Epoch 887/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.8443 - val_loss: 2.3666 - val_accuracy: 0.4500\n",
            "Epoch 888/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.8443 - val_loss: 2.3492 - val_accuracy: 0.4533\n",
            "Epoch 889/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.8500 - val_loss: 2.3545 - val_accuracy: 0.4467\n",
            "Epoch 890/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.8457 - val_loss: 2.3843 - val_accuracy: 0.4467\n",
            "Epoch 891/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.8414 - val_loss: 2.3660 - val_accuracy: 0.4333\n",
            "Epoch 892/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.8457 - val_loss: 2.3522 - val_accuracy: 0.4633\n",
            "Epoch 893/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.8471 - val_loss: 2.3632 - val_accuracy: 0.4367\n",
            "Epoch 894/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.8486 - val_loss: 2.4059 - val_accuracy: 0.4300\n",
            "Epoch 895/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.8500 - val_loss: 2.3878 - val_accuracy: 0.4467\n",
            "Epoch 896/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.8471 - val_loss: 2.3747 - val_accuracy: 0.4533\n",
            "Epoch 897/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.8457 - val_loss: 2.4081 - val_accuracy: 0.4400\n",
            "Epoch 898/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.8371 - val_loss: 2.3603 - val_accuracy: 0.4433\n",
            "Epoch 899/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.8414 - val_loss: 2.3971 - val_accuracy: 0.4467\n",
            "Epoch 900/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.8486 - val_loss: 2.3737 - val_accuracy: 0.4400\n",
            "Epoch 901/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.8514 - val_loss: 2.4143 - val_accuracy: 0.4400\n",
            "Epoch 902/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.8443 - val_loss: 2.3703 - val_accuracy: 0.4467\n",
            "Epoch 903/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.8514 - val_loss: 2.4144 - val_accuracy: 0.4300\n",
            "Epoch 904/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.8443 - val_loss: 2.4015 - val_accuracy: 0.4367\n",
            "Epoch 905/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.8486 - val_loss: 2.3823 - val_accuracy: 0.4433\n",
            "Epoch 906/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.8529 - val_loss: 2.3789 - val_accuracy: 0.4433\n",
            "Epoch 907/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.8529 - val_loss: 2.3929 - val_accuracy: 0.4433\n",
            "Epoch 908/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.8471 - val_loss: 2.3954 - val_accuracy: 0.4367\n",
            "Epoch 909/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.8529 - val_loss: 2.4183 - val_accuracy: 0.4400\n",
            "Epoch 910/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.8443 - val_loss: 2.3996 - val_accuracy: 0.4400\n",
            "Epoch 911/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.8443 - val_loss: 2.4294 - val_accuracy: 0.4367\n",
            "Epoch 912/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.8471 - val_loss: 2.4129 - val_accuracy: 0.4367\n",
            "Epoch 913/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.8529 - val_loss: 2.4331 - val_accuracy: 0.4433\n",
            "Epoch 914/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.8443 - val_loss: 2.4054 - val_accuracy: 0.4433\n",
            "Epoch 915/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.8500 - val_loss: 2.4163 - val_accuracy: 0.4533\n",
            "Epoch 916/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.8400 - val_loss: 2.4143 - val_accuracy: 0.4367\n",
            "Epoch 917/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.8514 - val_loss: 2.4149 - val_accuracy: 0.4567\n",
            "Epoch 918/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.8557 - val_loss: 2.4223 - val_accuracy: 0.4367\n",
            "Epoch 919/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.8500 - val_loss: 2.4033 - val_accuracy: 0.4533\n",
            "Epoch 920/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.8386 - val_loss: 2.4115 - val_accuracy: 0.4367\n",
            "Epoch 921/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.8457 - val_loss: 2.4209 - val_accuracy: 0.4433\n",
            "Epoch 922/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.8500 - val_loss: 2.4215 - val_accuracy: 0.4467\n",
            "Epoch 923/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.8514 - val_loss: 2.4297 - val_accuracy: 0.4367\n",
            "Epoch 924/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.8543 - val_loss: 2.4244 - val_accuracy: 0.4333\n",
            "Epoch 925/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.8486 - val_loss: 2.4051 - val_accuracy: 0.4533\n",
            "Epoch 926/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.8471 - val_loss: 2.4027 - val_accuracy: 0.4533\n",
            "Epoch 927/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.8529 - val_loss: 2.4100 - val_accuracy: 0.4367\n",
            "Epoch 928/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.8500 - val_loss: 2.3953 - val_accuracy: 0.4633\n",
            "Epoch 929/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.8443 - val_loss: 2.4166 - val_accuracy: 0.4533\n",
            "Epoch 930/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.8429 - val_loss: 2.4224 - val_accuracy: 0.4367\n",
            "Epoch 931/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.8500 - val_loss: 2.4479 - val_accuracy: 0.4433\n",
            "Epoch 932/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.8571 - val_loss: 2.4323 - val_accuracy: 0.4367\n",
            "Epoch 933/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.8471 - val_loss: 2.4097 - val_accuracy: 0.4333\n",
            "Epoch 934/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.8543 - val_loss: 2.4528 - val_accuracy: 0.4300\n",
            "Epoch 935/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8486 - val_loss: 2.4552 - val_accuracy: 0.4333\n",
            "Epoch 936/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.8429 - val_loss: 2.4456 - val_accuracy: 0.4333\n",
            "Epoch 937/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.8486 - val_loss: 2.4190 - val_accuracy: 0.4367\n",
            "Epoch 938/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.8486 - val_loss: 2.4560 - val_accuracy: 0.4367\n",
            "Epoch 939/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.8443 - val_loss: 2.4762 - val_accuracy: 0.4400\n",
            "Epoch 940/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.8429 - val_loss: 2.4290 - val_accuracy: 0.4533\n",
            "Epoch 941/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.8486 - val_loss: 2.4522 - val_accuracy: 0.4400\n",
            "Epoch 942/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.8443 - val_loss: 2.4206 - val_accuracy: 0.4467\n",
            "Epoch 943/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.8543 - val_loss: 2.4433 - val_accuracy: 0.4467\n",
            "Epoch 944/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.8457 - val_loss: 2.4278 - val_accuracy: 0.4400\n",
            "Epoch 945/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.8529 - val_loss: 2.4707 - val_accuracy: 0.4600\n",
            "Epoch 946/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.8543 - val_loss: 2.4785 - val_accuracy: 0.4333\n",
            "Epoch 947/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.8529 - val_loss: 2.4554 - val_accuracy: 0.4333\n",
            "Epoch 948/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.8500 - val_loss: 2.4762 - val_accuracy: 0.4333\n",
            "Epoch 949/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.8571 - val_loss: 2.4520 - val_accuracy: 0.4433\n",
            "Epoch 950/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.8529 - val_loss: 2.4726 - val_accuracy: 0.4433\n",
            "Epoch 951/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.8514 - val_loss: 2.4604 - val_accuracy: 0.4567\n",
            "Epoch 952/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8529 - val_loss: 2.4778 - val_accuracy: 0.4367\n",
            "Epoch 953/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.8529 - val_loss: 2.4408 - val_accuracy: 0.4567\n",
            "Epoch 954/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8543 - val_loss: 2.4696 - val_accuracy: 0.4333\n",
            "Epoch 955/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.8543 - val_loss: 2.4510 - val_accuracy: 0.4333\n",
            "Epoch 956/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.8514 - val_loss: 2.4423 - val_accuracy: 0.4567\n",
            "Epoch 957/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.8514 - val_loss: 2.4784 - val_accuracy: 0.4433\n",
            "Epoch 958/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.8557 - val_loss: 2.4475 - val_accuracy: 0.4433\n",
            "Epoch 959/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.8529 - val_loss: 2.4882 - val_accuracy: 0.4367\n",
            "Epoch 960/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.8543 - val_loss: 2.4539 - val_accuracy: 0.4700\n",
            "Epoch 961/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.8514 - val_loss: 2.4879 - val_accuracy: 0.4300\n",
            "Epoch 962/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.8514 - val_loss: 2.4898 - val_accuracy: 0.4400\n",
            "Epoch 963/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.8514 - val_loss: 2.4829 - val_accuracy: 0.4367\n",
            "Epoch 964/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.8586 - val_loss: 2.4974 - val_accuracy: 0.4433\n",
            "Epoch 965/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.8529 - val_loss: 2.4924 - val_accuracy: 0.4367\n",
            "Epoch 966/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.8600 - val_loss: 2.4670 - val_accuracy: 0.4367\n",
            "Epoch 967/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.8557 - val_loss: 2.4655 - val_accuracy: 0.4400\n",
            "Epoch 968/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.8571 - val_loss: 2.4949 - val_accuracy: 0.4367\n",
            "Epoch 969/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.8500 - val_loss: 2.4761 - val_accuracy: 0.4333\n",
            "Epoch 970/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.8571 - val_loss: 2.4734 - val_accuracy: 0.4433\n",
            "Epoch 971/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.8557 - val_loss: 2.4879 - val_accuracy: 0.4500\n",
            "Epoch 972/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.8543 - val_loss: 2.4744 - val_accuracy: 0.4533\n",
            "Epoch 973/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.8557 - val_loss: 2.4984 - val_accuracy: 0.4367\n",
            "Epoch 974/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.8557 - val_loss: 2.4752 - val_accuracy: 0.4467\n",
            "Epoch 975/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.8529 - val_loss: 2.4557 - val_accuracy: 0.4333\n",
            "Epoch 976/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.8543 - val_loss: 2.5259 - val_accuracy: 0.4333\n",
            "Epoch 977/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.8571 - val_loss: 2.4837 - val_accuracy: 0.4500\n",
            "Epoch 978/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.8529 - val_loss: 2.4702 - val_accuracy: 0.4500\n",
            "Epoch 979/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.8557 - val_loss: 2.5176 - val_accuracy: 0.4367\n",
            "Epoch 980/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.8543 - val_loss: 2.4863 - val_accuracy: 0.4433\n",
            "Epoch 981/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.8543 - val_loss: 2.4831 - val_accuracy: 0.4367\n",
            "Epoch 982/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.8571 - val_loss: 2.4960 - val_accuracy: 0.4367\n",
            "Epoch 983/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.8557 - val_loss: 2.5215 - val_accuracy: 0.4433\n",
            "Epoch 984/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.8514 - val_loss: 2.4682 - val_accuracy: 0.4400\n",
            "Epoch 985/1000\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.8600 - val_loss: 2.5002 - val_accuracy: 0.4400\n",
            "Epoch 986/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.8500 - val_loss: 2.5158 - val_accuracy: 0.4333\n",
            "Epoch 987/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.8543 - val_loss: 2.5070 - val_accuracy: 0.4467\n",
            "Epoch 988/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.8529 - val_loss: 2.4939 - val_accuracy: 0.4300\n",
            "Epoch 989/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.8557 - val_loss: 2.5215 - val_accuracy: 0.4267\n",
            "Epoch 990/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.8557 - val_loss: 2.5185 - val_accuracy: 0.4300\n",
            "Epoch 991/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.8557 - val_loss: 2.5097 - val_accuracy: 0.4333\n",
            "Epoch 992/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.8557 - val_loss: 2.5190 - val_accuracy: 0.4433\n",
            "Epoch 993/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.8543 - val_loss: 2.5125 - val_accuracy: 0.4567\n",
            "Epoch 994/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.8557 - val_loss: 2.5000 - val_accuracy: 0.4333\n",
            "Epoch 995/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.8557 - val_loss: 2.5271 - val_accuracy: 0.4300\n",
            "Epoch 996/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.8600 - val_loss: 2.5299 - val_accuracy: 0.4433\n",
            "Epoch 997/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.8471 - val_loss: 2.5189 - val_accuracy: 0.4300\n",
            "Epoch 998/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.8514 - val_loss: 2.5246 - val_accuracy: 0.4333\n",
            "Epoch 999/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.8629 - val_loss: 2.5453 - val_accuracy: 0.4333\n",
            "Epoch 1000/1000\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.8557 - val_loss: 2.5236 - val_accuracy: 0.4367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTFys-wRbkNS",
        "colab_type": "text"
      },
      "source": [
        "![png](http://tykimos.github.io/warehouse/2017-7-9-Training_Monitoring_output_7_2.png)\n",
        "\n",
        "\n",
        "각 에포크에 대한 손실값, 정확도 추이를 보실 수가 있습니다. 검증셋의 손실값이 감소하다가 100번째 에포크에서 다시 증가되는 양상을 보입니다. 과적합(overfitting)이 발생했다고 보실 수가 있습니다. 이 경우 100번째 에포크만 학습시킨 모델이 1000번째 에포크까지 학습한 모델보다 실제 테스트에서 더 좋은 결과가 나올 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOBbXUinbkNg",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### 직접 콜백함수 만들어보기\n",
        "\n",
        "기본적인 모델의 학습 상태 모니터링은 앞서 소개한 히스토리 콜백함수나 텐서보드를 이용하면 되지만, 순환신경망 모델인 경우에는 fit 함수를 여러번 호출되기 때문에 제대로 학습상태를 볼 수가 없습니다. 먼저 순환신경망 모델 코드를 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXVpm3n2bkNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch_idx in range(1000):\n",
        "    print ('epochs : ' + str(epoch_idx) )\n",
        "    hist = model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False) # 50 is X.shape[0]\n",
        "    model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "IbHlTqQybkNp",
        "colab_type": "text"
      },
      "source": [
        "매 에포크마다 히스토리 객체가 생성되어 매번 초기화 되기 때문에 에포크별로 추이를 볼 수가 없습니다. 이 문제를 해결하기 위해 fit 함수를 여러 번 호출되더라도 학습 상태가 유지될 수 있도록 콜백함수를 정의해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWfCHj9ebkNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "# 사용자 정의 히스토리 클래스 정의\n",
        "class CustomHistory(keras.callbacks.Callback):\n",
        "    def init(self):\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.train_acc = []\n",
        "        self.val_acc = []        \n",
        "        \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.train_loss.append(logs.get('loss'))\n",
        "        self.val_loss.append(logs.get('val_loss'))\n",
        "        self.train_acc.append(logs.get('accuracy'))\n",
        "        self.val_acc.append(logs.get('val_accuracy'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXftmWO4bkNw",
        "colab_type": "text"
      },
      "source": [
        "새로 만든 콜백함수를 이용해서 학습 상태를 모니터링 해보겠습니다. 이전 코드에서 fit 함수 내에서 1000번 에포크를 수행했던 부분을 한 번 에포크를 수행하는 fit() 함수를 천 번 호출하는 식으로 수정했었습니다. 참고로 fit() 함수를 한 번 호출해서 에포크를 여러번 수행하는 것과 fit() 함수를 여러 번 호출하는 것은 동일한 효과를 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5V8qFovbkNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6979a98a-fd5a-4f00-8aa8-6e8f264b549a"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "# 사용자 정의 히스토리 클래스 정의\n",
        "class CustomHistory(keras.callbacks.Callback):\n",
        "    def init(self):\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.train_acc = []\n",
        "        self.val_acc = []        \n",
        "        \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.train_loss.append(logs.get('loss'))\n",
        "        self.val_loss.append(logs.get('val_loss'))\n",
        "        self.train_acc.append(logs.get('accuracy'))\n",
        "        self.val_acc.append(logs.get('val_accuracy'))\n",
        "        \n",
        "# 1. 데이터셋 생성하기\n",
        "\n",
        "# 훈련셋과 시험셋 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 훈련셋과 검증셋 분리\n",
        "x_val = x_train[50000:]\n",
        "y_val = y_train[50000:]\n",
        "x_train = x_train[:50000]\n",
        "y_train = y_train[:50000]\n",
        "\n",
        "# 데이터셋 전처리\n",
        "x_train = x_train.reshape(50000, 784).astype('float32') / 255.0\n",
        "x_val = x_val.reshape(10000, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "\n",
        "# 훈련셋과 검증셋 고르기\n",
        "train_rand_idxs = np.random.choice(50000, 700)\n",
        "val_rand_idxs = np.random.choice(10000, 300)\n",
        "x_train = x_train[train_rand_idxs]\n",
        "y_train = y_train[train_rand_idxs]\n",
        "x_val = x_val[val_rand_idxs]\n",
        "y_val = y_val[val_rand_idxs]\n",
        "\n",
        "# 라벨데이터 원핫인코딩 (one-hot encoding) 처리\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_val = np_utils.to_categorical(y_val)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "custom_hist = CustomHistory()\n",
        "custom_hist.init()\n",
        "\n",
        "for epoch_idx in range(1000):\n",
        "    print ('epochs : ' + str(epoch_idx) )\n",
        "    model.fit(x_train, y_train, epochs=1, batch_size=10, validation_data=(x_val, y_val), callbacks=[custom_hist])\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "        \n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(custom_hist.train_loss, 'y', label='train loss')\n",
        "loss_ax.plot(custom_hist.val_loss, 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(custom_hist.train_acc, 'b', label='train acc')\n",
        "acc_ax.plot(custom_hist.val_acc, 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "epochs : 0\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2498 - accuracy: 0.1714 - val_loss: 2.1939 - val_accuracy: 0.2133\n",
            "epochs : 1\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 2.1370 - accuracy: 0.2329 - val_loss: 2.1107 - val_accuracy: 0.2500\n",
            "epochs : 2\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 2.0520 - accuracy: 0.2486 - val_loss: 2.0472 - val_accuracy: 0.2267\n",
            "epochs : 3\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.9906 - accuracy: 0.2886 - val_loss: 1.9846 - val_accuracy: 0.2533\n",
            "epochs : 4\n",
            " 1/70 [..............................] - ETA: 0s - loss: 1.9504 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.9428 - accuracy: 0.3129 - val_loss: 1.9433 - val_accuracy: 0.2567\n",
            "epochs : 5\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.8995 - accuracy: 0.3086 - val_loss: 1.9006 - val_accuracy: 0.2567\n",
            "epochs : 6\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.8616 - accuracy: 0.3200 - val_loss: 1.8649 - val_accuracy: 0.2600\n",
            "epochs : 7\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.8285 - accuracy: 0.3300 - val_loss: 1.8354 - val_accuracy: 0.2700\n",
            "epochs : 8\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.7950 - accuracy: 0.3371 - val_loss: 1.8080 - val_accuracy: 0.2767\n",
            "epochs : 9\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.7679 - accuracy: 0.3457 - val_loss: 1.7842 - val_accuracy: 0.2767\n",
            "epochs : 10\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.7408 - accuracy: 0.3529 - val_loss: 1.7508 - val_accuracy: 0.2767\n",
            "epochs : 11\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.7151 - accuracy: 0.3586 - val_loss: 1.7285 - val_accuracy: 0.2833\n",
            "epochs : 12\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.6914 - accuracy: 0.3657 - val_loss: 1.7143 - val_accuracy: 0.2800\n",
            "epochs : 13\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.6685 - accuracy: 0.3657 - val_loss: 1.6848 - val_accuracy: 0.2900\n",
            "epochs : 14\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.6492 - accuracy: 0.3671 - val_loss: 1.6747 - val_accuracy: 0.2967\n",
            "epochs : 15\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.6295 - accuracy: 0.3686 - val_loss: 1.6577 - val_accuracy: 0.2933\n",
            "epochs : 16\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.6100 - accuracy: 0.3600 - val_loss: 1.6346 - val_accuracy: 0.2933\n",
            "epochs : 17\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.5935 - accuracy: 0.3629 - val_loss: 1.6221 - val_accuracy: 0.3133\n",
            "epochs : 18\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.5745 - accuracy: 0.3671 - val_loss: 1.6051 - val_accuracy: 0.3100\n",
            "epochs : 19\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.5599 - accuracy: 0.3729 - val_loss: 1.5984 - val_accuracy: 0.2967\n",
            "epochs : 20\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.5448 - accuracy: 0.3614 - val_loss: 1.5814 - val_accuracy: 0.3100\n",
            "epochs : 21\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.5290 - accuracy: 0.3671 - val_loss: 1.5732 - val_accuracy: 0.3033\n",
            "epochs : 22\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.5135 - accuracy: 0.3629 - val_loss: 1.5555 - val_accuracy: 0.2967\n",
            "epochs : 23\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.5004 - accuracy: 0.3657 - val_loss: 1.5487 - val_accuracy: 0.3167\n",
            "epochs : 24\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4873 - accuracy: 0.3700 - val_loss: 1.5340 - val_accuracy: 0.3300\n",
            "epochs : 25\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4752 - accuracy: 0.3714 - val_loss: 1.5276 - val_accuracy: 0.3333\n",
            "epochs : 26\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4634 - accuracy: 0.3686 - val_loss: 1.5124 - val_accuracy: 0.3500\n",
            "epochs : 27\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4516 - accuracy: 0.3686 - val_loss: 1.5030 - val_accuracy: 0.3533\n",
            "epochs : 28\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4407 - accuracy: 0.3843 - val_loss: 1.5017 - val_accuracy: 0.3567\n",
            "epochs : 29\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4305 - accuracy: 0.3971 - val_loss: 1.4910 - val_accuracy: 0.3567\n",
            "epochs : 30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4182 - accuracy: 0.3971 - val_loss: 1.4818 - val_accuracy: 0.3633\n",
            "epochs : 31\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4082 - accuracy: 0.3871 - val_loss: 1.4761 - val_accuracy: 0.3500\n",
            "epochs : 32\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3985 - accuracy: 0.4086 - val_loss: 1.4691 - val_accuracy: 0.3733\n",
            "epochs : 33\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3862 - accuracy: 0.4143 - val_loss: 1.4678 - val_accuracy: 0.3633\n",
            "epochs : 34\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3774 - accuracy: 0.4086 - val_loss: 1.4600 - val_accuracy: 0.3600\n",
            "epochs : 35\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3695 - accuracy: 0.4171 - val_loss: 1.4466 - val_accuracy: 0.3633\n",
            "epochs : 36\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3609 - accuracy: 0.4386 - val_loss: 1.4394 - val_accuracy: 0.3767\n",
            "epochs : 37\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3522 - accuracy: 0.4657 - val_loss: 1.4329 - val_accuracy: 0.4200\n",
            "epochs : 38\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3438 - accuracy: 0.4829 - val_loss: 1.4336 - val_accuracy: 0.4100\n",
            "epochs : 39\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3359 - accuracy: 0.4871 - val_loss: 1.4217 - val_accuracy: 0.4400\n",
            "epochs : 40\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3269 - accuracy: 0.5014 - val_loss: 1.4145 - val_accuracy: 0.4367\n",
            "epochs : 41\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3195 - accuracy: 0.4971 - val_loss: 1.4086 - val_accuracy: 0.4467\n",
            "epochs : 42\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3116 - accuracy: 0.5043 - val_loss: 1.4022 - val_accuracy: 0.4433\n",
            "epochs : 43\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3044 - accuracy: 0.5071 - val_loss: 1.3942 - val_accuracy: 0.4633\n",
            "epochs : 44\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2961 - accuracy: 0.5157 - val_loss: 1.3966 - val_accuracy: 0.4500\n",
            "epochs : 45\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2889 - accuracy: 0.5114 - val_loss: 1.3905 - val_accuracy: 0.4533\n",
            "epochs : 46\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2825 - accuracy: 0.5343 - val_loss: 1.3801 - val_accuracy: 0.4533\n",
            "epochs : 47\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2742 - accuracy: 0.5229 - val_loss: 1.3799 - val_accuracy: 0.4533\n",
            "epochs : 48\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2663 - accuracy: 0.5229 - val_loss: 1.3769 - val_accuracy: 0.4533\n",
            "epochs : 49\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2603 - accuracy: 0.5414 - val_loss: 1.3619 - val_accuracy: 0.4700\n",
            "epochs : 50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2536 - accuracy: 0.5371 - val_loss: 1.3575 - val_accuracy: 0.4633\n",
            "epochs : 51\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2466 - accuracy: 0.5200 - val_loss: 1.3605 - val_accuracy: 0.4667\n",
            "epochs : 52\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2392 - accuracy: 0.5243 - val_loss: 1.3484 - val_accuracy: 0.4700\n",
            "epochs : 53\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2326 - accuracy: 0.5400 - val_loss: 1.3470 - val_accuracy: 0.4667\n",
            "epochs : 54\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2267 - accuracy: 0.5371 - val_loss: 1.3415 - val_accuracy: 0.4767\n",
            "epochs : 55\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2194 - accuracy: 0.5471 - val_loss: 1.3385 - val_accuracy: 0.4733\n",
            "epochs : 56\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2142 - accuracy: 0.5514 - val_loss: 1.3387 - val_accuracy: 0.4733\n",
            "epochs : 57\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.2060 - accuracy: 0.5471 - val_loss: 1.3271 - val_accuracy: 0.4700\n",
            "epochs : 58\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1996 - accuracy: 0.5443 - val_loss: 1.3324 - val_accuracy: 0.4800\n",
            "epochs : 59\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1961 - accuracy: 0.5543 - val_loss: 1.3190 - val_accuracy: 0.4833\n",
            "epochs : 60\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1897 - accuracy: 0.5586 - val_loss: 1.3233 - val_accuracy: 0.4833\n",
            "epochs : 61\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1830 - accuracy: 0.5586 - val_loss: 1.3086 - val_accuracy: 0.4900\n",
            "epochs : 62\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1772 - accuracy: 0.5643 - val_loss: 1.3083 - val_accuracy: 0.4833\n",
            "epochs : 63\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1725 - accuracy: 0.5686 - val_loss: 1.3070 - val_accuracy: 0.4933\n",
            "epochs : 64\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1673 - accuracy: 0.5614 - val_loss: 1.3059 - val_accuracy: 0.4867\n",
            "epochs : 65\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1605 - accuracy: 0.5743 - val_loss: 1.3126 - val_accuracy: 0.4733\n",
            "epochs : 66\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1574 - accuracy: 0.5757 - val_loss: 1.2982 - val_accuracy: 0.4767\n",
            "epochs : 67\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1503 - accuracy: 0.5857 - val_loss: 1.3098 - val_accuracy: 0.4800\n",
            "epochs : 68\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1468 - accuracy: 0.5743 - val_loss: 1.3073 - val_accuracy: 0.4833\n",
            "epochs : 69\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1419 - accuracy: 0.5729 - val_loss: 1.3057 - val_accuracy: 0.4800\n",
            "epochs : 70\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1372 - accuracy: 0.5800 - val_loss: 1.2876 - val_accuracy: 0.4867\n",
            "epochs : 71\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1321 - accuracy: 0.5686 - val_loss: 1.2875 - val_accuracy: 0.4967\n",
            "epochs : 72\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1275 - accuracy: 0.5800 - val_loss: 1.2917 - val_accuracy: 0.4867\n",
            "epochs : 73\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1232 - accuracy: 0.5814 - val_loss: 1.2884 - val_accuracy: 0.4900\n",
            "epochs : 74\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1188 - accuracy: 0.5871 - val_loss: 1.2790 - val_accuracy: 0.4900\n",
            "epochs : 75\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1141 - accuracy: 0.5814 - val_loss: 1.2889 - val_accuracy: 0.4967\n",
            "epochs : 76\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1089 - accuracy: 0.6029 - val_loss: 1.2758 - val_accuracy: 0.4967\n",
            "epochs : 77\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1060 - accuracy: 0.5929 - val_loss: 1.2764 - val_accuracy: 0.4900\n",
            "epochs : 78\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.1027 - accuracy: 0.5971 - val_loss: 1.2767 - val_accuracy: 0.4867\n",
            "epochs : 79\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0981 - accuracy: 0.5814 - val_loss: 1.2687 - val_accuracy: 0.5000\n",
            "epochs : 80\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0946 - accuracy: 0.5914 - val_loss: 1.2768 - val_accuracy: 0.4967\n",
            "epochs : 81\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0900 - accuracy: 0.5943 - val_loss: 1.2780 - val_accuracy: 0.5133\n",
            "epochs : 82\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0876 - accuracy: 0.5971 - val_loss: 1.2770 - val_accuracy: 0.4900\n",
            "epochs : 83\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0836 - accuracy: 0.6000 - val_loss: 1.2699 - val_accuracy: 0.5000\n",
            "epochs : 84\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0810 - accuracy: 0.6000 - val_loss: 1.2614 - val_accuracy: 0.5033\n",
            "epochs : 85\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0765 - accuracy: 0.5957 - val_loss: 1.2737 - val_accuracy: 0.5033\n",
            "epochs : 86\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0724 - accuracy: 0.6014 - val_loss: 1.2705 - val_accuracy: 0.5033\n",
            "epochs : 87\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0689 - accuracy: 0.5971 - val_loss: 1.2750 - val_accuracy: 0.5000\n",
            "epochs : 88\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0664 - accuracy: 0.6071 - val_loss: 1.2672 - val_accuracy: 0.5067\n",
            "epochs : 89\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0637 - accuracy: 0.6057 - val_loss: 1.2552 - val_accuracy: 0.5067\n",
            "epochs : 90\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0610 - accuracy: 0.6043 - val_loss: 1.2661 - val_accuracy: 0.5167\n",
            "epochs : 91\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0584 - accuracy: 0.6100 - val_loss: 1.2662 - val_accuracy: 0.5033\n",
            "epochs : 92\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0541 - accuracy: 0.6129 - val_loss: 1.2535 - val_accuracy: 0.5100\n",
            "epochs : 93\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0504 - accuracy: 0.6057 - val_loss: 1.2666 - val_accuracy: 0.5033\n",
            "epochs : 94\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0477 - accuracy: 0.6086 - val_loss: 1.2595 - val_accuracy: 0.5200\n",
            "epochs : 95\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0467 - accuracy: 0.6029 - val_loss: 1.2616 - val_accuracy: 0.5067\n",
            "epochs : 96\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0421 - accuracy: 0.6057 - val_loss: 1.2522 - val_accuracy: 0.5167\n",
            "epochs : 97\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0397 - accuracy: 0.6114 - val_loss: 1.2564 - val_accuracy: 0.5133\n",
            "epochs : 98\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0349 - accuracy: 0.6214 - val_loss: 1.2474 - val_accuracy: 0.5033\n",
            "epochs : 99\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0352 - accuracy: 0.6043 - val_loss: 1.2476 - val_accuracy: 0.5200\n",
            "epochs : 100\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.6129 - val_loss: 1.2518 - val_accuracy: 0.5133\n",
            "epochs : 101\n",
            "57/70 [=======================>......] - ETA: 0s - loss: 1.0184 - accuracy: 0.6140WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0017s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0291 - accuracy: 0.6171 - val_loss: 1.2517 - val_accuracy: 0.5167\n",
            "epochs : 102\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.6114 - val_loss: 1.2526 - val_accuracy: 0.5133\n",
            "epochs : 103\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0242 - accuracy: 0.6257 - val_loss: 1.2572 - val_accuracy: 0.5133\n",
            "epochs : 104\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0208 - accuracy: 0.6114 - val_loss: 1.2535 - val_accuracy: 0.5167\n",
            "epochs : 105\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0180 - accuracy: 0.6286 - val_loss: 1.2608 - val_accuracy: 0.5000\n",
            "epochs : 106\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0165 - accuracy: 0.6171 - val_loss: 1.2493 - val_accuracy: 0.5133\n",
            "epochs : 107\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0127 - accuracy: 0.6271 - val_loss: 1.2516 - val_accuracy: 0.5200\n",
            "epochs : 108\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0106 - accuracy: 0.6243 - val_loss: 1.2518 - val_accuracy: 0.5233\n",
            "epochs : 109\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0087 - accuracy: 0.6257 - val_loss: 1.2538 - val_accuracy: 0.5233\n",
            "epochs : 110\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0059 - accuracy: 0.6257 - val_loss: 1.2459 - val_accuracy: 0.5167\n",
            "epochs : 111\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.6286 - val_loss: 1.2587 - val_accuracy: 0.5200\n",
            "epochs : 112\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.0020 - accuracy: 0.6300 - val_loss: 1.2566 - val_accuracy: 0.5133\n",
            "epochs : 113\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9979 - accuracy: 0.6314 - val_loss: 1.2579 - val_accuracy: 0.5200\n",
            "epochs : 114\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9974 - accuracy: 0.6229 - val_loss: 1.2577 - val_accuracy: 0.5133\n",
            "epochs : 115\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9934 - accuracy: 0.6357 - val_loss: 1.2460 - val_accuracy: 0.5167\n",
            "epochs : 116\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9920 - accuracy: 0.6443 - val_loss: 1.2448 - val_accuracy: 0.5200\n",
            "epochs : 117\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9911 - accuracy: 0.6300 - val_loss: 1.2403 - val_accuracy: 0.5300\n",
            "epochs : 118\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9890 - accuracy: 0.6357 - val_loss: 1.2452 - val_accuracy: 0.5167\n",
            "epochs : 119\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9868 - accuracy: 0.6443 - val_loss: 1.2619 - val_accuracy: 0.5133\n",
            "epochs : 120\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.9877 - accuracy: 0.6429WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9839 - accuracy: 0.6443 - val_loss: 1.2620 - val_accuracy: 0.5333\n",
            "epochs : 121\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9826 - accuracy: 0.6286 - val_loss: 1.2540 - val_accuracy: 0.5133\n",
            "epochs : 122\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9797 - accuracy: 0.6329 - val_loss: 1.2549 - val_accuracy: 0.5233\n",
            "epochs : 123\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9775 - accuracy: 0.6343 - val_loss: 1.2436 - val_accuracy: 0.5333\n",
            "epochs : 124\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9754 - accuracy: 0.6400 - val_loss: 1.2679 - val_accuracy: 0.5333\n",
            "epochs : 125\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9736 - accuracy: 0.6400 - val_loss: 1.2567 - val_accuracy: 0.5200\n",
            "epochs : 126\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9722 - accuracy: 0.6429 - val_loss: 1.2491 - val_accuracy: 0.5333\n",
            "epochs : 127\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9683 - accuracy: 0.6414 - val_loss: 1.2612 - val_accuracy: 0.5133\n",
            "epochs : 128\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9689 - accuracy: 0.6414 - val_loss: 1.2643 - val_accuracy: 0.5433\n",
            "epochs : 129\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9652 - accuracy: 0.6500 - val_loss: 1.2497 - val_accuracy: 0.5233\n",
            "epochs : 130\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9633 - accuracy: 0.6329 - val_loss: 1.2655 - val_accuracy: 0.5267\n",
            "epochs : 131\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9619 - accuracy: 0.6414 - val_loss: 1.2566 - val_accuracy: 0.5200\n",
            "epochs : 132\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6414 - val_loss: 1.2690 - val_accuracy: 0.5233\n",
            "epochs : 133\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9594 - accuracy: 0.6514 - val_loss: 1.2547 - val_accuracy: 0.5200\n",
            "epochs : 134\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9554 - accuracy: 0.6400 - val_loss: 1.2584 - val_accuracy: 0.5200\n",
            "epochs : 135\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9560 - accuracy: 0.6429 - val_loss: 1.2591 - val_accuracy: 0.5267\n",
            "epochs : 136\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9525 - accuracy: 0.6486 - val_loss: 1.2760 - val_accuracy: 0.5333\n",
            "epochs : 137\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9502 - accuracy: 0.6457 - val_loss: 1.2537 - val_accuracy: 0.5200\n",
            "epochs : 138\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9512 - accuracy: 0.6414 - val_loss: 1.2525 - val_accuracy: 0.5200\n",
            "epochs : 139\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9481 - accuracy: 0.6457 - val_loss: 1.2484 - val_accuracy: 0.5167\n",
            "epochs : 140\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9453 - accuracy: 0.6414 - val_loss: 1.2674 - val_accuracy: 0.5333\n",
            "epochs : 141\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9430 - accuracy: 0.6429 - val_loss: 1.2771 - val_accuracy: 0.5300\n",
            "epochs : 142\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9421 - accuracy: 0.6514 - val_loss: 1.2468 - val_accuracy: 0.5167\n",
            "epochs : 143\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9402 - accuracy: 0.6443 - val_loss: 1.2588 - val_accuracy: 0.5233\n",
            "epochs : 144\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9373 - accuracy: 0.6471 - val_loss: 1.2509 - val_accuracy: 0.5167\n",
            "epochs : 145\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9369 - accuracy: 0.6471 - val_loss: 1.2607 - val_accuracy: 0.5200\n",
            "epochs : 146\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9344 - accuracy: 0.6529 - val_loss: 1.2741 - val_accuracy: 0.5167\n",
            "epochs : 147\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9337 - accuracy: 0.6514 - val_loss: 1.2624 - val_accuracy: 0.5267\n",
            "epochs : 148\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9307 - accuracy: 0.6471 - val_loss: 1.2547 - val_accuracy: 0.5233\n",
            "epochs : 149\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9282 - accuracy: 0.6543 - val_loss: 1.2722 - val_accuracy: 0.5233\n",
            "epochs : 150\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9272 - accuracy: 0.6457 - val_loss: 1.2598 - val_accuracy: 0.5300\n",
            "epochs : 151\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9269 - accuracy: 0.6443 - val_loss: 1.2587 - val_accuracy: 0.5133\n",
            "epochs : 152\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9237 - accuracy: 0.6429 - val_loss: 1.2591 - val_accuracy: 0.5267\n",
            "epochs : 153\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.9342 - accuracy: 0.6400WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0027s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9237 - accuracy: 0.6486 - val_loss: 1.2620 - val_accuracy: 0.5200\n",
            "epochs : 154\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9224 - accuracy: 0.6557 - val_loss: 1.2753 - val_accuracy: 0.5233\n",
            "epochs : 155\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9189 - accuracy: 0.6543 - val_loss: 1.2771 - val_accuracy: 0.5300\n",
            "epochs : 156\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9177 - accuracy: 0.6500 - val_loss: 1.2670 - val_accuracy: 0.5200\n",
            "epochs : 157\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9154 - accuracy: 0.6600 - val_loss: 1.2608 - val_accuracy: 0.5233\n",
            "epochs : 158\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9142 - accuracy: 0.6557 - val_loss: 1.2645 - val_accuracy: 0.5300\n",
            "epochs : 159\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9105 - accuracy: 0.6629 - val_loss: 1.2732 - val_accuracy: 0.5167\n",
            "epochs : 160\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9101 - accuracy: 0.6529 - val_loss: 1.2630 - val_accuracy: 0.5200\n",
            "epochs : 161\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9089 - accuracy: 0.6643 - val_loss: 1.2834 - val_accuracy: 0.5267\n",
            "epochs : 162\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9068 - accuracy: 0.6571 - val_loss: 1.2720 - val_accuracy: 0.5167\n",
            "epochs : 163\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9063 - accuracy: 0.6586 - val_loss: 1.2789 - val_accuracy: 0.5200\n",
            "epochs : 164\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9033 - accuracy: 0.6657 - val_loss: 1.2710 - val_accuracy: 0.5200\n",
            "epochs : 165\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9028 - accuracy: 0.6700 - val_loss: 1.2585 - val_accuracy: 0.5167\n",
            "epochs : 166\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9025 - accuracy: 0.6671 - val_loss: 1.2903 - val_accuracy: 0.5233\n",
            "epochs : 167\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.9008 - accuracy: 0.6657 - val_loss: 1.2656 - val_accuracy: 0.5267\n",
            "epochs : 168\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8991 - accuracy: 0.6571 - val_loss: 1.2784 - val_accuracy: 0.5300\n",
            "epochs : 169\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8990 - accuracy: 0.6700 - val_loss: 1.2878 - val_accuracy: 0.5267\n",
            "epochs : 170\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8950 - accuracy: 0.6629 - val_loss: 1.2610 - val_accuracy: 0.5200\n",
            "epochs : 171\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8938 - accuracy: 0.6700 - val_loss: 1.2754 - val_accuracy: 0.5200\n",
            "epochs : 172\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8930 - accuracy: 0.6671 - val_loss: 1.2740 - val_accuracy: 0.5233\n",
            "epochs : 173\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8913 - accuracy: 0.6714 - val_loss: 1.2804 - val_accuracy: 0.5233\n",
            "epochs : 174\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8912 - accuracy: 0.6714 - val_loss: 1.2760 - val_accuracy: 0.5133\n",
            "epochs : 175\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8883 - accuracy: 0.6729 - val_loss: 1.2719 - val_accuracy: 0.5167\n",
            "epochs : 176\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8869 - accuracy: 0.6686 - val_loss: 1.2744 - val_accuracy: 0.5200\n",
            "epochs : 177\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8863 - accuracy: 0.6671 - val_loss: 1.2811 - val_accuracy: 0.5167\n",
            "epochs : 178\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8854 - accuracy: 0.6757 - val_loss: 1.2820 - val_accuracy: 0.5200\n",
            "epochs : 179\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8839 - accuracy: 0.6629 - val_loss: 1.2809 - val_accuracy: 0.5200\n",
            "epochs : 180\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8820 - accuracy: 0.6700 - val_loss: 1.2790 - val_accuracy: 0.5200\n",
            "epochs : 181\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8811 - accuracy: 0.6757 - val_loss: 1.2901 - val_accuracy: 0.5167\n",
            "epochs : 182\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8802 - accuracy: 0.6686 - val_loss: 1.2838 - val_accuracy: 0.5133\n",
            "epochs : 183\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8787 - accuracy: 0.6786 - val_loss: 1.2826 - val_accuracy: 0.5200\n",
            "epochs : 184\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8761 - accuracy: 0.6786 - val_loss: 1.2894 - val_accuracy: 0.5233\n",
            "epochs : 185\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8756 - accuracy: 0.6743 - val_loss: 1.2844 - val_accuracy: 0.5133\n",
            "epochs : 186\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8739 - accuracy: 0.6757 - val_loss: 1.3066 - val_accuracy: 0.5300\n",
            "epochs : 187\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8737 - accuracy: 0.6743 - val_loss: 1.2939 - val_accuracy: 0.5100\n",
            "epochs : 188\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8712 - accuracy: 0.6771 - val_loss: 1.3024 - val_accuracy: 0.5233\n",
            "epochs : 189\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8708 - accuracy: 0.6729 - val_loss: 1.2998 - val_accuracy: 0.5200\n",
            "epochs : 190\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8663 - accuracy: 0.6771 - val_loss: 1.2875 - val_accuracy: 0.5133\n",
            "epochs : 191\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8676 - accuracy: 0.6729 - val_loss: 1.2911 - val_accuracy: 0.5233\n",
            "epochs : 192\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8676 - accuracy: 0.6843 - val_loss: 1.2967 - val_accuracy: 0.5133\n",
            "epochs : 193\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8659 - accuracy: 0.6800 - val_loss: 1.2970 - val_accuracy: 0.5133\n",
            "epochs : 194\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8630 - accuracy: 0.6814 - val_loss: 1.2856 - val_accuracy: 0.5300\n",
            "epochs : 195\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8622 - accuracy: 0.6771 - val_loss: 1.2932 - val_accuracy: 0.5133\n",
            "epochs : 196\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8606 - accuracy: 0.6871 - val_loss: 1.2894 - val_accuracy: 0.5133\n",
            "epochs : 197\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8589 - accuracy: 0.6714 - val_loss: 1.3147 - val_accuracy: 0.5233\n",
            "epochs : 198\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8572 - accuracy: 0.6786 - val_loss: 1.3024 - val_accuracy: 0.5200\n",
            "epochs : 199\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8562 - accuracy: 0.6814 - val_loss: 1.2957 - val_accuracy: 0.5267\n",
            "epochs : 200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8556 - accuracy: 0.6843 - val_loss: 1.2990 - val_accuracy: 0.5300\n",
            "epochs : 201\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8546 - accuracy: 0.6814 - val_loss: 1.3175 - val_accuracy: 0.5200\n",
            "epochs : 202\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8532 - accuracy: 0.6843 - val_loss: 1.3007 - val_accuracy: 0.5167\n",
            "epochs : 203\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8520 - accuracy: 0.6814 - val_loss: 1.2974 - val_accuracy: 0.5233\n",
            "epochs : 204\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8509 - accuracy: 0.6929 - val_loss: 1.3051 - val_accuracy: 0.5200\n",
            "epochs : 205\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8485 - accuracy: 0.6971 - val_loss: 1.3083 - val_accuracy: 0.5267\n",
            "epochs : 206\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8483 - accuracy: 0.6800 - val_loss: 1.3113 - val_accuracy: 0.5267\n",
            "epochs : 207\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8480 - accuracy: 0.6857 - val_loss: 1.2952 - val_accuracy: 0.5267\n",
            "epochs : 208\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8454 - accuracy: 0.6886 - val_loss: 1.3231 - val_accuracy: 0.5233\n",
            "epochs : 209\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8458 - accuracy: 0.6886 - val_loss: 1.2999 - val_accuracy: 0.5233\n",
            "epochs : 210\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8442 - accuracy: 0.6871 - val_loss: 1.3086 - val_accuracy: 0.5233\n",
            "epochs : 211\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.6771 - val_loss: 1.3004 - val_accuracy: 0.5300\n",
            "epochs : 212\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8399 - accuracy: 0.6957 - val_loss: 1.3229 - val_accuracy: 0.5333\n",
            "epochs : 213\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8432 - accuracy: 0.6857 - val_loss: 1.3190 - val_accuracy: 0.5200\n",
            "epochs : 214\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8374 - accuracy: 0.6871 - val_loss: 1.3237 - val_accuracy: 0.5267\n",
            "epochs : 215\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8393 - accuracy: 0.6886 - val_loss: 1.3053 - val_accuracy: 0.5200\n",
            "epochs : 216\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8375 - accuracy: 0.6886 - val_loss: 1.3241 - val_accuracy: 0.5200\n",
            "epochs : 217\n",
            "60/70 [========================>.....] - ETA: 0s - loss: 0.8344 - accuracy: 0.6917WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0026s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8356 - accuracy: 0.6943 - val_loss: 1.3320 - val_accuracy: 0.5167\n",
            "epochs : 218\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8346 - accuracy: 0.6914 - val_loss: 1.3294 - val_accuracy: 0.5200\n",
            "epochs : 219\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.9194 - accuracy: 0.7000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0053s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8337 - accuracy: 0.6929 - val_loss: 1.3238 - val_accuracy: 0.5233\n",
            "epochs : 220\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8337 - accuracy: 0.6886 - val_loss: 1.3201 - val_accuracy: 0.5300\n",
            "epochs : 221\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8311 - accuracy: 0.6957 - val_loss: 1.3226 - val_accuracy: 0.5267\n",
            "epochs : 222\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8305 - accuracy: 0.6843 - val_loss: 1.3241 - val_accuracy: 0.5333\n",
            "epochs : 223\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8287 - accuracy: 0.6943 - val_loss: 1.3244 - val_accuracy: 0.5267\n",
            "epochs : 224\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8274 - accuracy: 0.6914 - val_loss: 1.3416 - val_accuracy: 0.5300\n",
            "epochs : 225\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8272 - accuracy: 0.6886 - val_loss: 1.3459 - val_accuracy: 0.5300\n",
            "epochs : 226\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8259 - accuracy: 0.6886 - val_loss: 1.3313 - val_accuracy: 0.5267\n",
            "epochs : 227\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8246 - accuracy: 0.6886 - val_loss: 1.3426 - val_accuracy: 0.5233\n",
            "epochs : 228\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8236 - accuracy: 0.6886 - val_loss: 1.3346 - val_accuracy: 0.5200\n",
            "epochs : 229\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8224 - accuracy: 0.6914 - val_loss: 1.3360 - val_accuracy: 0.5300\n",
            "epochs : 230\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8219 - accuracy: 0.6943 - val_loss: 1.3338 - val_accuracy: 0.5233\n",
            "epochs : 231\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8181 - accuracy: 0.6986 - val_loss: 1.3556 - val_accuracy: 0.5300\n",
            "epochs : 232\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8212 - accuracy: 0.6900 - val_loss: 1.3386 - val_accuracy: 0.5367\n",
            "epochs : 233\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8187 - accuracy: 0.6929 - val_loss: 1.3362 - val_accuracy: 0.5233\n",
            "epochs : 234\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8169 - accuracy: 0.6914 - val_loss: 1.3363 - val_accuracy: 0.5367\n",
            "epochs : 235\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8167 - accuracy: 0.7029 - val_loss: 1.3247 - val_accuracy: 0.5300\n",
            "epochs : 236\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8154 - accuracy: 0.7014 - val_loss: 1.3345 - val_accuracy: 0.5267\n",
            "epochs : 237\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8154 - accuracy: 0.6971 - val_loss: 1.3394 - val_accuracy: 0.5367\n",
            "epochs : 238\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8121 - accuracy: 0.6971 - val_loss: 1.3599 - val_accuracy: 0.5400\n",
            "epochs : 239\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8118 - accuracy: 0.7000 - val_loss: 1.3276 - val_accuracy: 0.5300\n",
            "epochs : 240\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8117 - accuracy: 0.7000 - val_loss: 1.3415 - val_accuracy: 0.5333\n",
            "epochs : 241\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8106 - accuracy: 0.6957 - val_loss: 1.3312 - val_accuracy: 0.5367\n",
            "epochs : 242\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8087 - accuracy: 0.6971 - val_loss: 1.3434 - val_accuracy: 0.5300\n",
            "epochs : 243\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8081 - accuracy: 0.6957 - val_loss: 1.3528 - val_accuracy: 0.5367\n",
            "epochs : 244\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8082 - accuracy: 0.6943 - val_loss: 1.3353 - val_accuracy: 0.5367\n",
            "epochs : 245\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8057 - accuracy: 0.6986 - val_loss: 1.3538 - val_accuracy: 0.5400\n",
            "epochs : 246\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8052 - accuracy: 0.6914 - val_loss: 1.3548 - val_accuracy: 0.5400\n",
            "epochs : 247\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8035 - accuracy: 0.7000 - val_loss: 1.3457 - val_accuracy: 0.5333\n",
            "epochs : 248\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8023 - accuracy: 0.6986 - val_loss: 1.3387 - val_accuracy: 0.5367\n",
            "epochs : 249\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8023 - accuracy: 0.7014 - val_loss: 1.3513 - val_accuracy: 0.5333\n",
            "epochs : 250\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8024 - accuracy: 0.6971 - val_loss: 1.3522 - val_accuracy: 0.5300\n",
            "epochs : 251\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.8012 - accuracy: 0.7014 - val_loss: 1.3473 - val_accuracy: 0.5367\n",
            "epochs : 252\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7986 - accuracy: 0.7000 - val_loss: 1.3399 - val_accuracy: 0.5367\n",
            "epochs : 253\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7978 - accuracy: 0.7029 - val_loss: 1.3544 - val_accuracy: 0.5333\n",
            "epochs : 254\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7972 - accuracy: 0.6957 - val_loss: 1.3657 - val_accuracy: 0.5433\n",
            "epochs : 255\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7964 - accuracy: 0.6971 - val_loss: 1.3445 - val_accuracy: 0.5333\n",
            "epochs : 256\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7943 - accuracy: 0.7029 - val_loss: 1.3485 - val_accuracy: 0.5267\n",
            "epochs : 257\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.7952 - accuracy: 0.6986 - val_loss: 1.3518 - val_accuracy: 0.5433\n",
            "epochs : 258\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7927 - accuracy: 0.7071 - val_loss: 1.3603 - val_accuracy: 0.5333\n",
            "epochs : 259\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7936 - accuracy: 0.7000 - val_loss: 1.3655 - val_accuracy: 0.5300\n",
            "epochs : 260\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.6929 - val_loss: 1.3666 - val_accuracy: 0.5400\n",
            "epochs : 261\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7901 - accuracy: 0.7057 - val_loss: 1.3483 - val_accuracy: 0.5300\n",
            "epochs : 262\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.8035 - accuracy: 0.6937WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0078s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7897 - accuracy: 0.7043 - val_loss: 1.3626 - val_accuracy: 0.5333\n",
            "epochs : 263\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7864 - accuracy: 0.7129 - val_loss: 1.3385 - val_accuracy: 0.5267\n",
            "epochs : 264\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7880 - accuracy: 0.7000 - val_loss: 1.3631 - val_accuracy: 0.5300\n",
            "epochs : 265\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7875 - accuracy: 0.7057 - val_loss: 1.3996 - val_accuracy: 0.5367\n",
            "epochs : 266\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7873 - accuracy: 0.7086 - val_loss: 1.3678 - val_accuracy: 0.5367\n",
            "epochs : 267\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7867 - accuracy: 0.7014 - val_loss: 1.3645 - val_accuracy: 0.5333\n",
            "epochs : 268\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7835 - accuracy: 0.7100 - val_loss: 1.3789 - val_accuracy: 0.5300\n",
            "epochs : 269\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7844 - accuracy: 0.7029 - val_loss: 1.3674 - val_accuracy: 0.5400\n",
            "epochs : 270\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7823 - accuracy: 0.7057 - val_loss: 1.3628 - val_accuracy: 0.5433\n",
            "epochs : 271\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.7071 - val_loss: 1.3780 - val_accuracy: 0.5333\n",
            "epochs : 272\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7811 - accuracy: 0.7071 - val_loss: 1.3959 - val_accuracy: 0.5467\n",
            "epochs : 273\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7811 - accuracy: 0.7100 - val_loss: 1.3681 - val_accuracy: 0.5433\n",
            "epochs : 274\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7788 - accuracy: 0.7100 - val_loss: 1.3613 - val_accuracy: 0.5267\n",
            "epochs : 275\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7791 - accuracy: 0.7100 - val_loss: 1.3743 - val_accuracy: 0.5433\n",
            "epochs : 276\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7780 - accuracy: 0.7186 - val_loss: 1.3829 - val_accuracy: 0.5433\n",
            "epochs : 277\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7757 - accuracy: 0.7071 - val_loss: 1.3940 - val_accuracy: 0.5333\n",
            "epochs : 278\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7770 - accuracy: 0.7129 - val_loss: 1.3708 - val_accuracy: 0.5367\n",
            "epochs : 279\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7772 - accuracy: 0.7043 - val_loss: 1.3777 - val_accuracy: 0.5367\n",
            "epochs : 280\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7751 - accuracy: 0.7171 - val_loss: 1.3739 - val_accuracy: 0.5367\n",
            "epochs : 281\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7733 - accuracy: 0.7143 - val_loss: 1.3786 - val_accuracy: 0.5367\n",
            "epochs : 282\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7733 - accuracy: 0.7171 - val_loss: 1.3799 - val_accuracy: 0.5400\n",
            "epochs : 283\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7721 - accuracy: 0.7100 - val_loss: 1.3954 - val_accuracy: 0.5333\n",
            "epochs : 284\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7718 - accuracy: 0.7171 - val_loss: 1.3856 - val_accuracy: 0.5433\n",
            "epochs : 285\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7704 - accuracy: 0.7071 - val_loss: 1.4082 - val_accuracy: 0.5400\n",
            "epochs : 286\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7699 - accuracy: 0.7157 - val_loss: 1.3909 - val_accuracy: 0.5267\n",
            "epochs : 287\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7685 - accuracy: 0.7186 - val_loss: 1.3811 - val_accuracy: 0.5267\n",
            "epochs : 288\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7670 - accuracy: 0.7271 - val_loss: 1.4073 - val_accuracy: 0.5267\n",
            "epochs : 289\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7668 - accuracy: 0.7214 - val_loss: 1.3823 - val_accuracy: 0.5400\n",
            "epochs : 290\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7660 - accuracy: 0.7171 - val_loss: 1.3984 - val_accuracy: 0.5333\n",
            "epochs : 291\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7653 - accuracy: 0.7129 - val_loss: 1.4010 - val_accuracy: 0.5433\n",
            "epochs : 292\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7639 - accuracy: 0.7129 - val_loss: 1.4032 - val_accuracy: 0.5200\n",
            "epochs : 293\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.7129 - val_loss: 1.3941 - val_accuracy: 0.5367\n",
            "epochs : 294\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.7214 - val_loss: 1.4014 - val_accuracy: 0.5433\n",
            "epochs : 295\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7616 - accuracy: 0.7214 - val_loss: 1.3962 - val_accuracy: 0.5433\n",
            "epochs : 296\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.7229 - val_loss: 1.3868 - val_accuracy: 0.5267\n",
            "epochs : 297\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7619 - accuracy: 0.7186 - val_loss: 1.4040 - val_accuracy: 0.5400\n",
            "epochs : 298\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7588 - accuracy: 0.7129 - val_loss: 1.4005 - val_accuracy: 0.5267\n",
            "epochs : 299\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7585 - accuracy: 0.7229 - val_loss: 1.4015 - val_accuracy: 0.5367\n",
            "epochs : 300\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.7143 - val_loss: 1.3920 - val_accuracy: 0.5133\n",
            "epochs : 301\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.7229 - val_loss: 1.4275 - val_accuracy: 0.5367\n",
            "epochs : 302\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7572 - accuracy: 0.7186 - val_loss: 1.4230 - val_accuracy: 0.5433\n",
            "epochs : 303\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.7200 - val_loss: 1.4000 - val_accuracy: 0.5300\n",
            "epochs : 304\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7546 - accuracy: 0.7271 - val_loss: 1.3943 - val_accuracy: 0.5300\n",
            "epochs : 305\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7547 - accuracy: 0.7214 - val_loss: 1.4029 - val_accuracy: 0.5233\n",
            "epochs : 306\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 0.7257 - val_loss: 1.4335 - val_accuracy: 0.5267\n",
            "epochs : 307\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7538 - accuracy: 0.7271 - val_loss: 1.4273 - val_accuracy: 0.5367\n",
            "epochs : 308\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7229 - val_loss: 1.4184 - val_accuracy: 0.5267\n",
            "epochs : 309\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.7243 - val_loss: 1.4166 - val_accuracy: 0.5267\n",
            "epochs : 310\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.7229 - val_loss: 1.4106 - val_accuracy: 0.5267\n",
            "epochs : 311\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7497 - accuracy: 0.7286 - val_loss: 1.4316 - val_accuracy: 0.5333\n",
            "epochs : 312\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.7229 - val_loss: 1.4012 - val_accuracy: 0.5233\n",
            "epochs : 313\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.7286 - val_loss: 1.4274 - val_accuracy: 0.5367\n",
            "epochs : 314\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.7257 - val_loss: 1.4285 - val_accuracy: 0.5400\n",
            "epochs : 315\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.7243 - val_loss: 1.4199 - val_accuracy: 0.5333\n",
            "epochs : 316\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.6162 - accuracy: 0.9000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0032s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7463 - accuracy: 0.7286 - val_loss: 1.4375 - val_accuracy: 0.5333\n",
            "epochs : 317\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7455 - accuracy: 0.7257 - val_loss: 1.4327 - val_accuracy: 0.5333\n",
            "epochs : 318\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7243 - val_loss: 1.4374 - val_accuracy: 0.5300\n",
            "epochs : 319\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7200 - val_loss: 1.4290 - val_accuracy: 0.5267\n",
            "epochs : 320\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7243 - val_loss: 1.4246 - val_accuracy: 0.5367\n",
            "epochs : 321\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7343 - val_loss: 1.4389 - val_accuracy: 0.5333\n",
            "epochs : 322\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7143 - val_loss: 1.4409 - val_accuracy: 0.5233\n",
            "epochs : 323\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7243 - val_loss: 1.4233 - val_accuracy: 0.5133\n",
            "epochs : 324\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7271 - val_loss: 1.4291 - val_accuracy: 0.5333\n",
            "epochs : 325\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7271 - val_loss: 1.4503 - val_accuracy: 0.5267\n",
            "epochs : 326\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7271 - val_loss: 1.4373 - val_accuracy: 0.5333\n",
            "epochs : 327\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.7343 - val_loss: 1.4641 - val_accuracy: 0.5433\n",
            "epochs : 328\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7200 - val_loss: 1.4304 - val_accuracy: 0.5200\n",
            "epochs : 329\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7343 - val_loss: 1.4368 - val_accuracy: 0.5167\n",
            "epochs : 330\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.7300 - val_loss: 1.4466 - val_accuracy: 0.5333\n",
            "epochs : 331\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.7229 - val_loss: 1.4403 - val_accuracy: 0.5233\n",
            "epochs : 332\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7271 - val_loss: 1.4360 - val_accuracy: 0.5133\n",
            "epochs : 333\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7329 - val_loss: 1.4458 - val_accuracy: 0.5300\n",
            "epochs : 334\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7314 - val_loss: 1.4533 - val_accuracy: 0.5300\n",
            "epochs : 335\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.7314 - val_loss: 1.4346 - val_accuracy: 0.5200\n",
            "epochs : 336\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.7314 - val_loss: 1.4416 - val_accuracy: 0.5233\n",
            "epochs : 337\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.7343 - val_loss: 1.4502 - val_accuracy: 0.5267\n",
            "epochs : 338\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.7286 - val_loss: 1.4403 - val_accuracy: 0.5233\n",
            "epochs : 339\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7308 - accuracy: 0.7271 - val_loss: 1.4427 - val_accuracy: 0.5200\n",
            "epochs : 340\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.7329 - val_loss: 1.4736 - val_accuracy: 0.5200\n",
            "epochs : 341\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.7286 - val_loss: 1.4498 - val_accuracy: 0.5267\n",
            "epochs : 342\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7280 - accuracy: 0.7357 - val_loss: 1.4738 - val_accuracy: 0.5400\n",
            "epochs : 343\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7274 - accuracy: 0.7314 - val_loss: 1.4522 - val_accuracy: 0.5267\n",
            "epochs : 344\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7284 - accuracy: 0.7314 - val_loss: 1.4596 - val_accuracy: 0.5167\n",
            "epochs : 345\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7270 - accuracy: 0.7271 - val_loss: 1.4639 - val_accuracy: 0.5167\n",
            "epochs : 346\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.7429 - val_loss: 1.4734 - val_accuracy: 0.5167\n",
            "epochs : 347\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7237 - accuracy: 0.7343 - val_loss: 1.4658 - val_accuracy: 0.5033\n",
            "epochs : 348\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.7457 - val_loss: 1.4763 - val_accuracy: 0.5167\n",
            "epochs : 349\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.7271 - val_loss: 1.4574 - val_accuracy: 0.5100\n",
            "epochs : 350\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.7371 - val_loss: 1.4850 - val_accuracy: 0.5267\n",
            "epochs : 351\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.7371 - val_loss: 1.4618 - val_accuracy: 0.5167\n",
            "epochs : 352\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.7329 - val_loss: 1.4703 - val_accuracy: 0.5267\n",
            "epochs : 353\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7209 - accuracy: 0.7400 - val_loss: 1.4595 - val_accuracy: 0.5200\n",
            "epochs : 354\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7204 - accuracy: 0.7414 - val_loss: 1.5023 - val_accuracy: 0.5300\n",
            "epochs : 355\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.7386 - val_loss: 1.4894 - val_accuracy: 0.5167\n",
            "epochs : 356\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7185 - accuracy: 0.7329 - val_loss: 1.4824 - val_accuracy: 0.5333\n",
            "epochs : 357\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.7357 - val_loss: 1.5013 - val_accuracy: 0.5033\n",
            "epochs : 358\n",
            "61/70 [=========================>....] - ETA: 0s - loss: 0.7209 - accuracy: 0.7361WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0024s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.7343 - val_loss: 1.4831 - val_accuracy: 0.5100\n",
            "epochs : 359\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7152 - accuracy: 0.7414 - val_loss: 1.4888 - val_accuracy: 0.5200\n",
            "epochs : 360\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7170 - accuracy: 0.7357 - val_loss: 1.4774 - val_accuracy: 0.5200\n",
            "epochs : 361\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7172 - accuracy: 0.7386 - val_loss: 1.4806 - val_accuracy: 0.5233\n",
            "epochs : 362\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7142 - accuracy: 0.7429 - val_loss: 1.4993 - val_accuracy: 0.5133\n",
            "epochs : 363\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.7429 - val_loss: 1.4928 - val_accuracy: 0.5267\n",
            "epochs : 364\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.7357 - val_loss: 1.4879 - val_accuracy: 0.5133\n",
            "epochs : 365\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7146 - accuracy: 0.7429 - val_loss: 1.4842 - val_accuracy: 0.5233\n",
            "epochs : 366\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.7414 - val_loss: 1.4869 - val_accuracy: 0.5067\n",
            "epochs : 367\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7114 - accuracy: 0.7414 - val_loss: 1.4889 - val_accuracy: 0.5200\n",
            "epochs : 368\n",
            "62/70 [=========================>....] - ETA: 0s - loss: 0.7113 - accuracy: 0.7532WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.7457 - val_loss: 1.4932 - val_accuracy: 0.5100\n",
            "epochs : 369\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.7429 - val_loss: 1.4834 - val_accuracy: 0.5100\n",
            "epochs : 370\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7102 - accuracy: 0.7400 - val_loss: 1.4823 - val_accuracy: 0.5133\n",
            "epochs : 371\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7093 - accuracy: 0.7414 - val_loss: 1.4880 - val_accuracy: 0.5067\n",
            "epochs : 372\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.7329 - val_loss: 1.5114 - val_accuracy: 0.5300\n",
            "epochs : 373\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.7486 - val_loss: 1.5099 - val_accuracy: 0.5300\n",
            "epochs : 374\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.7414 - val_loss: 1.4852 - val_accuracy: 0.5133\n",
            "epochs : 375\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.7457 - val_loss: 1.4892 - val_accuracy: 0.5133\n",
            "epochs : 376\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.7414 - val_loss: 1.4948 - val_accuracy: 0.5167\n",
            "epochs : 377\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.6902 - accuracy: 0.7485WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_test_batch_end` time: 0.0035s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.7500 - val_loss: 1.4882 - val_accuracy: 0.5133\n",
            "epochs : 378\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.7414 - val_loss: 1.4981 - val_accuracy: 0.5133\n",
            "epochs : 379\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.7543 - val_loss: 1.5063 - val_accuracy: 0.5033\n",
            "epochs : 380\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.7486 - val_loss: 1.5183 - val_accuracy: 0.5100\n",
            "epochs : 381\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.7457 - val_loss: 1.5064 - val_accuracy: 0.5133\n",
            "epochs : 382\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.7443 - val_loss: 1.5178 - val_accuracy: 0.5167\n",
            "epochs : 383\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.7457 - val_loss: 1.5247 - val_accuracy: 0.5233\n",
            "epochs : 384\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.7471 - val_loss: 1.4944 - val_accuracy: 0.5167\n",
            "epochs : 385\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7019 - accuracy: 0.7429 - val_loss: 1.5140 - val_accuracy: 0.5067\n",
            "epochs : 386\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.7500 - val_loss: 1.5133 - val_accuracy: 0.5100\n",
            "epochs : 387\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7005 - accuracy: 0.7471 - val_loss: 1.5286 - val_accuracy: 0.5167\n",
            "epochs : 388\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.7486 - val_loss: 1.5193 - val_accuracy: 0.5133\n",
            "epochs : 389\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.6795 - accuracy: 0.7531WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_test_batch_end` time: 0.0023s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6993 - accuracy: 0.7471 - val_loss: 1.5148 - val_accuracy: 0.5067\n",
            "epochs : 390\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.7429 - val_loss: 1.5143 - val_accuracy: 0.5133\n",
            "epochs : 391\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.7500 - val_loss: 1.5262 - val_accuracy: 0.5100\n",
            "epochs : 392\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6975 - accuracy: 0.7471 - val_loss: 1.5172 - val_accuracy: 0.5100\n",
            "epochs : 393\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.7514 - val_loss: 1.5270 - val_accuracy: 0.5167\n",
            "epochs : 394\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.7514 - val_loss: 1.5227 - val_accuracy: 0.5100\n",
            "epochs : 395\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.7500 - val_loss: 1.5440 - val_accuracy: 0.5267\n",
            "epochs : 396\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.7471 - val_loss: 1.5237 - val_accuracy: 0.5167\n",
            "epochs : 397\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.7486 - val_loss: 1.5223 - val_accuracy: 0.5133\n",
            "epochs : 398\n",
            "57/70 [=======================>......] - ETA: 0s - loss: 0.7047 - accuracy: 0.7491WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0019s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.7500 - val_loss: 1.5374 - val_accuracy: 0.5100\n",
            "epochs : 399\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.7543 - val_loss: 1.5251 - val_accuracy: 0.5100\n",
            "epochs : 400\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.7529 - val_loss: 1.5355 - val_accuracy: 0.5067\n",
            "epochs : 401\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.7543 - val_loss: 1.5329 - val_accuracy: 0.5133\n",
            "epochs : 402\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.7443 - val_loss: 1.5424 - val_accuracy: 0.5067\n",
            "epochs : 403\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.7514 - val_loss: 1.5530 - val_accuracy: 0.5100\n",
            "epochs : 404\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.7571 - val_loss: 1.5331 - val_accuracy: 0.5133\n",
            "epochs : 405\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.7529 - val_loss: 1.5401 - val_accuracy: 0.5100\n",
            "epochs : 406\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.7586 - val_loss: 1.5501 - val_accuracy: 0.5167\n",
            "epochs : 407\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.7557 - val_loss: 1.5386 - val_accuracy: 0.5133\n",
            "epochs : 408\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.7557 - val_loss: 1.5246 - val_accuracy: 0.5133\n",
            "epochs : 409\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.7471 - val_loss: 1.5415 - val_accuracy: 0.5067\n",
            "epochs : 410\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.7457 - val_loss: 1.5475 - val_accuracy: 0.5067\n",
            "epochs : 411\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.7557 - val_loss: 1.5615 - val_accuracy: 0.5100\n",
            "epochs : 412\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.7557 - val_loss: 1.5496 - val_accuracy: 0.5067\n",
            "epochs : 413\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.7557 - val_loss: 1.5356 - val_accuracy: 0.5067\n",
            "epochs : 414\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.7557 - val_loss: 1.5393 - val_accuracy: 0.5100\n",
            "epochs : 415\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.7529 - val_loss: 1.5504 - val_accuracy: 0.5033\n",
            "epochs : 416\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.7557 - val_loss: 1.5644 - val_accuracy: 0.5067\n",
            "epochs : 417\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.7529 - val_loss: 1.5477 - val_accuracy: 0.5133\n",
            "epochs : 418\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.7571 - val_loss: 1.5648 - val_accuracy: 0.5133\n",
            "epochs : 419\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.7529 - val_loss: 1.5478 - val_accuracy: 0.5033\n",
            "epochs : 420\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7586 - val_loss: 1.5401 - val_accuracy: 0.5167\n",
            "epochs : 421\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.7571 - val_loss: 1.5635 - val_accuracy: 0.5033\n",
            "epochs : 422\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.7571 - val_loss: 1.5869 - val_accuracy: 0.5100\n",
            "epochs : 423\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.7643 - val_loss: 1.5548 - val_accuracy: 0.5100\n",
            "epochs : 424\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.7557 - val_loss: 1.5705 - val_accuracy: 0.5033\n",
            "epochs : 425\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.7638 - accuracy: 0.6000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.7514 - val_loss: 1.5644 - val_accuracy: 0.5000\n",
            "epochs : 426\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.7586 - val_loss: 1.5675 - val_accuracy: 0.4967\n",
            "epochs : 427\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7629 - val_loss: 1.5778 - val_accuracy: 0.5100\n",
            "epochs : 428\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.7571 - val_loss: 1.5757 - val_accuracy: 0.5067\n",
            "epochs : 429\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.7586 - val_loss: 1.5720 - val_accuracy: 0.5033\n",
            "epochs : 430\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.7614 - val_loss: 1.5620 - val_accuracy: 0.5100\n",
            "epochs : 431\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.7571 - val_loss: 1.5566 - val_accuracy: 0.5167\n",
            "epochs : 432\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.7600 - val_loss: 1.5705 - val_accuracy: 0.5033\n",
            "epochs : 433\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.7586 - val_loss: 1.5711 - val_accuracy: 0.5033\n",
            "epochs : 434\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.7600 - val_loss: 1.5829 - val_accuracy: 0.5000\n",
            "epochs : 435\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.7600 - val_loss: 1.5684 - val_accuracy: 0.5067\n",
            "epochs : 436\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.7614 - val_loss: 1.5749 - val_accuracy: 0.5000\n",
            "epochs : 437\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.7586 - val_loss: 1.5824 - val_accuracy: 0.5067\n",
            "epochs : 438\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.7571 - val_loss: 1.5690 - val_accuracy: 0.5033\n",
            "epochs : 439\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.7586 - val_loss: 1.5764 - val_accuracy: 0.5067\n",
            "epochs : 440\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.7614 - val_loss: 1.5770 - val_accuracy: 0.5100\n",
            "epochs : 441\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.7543 - val_loss: 1.5717 - val_accuracy: 0.5067\n",
            "epochs : 442\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.7529 - val_loss: 1.5845 - val_accuracy: 0.5000\n",
            "epochs : 443\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7586 - val_loss: 1.5849 - val_accuracy: 0.5033\n",
            "epochs : 444\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7586 - val_loss: 1.5834 - val_accuracy: 0.5033\n",
            "epochs : 445\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.7614 - val_loss: 1.5691 - val_accuracy: 0.5100\n",
            "epochs : 446\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7600 - val_loss: 1.5722 - val_accuracy: 0.5133\n",
            "epochs : 447\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.7571 - val_loss: 1.5982 - val_accuracy: 0.5000\n",
            "epochs : 448\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.7657 - val_loss: 1.5868 - val_accuracy: 0.5000\n",
            "epochs : 449\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.7557 - val_loss: 1.5918 - val_accuracy: 0.5000\n",
            "epochs : 450\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.7629 - val_loss: 1.5895 - val_accuracy: 0.4967\n",
            "epochs : 451\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.7657 - val_loss: 1.5987 - val_accuracy: 0.5067\n",
            "epochs : 452\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.7657 - val_loss: 1.5853 - val_accuracy: 0.5100\n",
            "epochs : 453\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7629 - val_loss: 1.6039 - val_accuracy: 0.4967\n",
            "epochs : 454\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.7629 - val_loss: 1.6354 - val_accuracy: 0.4967\n",
            "epochs : 455\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.7671 - val_loss: 1.6037 - val_accuracy: 0.4967\n",
            "epochs : 456\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.7600 - val_loss: 1.6164 - val_accuracy: 0.4967\n",
            "epochs : 457\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.7671 - val_loss: 1.6268 - val_accuracy: 0.4933\n",
            "epochs : 458\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.7643 - val_loss: 1.6002 - val_accuracy: 0.4967\n",
            "epochs : 459\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.7657 - val_loss: 1.6102 - val_accuracy: 0.5033\n",
            "epochs : 460\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.7643 - val_loss: 1.6312 - val_accuracy: 0.4900\n",
            "epochs : 461\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.7657 - val_loss: 1.6137 - val_accuracy: 0.5000\n",
            "epochs : 462\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.7700 - val_loss: 1.6100 - val_accuracy: 0.5000\n",
            "epochs : 463\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7700 - val_loss: 1.6415 - val_accuracy: 0.5067\n",
            "epochs : 464\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.7671 - val_loss: 1.6004 - val_accuracy: 0.4967\n",
            "epochs : 465\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.7643 - val_loss: 1.6116 - val_accuracy: 0.5000\n",
            "epochs : 466\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.7657 - val_loss: 1.6040 - val_accuracy: 0.4967\n",
            "epochs : 467\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.7657 - val_loss: 1.6132 - val_accuracy: 0.5000\n",
            "epochs : 468\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.7714 - val_loss: 1.6160 - val_accuracy: 0.4967\n",
            "epochs : 469\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.7714 - val_loss: 1.6187 - val_accuracy: 0.5067\n",
            "epochs : 470\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.7700 - val_loss: 1.6200 - val_accuracy: 0.4967\n",
            "epochs : 471\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.7686 - val_loss: 1.6271 - val_accuracy: 0.4900\n",
            "epochs : 472\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.7686 - val_loss: 1.6241 - val_accuracy: 0.4933\n",
            "epochs : 473\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.7714 - val_loss: 1.6223 - val_accuracy: 0.4900\n",
            "epochs : 474\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.7686 - val_loss: 1.6278 - val_accuracy: 0.5000\n",
            "epochs : 475\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7657 - val_loss: 1.6190 - val_accuracy: 0.4933\n",
            "epochs : 476\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.7714 - val_loss: 1.6282 - val_accuracy: 0.4933\n",
            "epochs : 477\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7771 - val_loss: 1.6324 - val_accuracy: 0.4833\n",
            "epochs : 478\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.7657 - val_loss: 1.6330 - val_accuracy: 0.4967\n",
            "epochs : 479\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7714 - val_loss: 1.6299 - val_accuracy: 0.4933\n",
            "epochs : 480\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.7771 - val_loss: 1.6412 - val_accuracy: 0.4900\n",
            "epochs : 481\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7714 - val_loss: 1.6408 - val_accuracy: 0.4967\n",
            "epochs : 482\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.7671 - val_loss: 1.6452 - val_accuracy: 0.4933\n",
            "epochs : 483\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7714 - val_loss: 1.6358 - val_accuracy: 0.4933\n",
            "epochs : 484\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7700 - val_loss: 1.6463 - val_accuracy: 0.4933\n",
            "epochs : 485\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.7729 - val_loss: 1.6431 - val_accuracy: 0.5000\n",
            "epochs : 486\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7714 - val_loss: 1.6641 - val_accuracy: 0.4867\n",
            "epochs : 487\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.7729 - val_loss: 1.6582 - val_accuracy: 0.4900\n",
            "epochs : 488\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7729 - val_loss: 1.6719 - val_accuracy: 0.4867\n",
            "epochs : 489\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7729 - val_loss: 1.6469 - val_accuracy: 0.4933\n",
            "epochs : 490\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.7743 - val_loss: 1.6358 - val_accuracy: 0.5067\n",
            "epochs : 491\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7657 - val_loss: 1.6489 - val_accuracy: 0.5000\n",
            "epochs : 492\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7729 - val_loss: 1.6376 - val_accuracy: 0.4967\n",
            "epochs : 493\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.7743 - val_loss: 1.6377 - val_accuracy: 0.4933\n",
            "epochs : 494\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7743 - val_loss: 1.6484 - val_accuracy: 0.4933\n",
            "epochs : 495\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7743 - val_loss: 1.6404 - val_accuracy: 0.4833\n",
            "epochs : 496\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.7714 - val_loss: 1.6570 - val_accuracy: 0.4967\n",
            "epochs : 497\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7786 - val_loss: 1.6419 - val_accuracy: 0.4933\n",
            "epochs : 498\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7729 - val_loss: 1.6498 - val_accuracy: 0.4933\n",
            "epochs : 499\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.7714 - val_loss: 1.6485 - val_accuracy: 0.4933\n",
            "epochs : 500\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7729 - val_loss: 1.6445 - val_accuracy: 0.4967\n",
            "epochs : 501\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7729 - val_loss: 1.6618 - val_accuracy: 0.4900\n",
            "epochs : 502\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7686 - val_loss: 1.6625 - val_accuracy: 0.4867\n",
            "epochs : 503\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7757 - val_loss: 1.6589 - val_accuracy: 0.4900\n",
            "epochs : 504\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7771 - val_loss: 1.6653 - val_accuracy: 0.4867\n",
            "epochs : 505\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7729 - val_loss: 1.6796 - val_accuracy: 0.4900\n",
            "epochs : 506\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7714 - val_loss: 1.6651 - val_accuracy: 0.4967\n",
            "epochs : 507\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7743 - val_loss: 1.6776 - val_accuracy: 0.4867\n",
            "epochs : 508\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7729 - val_loss: 1.6736 - val_accuracy: 0.4867\n",
            "epochs : 509\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.3819 - accuracy: 0.8000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7829 - val_loss: 1.6772 - val_accuracy: 0.4967\n",
            "epochs : 510\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7771 - val_loss: 1.6718 - val_accuracy: 0.4867\n",
            "epochs : 511\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7800 - val_loss: 1.6805 - val_accuracy: 0.4867\n",
            "epochs : 512\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.7786 - val_loss: 1.6810 - val_accuracy: 0.4900\n",
            "epochs : 513\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7800 - val_loss: 1.6699 - val_accuracy: 0.4933\n",
            "epochs : 514\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7829 - val_loss: 1.7139 - val_accuracy: 0.4800\n",
            "epochs : 515\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7771 - val_loss: 1.6750 - val_accuracy: 0.4933\n",
            "epochs : 516\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.7743 - val_loss: 1.6743 - val_accuracy: 0.4867\n",
            "epochs : 517\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7843 - val_loss: 1.6774 - val_accuracy: 0.5000\n",
            "epochs : 518\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7814 - val_loss: 1.6835 - val_accuracy: 0.4900\n",
            "epochs : 519\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7800 - val_loss: 1.6952 - val_accuracy: 0.4867\n",
            "epochs : 520\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7729 - val_loss: 1.6758 - val_accuracy: 0.4900\n",
            "epochs : 521\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.7857 - val_loss: 1.7093 - val_accuracy: 0.4833\n",
            "epochs : 522\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7800 - val_loss: 1.6878 - val_accuracy: 0.4900\n",
            "epochs : 523\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.7829 - val_loss: 1.6869 - val_accuracy: 0.4967\n",
            "epochs : 524\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.7771 - val_loss: 1.7042 - val_accuracy: 0.4767\n",
            "epochs : 525\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.7843 - val_loss: 1.6903 - val_accuracy: 0.4867\n",
            "epochs : 526\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7829 - val_loss: 1.6808 - val_accuracy: 0.4933\n",
            "epochs : 527\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.7857 - val_loss: 1.7046 - val_accuracy: 0.4900\n",
            "epochs : 528\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.7786 - val_loss: 1.6929 - val_accuracy: 0.4933\n",
            "epochs : 529\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7857 - val_loss: 1.6925 - val_accuracy: 0.4900\n",
            "epochs : 530\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.7843 - val_loss: 1.7024 - val_accuracy: 0.4867\n",
            "epochs : 531\n",
            "61/70 [=========================>....] - ETA: 0s - loss: 0.6330 - accuracy: 0.7885WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_test_batch_end` time: 0.0031s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.7814 - val_loss: 1.7118 - val_accuracy: 0.4767\n",
            "epochs : 532\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.7743 - val_loss: 1.7115 - val_accuracy: 0.4867\n",
            "epochs : 533\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.7843 - val_loss: 1.6919 - val_accuracy: 0.4967\n",
            "epochs : 534\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.7843 - val_loss: 1.7055 - val_accuracy: 0.4900\n",
            "epochs : 535\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.7857 - val_loss: 1.7199 - val_accuracy: 0.4867\n",
            "epochs : 536\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.7814 - val_loss: 1.6886 - val_accuracy: 0.4967\n",
            "epochs : 537\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7814 - val_loss: 1.6964 - val_accuracy: 0.4967\n",
            "epochs : 538\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7886 - val_loss: 1.7234 - val_accuracy: 0.4833\n",
            "epochs : 539\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.7857 - val_loss: 1.7051 - val_accuracy: 0.4933\n",
            "epochs : 540\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7829 - val_loss: 1.7194 - val_accuracy: 0.4800\n",
            "epochs : 541\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.7743 - val_loss: 1.7136 - val_accuracy: 0.4933\n",
            "epochs : 542\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.6226 - accuracy: 0.7857 - val_loss: 1.6933 - val_accuracy: 0.4967\n",
            "epochs : 543\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.7814 - val_loss: 1.7204 - val_accuracy: 0.4867\n",
            "epochs : 544\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7786 - val_loss: 1.7199 - val_accuracy: 0.4867\n",
            "epochs : 545\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7814 - val_loss: 1.7080 - val_accuracy: 0.5000\n",
            "epochs : 546\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.7843 - val_loss: 1.7191 - val_accuracy: 0.4900\n",
            "epochs : 547\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7857 - val_loss: 1.7319 - val_accuracy: 0.4800\n",
            "epochs : 548\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7829 - val_loss: 1.7233 - val_accuracy: 0.4933\n",
            "epochs : 549\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7857 - val_loss: 1.7266 - val_accuracy: 0.4867\n",
            "epochs : 550\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7871 - val_loss: 1.7240 - val_accuracy: 0.4900\n",
            "epochs : 551\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7914 - val_loss: 1.7363 - val_accuracy: 0.4767\n",
            "epochs : 552\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7857 - val_loss: 1.7330 - val_accuracy: 0.4933\n",
            "epochs : 553\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7871 - val_loss: 1.7301 - val_accuracy: 0.4900\n",
            "epochs : 554\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.7871 - val_loss: 1.7400 - val_accuracy: 0.4900\n",
            "epochs : 555\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.7914 - val_loss: 1.7340 - val_accuracy: 0.4933\n",
            "epochs : 556\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.7857 - val_loss: 1.7266 - val_accuracy: 0.4900\n",
            "epochs : 557\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7900 - val_loss: 1.7354 - val_accuracy: 0.4900\n",
            "epochs : 558\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7857 - val_loss: 1.7386 - val_accuracy: 0.4933\n",
            "epochs : 559\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.7871 - val_loss: 1.7341 - val_accuracy: 0.4900\n",
            "epochs : 560\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.7929 - val_loss: 1.7296 - val_accuracy: 0.4933\n",
            "epochs : 561\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.7857 - val_loss: 1.7308 - val_accuracy: 0.4933\n",
            "epochs : 562\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.7871 - val_loss: 1.7303 - val_accuracy: 0.4933\n",
            "epochs : 563\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.7900 - val_loss: 1.7471 - val_accuracy: 0.4900\n",
            "epochs : 564\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.7900 - val_loss: 1.7527 - val_accuracy: 0.4867\n",
            "epochs : 565\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.7900 - val_loss: 1.7428 - val_accuracy: 0.4900\n",
            "epochs : 566\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.7886 - val_loss: 1.7464 - val_accuracy: 0.4900\n",
            "epochs : 567\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7929 - val_loss: 1.7428 - val_accuracy: 0.4900\n",
            "epochs : 568\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7900 - val_loss: 1.7542 - val_accuracy: 0.4833\n",
            "epochs : 569\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.7900 - val_loss: 1.7405 - val_accuracy: 0.4933\n",
            "epochs : 570\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.7914 - val_loss: 1.7417 - val_accuracy: 0.4933\n",
            "epochs : 571\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.7871 - val_loss: 1.7336 - val_accuracy: 0.4933\n",
            "epochs : 572\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.7929 - val_loss: 1.7529 - val_accuracy: 0.4867\n",
            "epochs : 573\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7871 - val_loss: 1.7493 - val_accuracy: 0.4900\n",
            "epochs : 574\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.7914 - val_loss: 1.7462 - val_accuracy: 0.4900\n",
            "epochs : 575\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7929 - val_loss: 1.7556 - val_accuracy: 0.5000\n",
            "epochs : 576\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7886 - val_loss: 1.7605 - val_accuracy: 0.4900\n",
            "epochs : 577\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.7914 - val_loss: 1.7611 - val_accuracy: 0.4867\n",
            "epochs : 578\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7957 - val_loss: 1.7660 - val_accuracy: 0.4933\n",
            "epochs : 579\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.7957 - val_loss: 1.7664 - val_accuracy: 0.4867\n",
            "epochs : 580\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.7871 - val_loss: 1.7556 - val_accuracy: 0.4900\n",
            "epochs : 581\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7886 - val_loss: 1.7826 - val_accuracy: 0.4767\n",
            "epochs : 582\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7886 - val_loss: 1.7684 - val_accuracy: 0.4900\n",
            "epochs : 583\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.7957 - val_loss: 1.7605 - val_accuracy: 0.4867\n",
            "epochs : 584\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.6008 - accuracy: 0.7909WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0025s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7886 - val_loss: 1.7730 - val_accuracy: 0.4867\n",
            "epochs : 585\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7900 - val_loss: 1.7727 - val_accuracy: 0.4833\n",
            "epochs : 586\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7943 - val_loss: 1.7841 - val_accuracy: 0.4833\n",
            "epochs : 587\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.7971 - val_loss: 1.7647 - val_accuracy: 0.4867\n",
            "epochs : 588\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.7929 - val_loss: 1.8021 - val_accuracy: 0.4733\n",
            "epochs : 589\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.7957 - val_loss: 1.7830 - val_accuracy: 0.4867\n",
            "epochs : 590\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7957 - val_loss: 1.7908 - val_accuracy: 0.4800\n",
            "epochs : 591\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.7943 - val_loss: 1.7783 - val_accuracy: 0.4867\n",
            "epochs : 592\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7929 - val_loss: 1.7856 - val_accuracy: 0.4833\n",
            "epochs : 593\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.7871 - val_loss: 1.7996 - val_accuracy: 0.4833\n",
            "epochs : 594\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.7929 - val_loss: 1.7835 - val_accuracy: 0.4833\n",
            "epochs : 595\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7986 - val_loss: 1.7915 - val_accuracy: 0.4800\n",
            "epochs : 596\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7957 - val_loss: 1.7737 - val_accuracy: 0.4933\n",
            "epochs : 597\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7986 - val_loss: 1.7908 - val_accuracy: 0.4833\n",
            "epochs : 598\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7914 - val_loss: 1.7880 - val_accuracy: 0.4833\n",
            "epochs : 599\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7943 - val_loss: 1.7887 - val_accuracy: 0.4867\n",
            "epochs : 600\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.8000 - val_loss: 1.8185 - val_accuracy: 0.4767\n",
            "epochs : 601\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7943 - val_loss: 1.7772 - val_accuracy: 0.4833\n",
            "epochs : 602\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.8014 - val_loss: 1.8123 - val_accuracy: 0.4867\n",
            "epochs : 603\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7943 - val_loss: 1.8061 - val_accuracy: 0.4900\n",
            "epochs : 604\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7957 - val_loss: 1.8016 - val_accuracy: 0.4867\n",
            "epochs : 605\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7929 - val_loss: 1.8010 - val_accuracy: 0.4833\n",
            "epochs : 606\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7957 - val_loss: 1.8039 - val_accuracy: 0.4867\n",
            "epochs : 607\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7986 - val_loss: 1.8014 - val_accuracy: 0.4833\n",
            "epochs : 608\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.7971 - val_loss: 1.8046 - val_accuracy: 0.4900\n",
            "epochs : 609\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7914 - val_loss: 1.7944 - val_accuracy: 0.4800\n",
            "epochs : 610\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7971 - val_loss: 1.8179 - val_accuracy: 0.4900\n",
            "epochs : 611\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7957 - val_loss: 1.8069 - val_accuracy: 0.4833\n",
            "epochs : 612\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.7900 - val_loss: 1.8102 - val_accuracy: 0.4900\n",
            "epochs : 613\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7957 - val_loss: 1.7972 - val_accuracy: 0.4833\n",
            "epochs : 614\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7914 - val_loss: 1.8058 - val_accuracy: 0.4867\n",
            "epochs : 615\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7943 - val_loss: 1.8088 - val_accuracy: 0.4833\n",
            "epochs : 616\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7971 - val_loss: 1.8367 - val_accuracy: 0.4767\n",
            "epochs : 617\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7943 - val_loss: 1.8146 - val_accuracy: 0.4900\n",
            "epochs : 618\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7986 - val_loss: 1.8129 - val_accuracy: 0.4933\n",
            "epochs : 619\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7914 - val_loss: 1.8217 - val_accuracy: 0.4867\n",
            "epochs : 620\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.8000 - val_loss: 1.8108 - val_accuracy: 0.4900\n",
            "epochs : 621\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7943 - val_loss: 1.8287 - val_accuracy: 0.4867\n",
            "epochs : 622\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7957 - val_loss: 1.8097 - val_accuracy: 0.4867\n",
            "epochs : 623\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.8000 - val_loss: 1.8171 - val_accuracy: 0.4933\n",
            "epochs : 624\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.8000 - val_loss: 1.8207 - val_accuracy: 0.4867\n",
            "epochs : 625\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.8029 - val_loss: 1.8502 - val_accuracy: 0.4733\n",
            "epochs : 626\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7957 - val_loss: 1.8652 - val_accuracy: 0.4733\n",
            "epochs : 627\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.8000 - val_loss: 1.8257 - val_accuracy: 0.4833\n",
            "epochs : 628\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.8043 - val_loss: 1.8390 - val_accuracy: 0.4867\n",
            "epochs : 629\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7943 - val_loss: 1.8138 - val_accuracy: 0.4800\n",
            "epochs : 630\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7971 - val_loss: 1.8200 - val_accuracy: 0.4867\n",
            "epochs : 631\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.8029 - val_loss: 1.8356 - val_accuracy: 0.4867\n",
            "epochs : 632\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7986 - val_loss: 1.8289 - val_accuracy: 0.4833\n",
            "epochs : 633\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.8000 - val_loss: 1.8272 - val_accuracy: 0.4900\n",
            "epochs : 634\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.8000 - val_loss: 1.8390 - val_accuracy: 0.4833\n",
            "epochs : 635\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.8043 - val_loss: 1.8324 - val_accuracy: 0.4867\n",
            "epochs : 636\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.8014 - val_loss: 1.8309 - val_accuracy: 0.4900\n",
            "epochs : 637\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.8000 - val_loss: 1.8433 - val_accuracy: 0.4833\n",
            "epochs : 638\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.8000 - val_loss: 1.8381 - val_accuracy: 0.4833\n",
            "epochs : 639\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.8057 - val_loss: 1.8306 - val_accuracy: 0.4733\n",
            "epochs : 640\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.8043 - val_loss: 1.8442 - val_accuracy: 0.4867\n",
            "epochs : 641\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8000 - val_loss: 1.8499 - val_accuracy: 0.4833\n",
            "epochs : 642\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8057 - val_loss: 1.8456 - val_accuracy: 0.4767\n",
            "epochs : 643\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.8057 - val_loss: 1.8667 - val_accuracy: 0.4833\n",
            "epochs : 644\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.8057 - val_loss: 1.8539 - val_accuracy: 0.4767\n",
            "epochs : 645\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.8029 - val_loss: 1.8530 - val_accuracy: 0.4833\n",
            "epochs : 646\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.8014 - val_loss: 1.8501 - val_accuracy: 0.4833\n",
            "epochs : 647\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.8014 - val_loss: 1.8522 - val_accuracy: 0.4867\n",
            "epochs : 648\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.8029 - val_loss: 1.8649 - val_accuracy: 0.4833\n",
            "epochs : 649\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.8014 - val_loss: 1.8513 - val_accuracy: 0.4833\n",
            "epochs : 650\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.8100 - val_loss: 1.8547 - val_accuracy: 0.4867\n",
            "epochs : 651\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.8043 - val_loss: 1.8558 - val_accuracy: 0.4867\n",
            "epochs : 652\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.8029 - val_loss: 1.8713 - val_accuracy: 0.4833\n",
            "epochs : 653\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.8071 - val_loss: 1.8676 - val_accuracy: 0.4833\n",
            "epochs : 654\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.8000 - val_loss: 1.8720 - val_accuracy: 0.4767\n",
            "epochs : 655\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.8071 - val_loss: 1.8566 - val_accuracy: 0.4833\n",
            "epochs : 656\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.8014 - val_loss: 1.8592 - val_accuracy: 0.4833\n",
            "epochs : 657\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.8086 - val_loss: 1.8812 - val_accuracy: 0.4800\n",
            "epochs : 658\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.8057 - val_loss: 1.8665 - val_accuracy: 0.4867\n",
            "epochs : 659\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.8029 - val_loss: 1.8822 - val_accuracy: 0.4767\n",
            "epochs : 660\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.8086 - val_loss: 1.8804 - val_accuracy: 0.4833\n",
            "epochs : 661\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.8043 - val_loss: 1.8633 - val_accuracy: 0.4833\n",
            "epochs : 662\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.8043 - val_loss: 1.8763 - val_accuracy: 0.4800\n",
            "epochs : 663\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.8100 - val_loss: 1.8738 - val_accuracy: 0.4833\n",
            "epochs : 664\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.8014 - val_loss: 1.8754 - val_accuracy: 0.4833\n",
            "epochs : 665\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.8043 - val_loss: 1.8716 - val_accuracy: 0.4800\n",
            "epochs : 666\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.8029 - val_loss: 1.8848 - val_accuracy: 0.4867\n",
            "epochs : 667\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.8071 - val_loss: 1.8855 - val_accuracy: 0.4833\n",
            "epochs : 668\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.8086 - val_loss: 1.8837 - val_accuracy: 0.4800\n",
            "epochs : 669\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.8086 - val_loss: 1.8882 - val_accuracy: 0.4800\n",
            "epochs : 670\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.8100 - val_loss: 1.8919 - val_accuracy: 0.4800\n",
            "epochs : 671\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.8071 - val_loss: 1.8975 - val_accuracy: 0.4833\n",
            "epochs : 672\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.8043 - val_loss: 1.8956 - val_accuracy: 0.4833\n",
            "epochs : 673\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.8043 - val_loss: 1.8785 - val_accuracy: 0.4800\n",
            "epochs : 674\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8086 - val_loss: 1.8915 - val_accuracy: 0.4800\n",
            "epochs : 675\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.8043 - val_loss: 1.8953 - val_accuracy: 0.4800\n",
            "epochs : 676\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.8114 - val_loss: 1.9042 - val_accuracy: 0.4833\n",
            "epochs : 677\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.8086 - val_loss: 1.8928 - val_accuracy: 0.4800\n",
            "epochs : 678\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.8086 - val_loss: 1.8835 - val_accuracy: 0.4800\n",
            "epochs : 679\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.8086 - val_loss: 1.8803 - val_accuracy: 0.4800\n",
            "epochs : 680\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.8114 - val_loss: 1.8768 - val_accuracy: 0.4800\n",
            "epochs : 681\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.8100 - val_loss: 1.8949 - val_accuracy: 0.4833\n",
            "epochs : 682\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.8100 - val_loss: 1.9063 - val_accuracy: 0.4800\n",
            "epochs : 683\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.8086 - val_loss: 1.9000 - val_accuracy: 0.4800\n",
            "epochs : 684\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.8129 - val_loss: 1.9018 - val_accuracy: 0.4800\n",
            "epochs : 685\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.8157 - val_loss: 1.9043 - val_accuracy: 0.4800\n",
            "epochs : 686\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.8086 - val_loss: 1.9023 - val_accuracy: 0.4867\n",
            "epochs : 687\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.8071 - val_loss: 1.9143 - val_accuracy: 0.4800\n",
            "epochs : 688\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.8114 - val_loss: 1.9133 - val_accuracy: 0.4767\n",
            "epochs : 689\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.8129 - val_loss: 1.9142 - val_accuracy: 0.4767\n",
            "epochs : 690\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.8100 - val_loss: 1.9094 - val_accuracy: 0.4833\n",
            "epochs : 691\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.8100 - val_loss: 1.9122 - val_accuracy: 0.4767\n",
            "epochs : 692\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.8114 - val_loss: 1.9148 - val_accuracy: 0.4867\n",
            "epochs : 693\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.8157 - val_loss: 1.9176 - val_accuracy: 0.4767\n",
            "epochs : 694\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.8100 - val_loss: 1.9202 - val_accuracy: 0.4800\n",
            "epochs : 695\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.8114 - val_loss: 1.9050 - val_accuracy: 0.4800\n",
            "epochs : 696\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.8114 - val_loss: 1.9085 - val_accuracy: 0.4800\n",
            "epochs : 697\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.8114 - val_loss: 1.9025 - val_accuracy: 0.4833\n",
            "epochs : 698\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.8129 - val_loss: 1.9366 - val_accuracy: 0.4800\n",
            "epochs : 699\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.8171 - val_loss: 1.9304 - val_accuracy: 0.4800\n",
            "epochs : 700\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.8114 - val_loss: 1.9375 - val_accuracy: 0.4833\n",
            "epochs : 701\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.8171 - val_loss: 1.9422 - val_accuracy: 0.4733\n",
            "epochs : 702\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.8114 - val_loss: 1.9313 - val_accuracy: 0.4800\n",
            "epochs : 703\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.8129 - val_loss: 1.9340 - val_accuracy: 0.4833\n",
            "epochs : 704\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.8143 - val_loss: 1.9421 - val_accuracy: 0.4833\n",
            "epochs : 705\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.8157 - val_loss: 1.9422 - val_accuracy: 0.4800\n",
            "epochs : 706\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.8100 - val_loss: 1.9195 - val_accuracy: 0.4833\n",
            "epochs : 707\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.8143 - val_loss: 1.9305 - val_accuracy: 0.4733\n",
            "epochs : 708\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.8100 - val_loss: 1.9370 - val_accuracy: 0.4800\n",
            "epochs : 709\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.8100 - val_loss: 1.9342 - val_accuracy: 0.4767\n",
            "epochs : 710\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.8157 - val_loss: 1.9361 - val_accuracy: 0.4867\n",
            "epochs : 711\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.8157 - val_loss: 1.9361 - val_accuracy: 0.4700\n",
            "epochs : 712\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.8157 - val_loss: 1.9392 - val_accuracy: 0.4800\n",
            "epochs : 713\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.8171 - val_loss: 1.9327 - val_accuracy: 0.4733\n",
            "epochs : 714\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.8143 - val_loss: 1.9492 - val_accuracy: 0.4800\n",
            "epochs : 715\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.4199 - accuracy: 0.9000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0043s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.8200 - val_loss: 1.9380 - val_accuracy: 0.4700\n",
            "epochs : 716\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.8157 - val_loss: 1.9441 - val_accuracy: 0.4733\n",
            "epochs : 717\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.8157 - val_loss: 1.9500 - val_accuracy: 0.4733\n",
            "epochs : 718\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.8157 - val_loss: 1.9464 - val_accuracy: 0.4767\n",
            "epochs : 719\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.8143 - val_loss: 1.9696 - val_accuracy: 0.4767\n",
            "epochs : 720\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.8186 - val_loss: 1.9524 - val_accuracy: 0.4767\n",
            "epochs : 721\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.8171 - val_loss: 1.9538 - val_accuracy: 0.4733\n",
            "epochs : 722\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.8129 - val_loss: 1.9476 - val_accuracy: 0.4833\n",
            "epochs : 723\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.8171 - val_loss: 1.9603 - val_accuracy: 0.4733\n",
            "epochs : 724\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.8143 - val_loss: 1.9582 - val_accuracy: 0.4733\n",
            "epochs : 725\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.8200 - val_loss: 1.9557 - val_accuracy: 0.4700\n",
            "epochs : 726\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.8157 - val_loss: 1.9808 - val_accuracy: 0.4700\n",
            "epochs : 727\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.8171 - val_loss: 1.9546 - val_accuracy: 0.4867\n",
            "epochs : 728\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.8171 - val_loss: 1.9733 - val_accuracy: 0.4733\n",
            "epochs : 729\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.8143 - val_loss: 1.9621 - val_accuracy: 0.4767\n",
            "epochs : 730\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.8186 - val_loss: 1.9708 - val_accuracy: 0.4700\n",
            "epochs : 731\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.8143 - val_loss: 1.9819 - val_accuracy: 0.4767\n",
            "epochs : 732\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.8157 - val_loss: 1.9631 - val_accuracy: 0.4767\n",
            "epochs : 733\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.8157 - val_loss: 1.9526 - val_accuracy: 0.4800\n",
            "epochs : 734\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8171 - val_loss: 1.9713 - val_accuracy: 0.4700\n",
            "epochs : 735\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.8200 - val_loss: 1.9923 - val_accuracy: 0.4767\n",
            "epochs : 736\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.8186 - val_loss: 1.9949 - val_accuracy: 0.4800\n",
            "epochs : 737\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.8214 - val_loss: 1.9769 - val_accuracy: 0.4733\n",
            "epochs : 738\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.8200 - val_loss: 1.9818 - val_accuracy: 0.4733\n",
            "epochs : 739\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.8186 - val_loss: 1.9758 - val_accuracy: 0.4733\n",
            "epochs : 740\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.8143 - val_loss: 1.9685 - val_accuracy: 0.4833\n",
            "epochs : 741\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.8129 - val_loss: 1.9891 - val_accuracy: 0.4767\n",
            "epochs : 742\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8171 - val_loss: 1.9649 - val_accuracy: 0.4767\n",
            "epochs : 743\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.8243 - val_loss: 1.9752 - val_accuracy: 0.4700\n",
            "epochs : 744\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.8186 - val_loss: 1.9832 - val_accuracy: 0.4767\n",
            "epochs : 745\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.8186 - val_loss: 1.9700 - val_accuracy: 0.4800\n",
            "epochs : 746\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.8143 - val_loss: 1.9902 - val_accuracy: 0.4733\n",
            "epochs : 747\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.8186 - val_loss: 1.9766 - val_accuracy: 0.4867\n",
            "epochs : 748\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.8186 - val_loss: 1.9804 - val_accuracy: 0.4800\n",
            "epochs : 749\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.8171 - val_loss: 2.0066 - val_accuracy: 0.4700\n",
            "epochs : 750\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.8214 - val_loss: 1.9984 - val_accuracy: 0.4733\n",
            "epochs : 751\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.8200 - val_loss: 1.9982 - val_accuracy: 0.4667\n",
            "epochs : 752\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.8171 - val_loss: 1.9816 - val_accuracy: 0.4800\n",
            "epochs : 753\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8157 - val_loss: 2.0002 - val_accuracy: 0.4700\n",
            "epochs : 754\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.4679 - accuracy: 0.9000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0059s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.8186 - val_loss: 1.9874 - val_accuracy: 0.4733\n",
            "epochs : 755\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.8171 - val_loss: 1.9943 - val_accuracy: 0.4767\n",
            "epochs : 756\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.8200 - val_loss: 2.0026 - val_accuracy: 0.4700\n",
            "epochs : 757\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.8214 - val_loss: 2.0176 - val_accuracy: 0.4733\n",
            "epochs : 758\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.8229 - val_loss: 2.0032 - val_accuracy: 0.4733\n",
            "epochs : 759\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.8214 - val_loss: 2.0112 - val_accuracy: 0.4700\n",
            "epochs : 760\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.8200 - val_loss: 1.9962 - val_accuracy: 0.4800\n",
            "epochs : 761\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.4623 - accuracy: 0.7000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.8200 - val_loss: 2.0077 - val_accuracy: 0.4700\n",
            "epochs : 762\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.8171 - val_loss: 2.0069 - val_accuracy: 0.4633\n",
            "epochs : 763\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.8200 - val_loss: 1.9915 - val_accuracy: 0.4833\n",
            "epochs : 764\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.8214 - val_loss: 2.0079 - val_accuracy: 0.4733\n",
            "epochs : 765\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.8200 - val_loss: 2.0127 - val_accuracy: 0.4733\n",
            "epochs : 766\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.8200 - val_loss: 2.0236 - val_accuracy: 0.4733\n",
            "epochs : 767\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.8214 - val_loss: 2.0092 - val_accuracy: 0.4767\n",
            "epochs : 768\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.8214 - val_loss: 2.0123 - val_accuracy: 0.4667\n",
            "epochs : 769\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.8200 - val_loss: 2.0218 - val_accuracy: 0.4767\n",
            "epochs : 770\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.8257 - val_loss: 2.0309 - val_accuracy: 0.4733\n",
            "epochs : 771\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.8200 - val_loss: 2.0149 - val_accuracy: 0.4833\n",
            "epochs : 772\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.8243 - val_loss: 2.0282 - val_accuracy: 0.4733\n",
            "epochs : 773\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.3473 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0102s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.8229 - val_loss: 2.0330 - val_accuracy: 0.4733\n",
            "epochs : 774\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.8186 - val_loss: 2.0134 - val_accuracy: 0.4700\n",
            "epochs : 775\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.8243 - val_loss: 2.0149 - val_accuracy: 0.4700\n",
            "epochs : 776\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.8229 - val_loss: 2.0117 - val_accuracy: 0.4833\n",
            "epochs : 777\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.8214 - val_loss: 2.0299 - val_accuracy: 0.4733\n",
            "epochs : 778\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.8229 - val_loss: 2.0323 - val_accuracy: 0.4767\n",
            "epochs : 779\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.8200 - val_loss: 2.0086 - val_accuracy: 0.4800\n",
            "epochs : 780\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.8271 - val_loss: 2.0217 - val_accuracy: 0.4800\n",
            "epochs : 781\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8214 - val_loss: 2.0120 - val_accuracy: 0.4800\n",
            "epochs : 782\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.8200 - val_loss: 2.0144 - val_accuracy: 0.4800\n",
            "epochs : 783\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.8229 - val_loss: 2.0352 - val_accuracy: 0.4733\n",
            "epochs : 784\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.8243 - val_loss: 2.0164 - val_accuracy: 0.4733\n",
            "epochs : 785\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.8243 - val_loss: 2.0240 - val_accuracy: 0.4667\n",
            "epochs : 786\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.8257 - val_loss: 2.0416 - val_accuracy: 0.4767\n",
            "epochs : 787\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.8214 - val_loss: 2.0438 - val_accuracy: 0.4800\n",
            "epochs : 788\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.8257 - val_loss: 2.0470 - val_accuracy: 0.4767\n",
            "epochs : 789\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.8271 - val_loss: 2.0496 - val_accuracy: 0.4767\n",
            "epochs : 790\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.2772 - accuracy: 0.9000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0056s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8186 - val_loss: 2.0363 - val_accuracy: 0.4733\n",
            "epochs : 791\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.8243 - val_loss: 2.0391 - val_accuracy: 0.4733\n",
            "epochs : 792\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.8243 - val_loss: 2.0316 - val_accuracy: 0.4800\n",
            "epochs : 793\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.8271 - val_loss: 2.0414 - val_accuracy: 0.4733\n",
            "epochs : 794\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.8257 - val_loss: 2.0569 - val_accuracy: 0.4767\n",
            "epochs : 795\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.8243 - val_loss: 2.0484 - val_accuracy: 0.4733\n",
            "epochs : 796\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.8257 - val_loss: 2.0480 - val_accuracy: 0.4667\n",
            "epochs : 797\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.8271 - val_loss: 2.0545 - val_accuracy: 0.4767\n",
            "epochs : 798\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.8271 - val_loss: 2.0534 - val_accuracy: 0.4767\n",
            "epochs : 799\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.8243 - val_loss: 2.0534 - val_accuracy: 0.4733\n",
            "epochs : 800\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.8257 - val_loss: 2.0564 - val_accuracy: 0.4733\n",
            "epochs : 801\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.8286 - val_loss: 2.0473 - val_accuracy: 0.4700\n",
            "epochs : 802\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.8271 - val_loss: 2.0692 - val_accuracy: 0.4767\n",
            "epochs : 803\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.8300 - val_loss: 2.0658 - val_accuracy: 0.4733\n",
            "epochs : 804\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.8214 - val_loss: 2.0615 - val_accuracy: 0.4733\n",
            "epochs : 805\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.8271 - val_loss: 2.0459 - val_accuracy: 0.4767\n",
            "epochs : 806\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.8257 - val_loss: 2.0719 - val_accuracy: 0.4767\n",
            "epochs : 807\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.8229 - val_loss: 2.0597 - val_accuracy: 0.4700\n",
            "epochs : 808\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.8243 - val_loss: 2.0600 - val_accuracy: 0.4733\n",
            "epochs : 809\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.8243 - val_loss: 2.0762 - val_accuracy: 0.4700\n",
            "epochs : 810\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.8257 - val_loss: 2.0681 - val_accuracy: 0.4767\n",
            "epochs : 811\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.8257 - val_loss: 2.0889 - val_accuracy: 0.4767\n",
            "epochs : 812\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.8300 - val_loss: 2.0788 - val_accuracy: 0.4767\n",
            "epochs : 813\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.8271 - val_loss: 2.0731 - val_accuracy: 0.4700\n",
            "epochs : 814\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.8257 - val_loss: 2.0863 - val_accuracy: 0.4733\n",
            "epochs : 815\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.8257 - val_loss: 2.0761 - val_accuracy: 0.4700\n",
            "epochs : 816\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.8257 - val_loss: 2.0925 - val_accuracy: 0.4733\n",
            "epochs : 817\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.8271 - val_loss: 2.0847 - val_accuracy: 0.4733\n",
            "epochs : 818\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.8271 - val_loss: 2.0791 - val_accuracy: 0.4767\n",
            "epochs : 819\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.8286 - val_loss: 2.1009 - val_accuracy: 0.4767\n",
            "epochs : 820\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.8243 - val_loss: 2.0893 - val_accuracy: 0.4733\n",
            "epochs : 821\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.8271 - val_loss: 2.0782 - val_accuracy: 0.4800\n",
            "epochs : 822\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.8271 - val_loss: 2.0894 - val_accuracy: 0.4667\n",
            "epochs : 823\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.8229 - val_loss: 2.1021 - val_accuracy: 0.4733\n",
            "epochs : 824\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.8314 - val_loss: 2.0946 - val_accuracy: 0.4800\n",
            "epochs : 825\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8271 - val_loss: 2.1072 - val_accuracy: 0.4700\n",
            "epochs : 826\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.8286 - val_loss: 2.0999 - val_accuracy: 0.4800\n",
            "epochs : 827\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.8329 - val_loss: 2.1047 - val_accuracy: 0.4733\n",
            "epochs : 828\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8343 - val_loss: 2.0936 - val_accuracy: 0.4733\n",
            "epochs : 829\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.8286 - val_loss: 2.0913 - val_accuracy: 0.4733\n",
            "epochs : 830\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8271 - val_loss: 2.0949 - val_accuracy: 0.4767\n",
            "epochs : 831\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8300 - val_loss: 2.0855 - val_accuracy: 0.4667\n",
            "epochs : 832\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.8286 - val_loss: 2.1080 - val_accuracy: 0.4800\n",
            "epochs : 833\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.8300 - val_loss: 2.0953 - val_accuracy: 0.4733\n",
            "epochs : 834\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.8343 - val_loss: 2.1120 - val_accuracy: 0.4800\n",
            "epochs : 835\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.8357 - val_loss: 2.1224 - val_accuracy: 0.4733\n",
            "epochs : 836\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.8357 - val_loss: 2.1014 - val_accuracy: 0.4733\n",
            "epochs : 837\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.8286 - val_loss: 2.1215 - val_accuracy: 0.4800\n",
            "epochs : 838\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.8286 - val_loss: 2.0980 - val_accuracy: 0.4733\n",
            "epochs : 839\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.8229 - val_loss: 2.1070 - val_accuracy: 0.4733\n",
            "epochs : 840\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.8357 - val_loss: 2.1269 - val_accuracy: 0.4767\n",
            "epochs : 841\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.8300 - val_loss: 2.1124 - val_accuracy: 0.4733\n",
            "epochs : 842\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.8271 - val_loss: 2.1245 - val_accuracy: 0.4700\n",
            "epochs : 843\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8329 - val_loss: 2.1235 - val_accuracy: 0.4700\n",
            "epochs : 844\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.8300 - val_loss: 2.1170 - val_accuracy: 0.4733\n",
            "epochs : 845\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.8343 - val_loss: 2.1331 - val_accuracy: 0.4800\n",
            "epochs : 846\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.8314 - val_loss: 2.1313 - val_accuracy: 0.4767\n",
            "epochs : 847\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.8314 - val_loss: 2.1203 - val_accuracy: 0.4733\n",
            "epochs : 848\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.8357 - val_loss: 2.1276 - val_accuracy: 0.4733\n",
            "epochs : 849\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.8343 - val_loss: 2.1226 - val_accuracy: 0.4733\n",
            "epochs : 850\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8300 - val_loss: 2.1180 - val_accuracy: 0.4800\n",
            "epochs : 851\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.8314 - val_loss: 2.1365 - val_accuracy: 0.4733\n",
            "epochs : 852\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.8286 - val_loss: 2.1278 - val_accuracy: 0.4767\n",
            "epochs : 853\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.8343 - val_loss: 2.1386 - val_accuracy: 0.4733\n",
            "epochs : 854\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.8343 - val_loss: 2.1318 - val_accuracy: 0.4700\n",
            "epochs : 855\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8286 - val_loss: 2.1390 - val_accuracy: 0.4700\n",
            "epochs : 856\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.8343 - val_loss: 2.1534 - val_accuracy: 0.4800\n",
            "epochs : 857\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.5157 - accuracy: 0.8309WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.8286 - val_loss: 2.1408 - val_accuracy: 0.4800\n",
            "epochs : 858\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.8343 - val_loss: 2.1343 - val_accuracy: 0.4700\n",
            "epochs : 859\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.8343 - val_loss: 2.1543 - val_accuracy: 0.4733\n",
            "epochs : 860\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.5118 - accuracy: 0.8364WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_test_batch_end` time: 0.0024s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.8371 - val_loss: 2.1477 - val_accuracy: 0.4767\n",
            "epochs : 861\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.8386 - val_loss: 2.1333 - val_accuracy: 0.4667\n",
            "epochs : 862\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.8357 - val_loss: 2.1600 - val_accuracy: 0.4733\n",
            "epochs : 863\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.8343 - val_loss: 2.1479 - val_accuracy: 0.4733\n",
            "epochs : 864\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.8314 - val_loss: 2.1355 - val_accuracy: 0.4733\n",
            "epochs : 865\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.8329 - val_loss: 2.1478 - val_accuracy: 0.4700\n",
            "epochs : 866\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.8386 - val_loss: 2.1608 - val_accuracy: 0.4733\n",
            "epochs : 867\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.8343 - val_loss: 2.1352 - val_accuracy: 0.4700\n",
            "epochs : 868\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.8329 - val_loss: 2.1336 - val_accuracy: 0.4767\n",
            "epochs : 869\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.8343 - val_loss: 2.1700 - val_accuracy: 0.4733\n",
            "epochs : 870\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.8400 - val_loss: 2.1559 - val_accuracy: 0.4700\n",
            "epochs : 871\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.8343 - val_loss: 2.1670 - val_accuracy: 0.4700\n",
            "epochs : 872\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.3532 - accuracy: 0.9000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.8343 - val_loss: 2.1493 - val_accuracy: 0.4767\n",
            "epochs : 873\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.8343 - val_loss: 2.1620 - val_accuracy: 0.4700\n",
            "epochs : 874\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8386 - val_loss: 2.1592 - val_accuracy: 0.4700\n",
            "epochs : 875\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.8343 - val_loss: 2.1590 - val_accuracy: 0.4700\n",
            "epochs : 876\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.8371 - val_loss: 2.1652 - val_accuracy: 0.4733\n",
            "epochs : 877\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.8343 - val_loss: 2.1427 - val_accuracy: 0.4733\n",
            "epochs : 878\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.3978 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.8329 - val_loss: 2.1743 - val_accuracy: 0.4700\n",
            "epochs : 879\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.8357 - val_loss: 2.1660 - val_accuracy: 0.4800\n",
            "epochs : 880\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.8386 - val_loss: 2.1718 - val_accuracy: 0.4733\n",
            "epochs : 881\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.8343 - val_loss: 2.1657 - val_accuracy: 0.4800\n",
            "epochs : 882\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.8414 - val_loss: 2.1822 - val_accuracy: 0.4733\n",
            "epochs : 883\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.8357 - val_loss: 2.1687 - val_accuracy: 0.4800\n",
            "epochs : 884\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.8357 - val_loss: 2.1722 - val_accuracy: 0.4733\n",
            "epochs : 885\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8343 - val_loss: 2.1885 - val_accuracy: 0.4700\n",
            "epochs : 886\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8357 - val_loss: 2.1618 - val_accuracy: 0.4700\n",
            "epochs : 887\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8357 - val_loss: 2.1875 - val_accuracy: 0.4733\n",
            "epochs : 888\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8429 - val_loss: 2.1613 - val_accuracy: 0.4733\n",
            "epochs : 889\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8371 - val_loss: 2.1618 - val_accuracy: 0.4733\n",
            "epochs : 890\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.8386 - val_loss: 2.1841 - val_accuracy: 0.4733\n",
            "epochs : 891\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.8357 - val_loss: 2.1751 - val_accuracy: 0.4767\n",
            "epochs : 892\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.8386 - val_loss: 2.1918 - val_accuracy: 0.4767\n",
            "epochs : 893\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.8343 - val_loss: 2.1680 - val_accuracy: 0.4700\n",
            "epochs : 894\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8414 - val_loss: 2.1844 - val_accuracy: 0.4733\n",
            "epochs : 895\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8429 - val_loss: 2.1992 - val_accuracy: 0.4733\n",
            "epochs : 896\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.8400 - val_loss: 2.1825 - val_accuracy: 0.4767\n",
            "epochs : 897\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.8414 - val_loss: 2.1869 - val_accuracy: 0.4700\n",
            "epochs : 898\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.8400 - val_loss: 2.1884 - val_accuracy: 0.4733\n",
            "epochs : 899\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.8343 - val_loss: 2.1853 - val_accuracy: 0.4733\n",
            "epochs : 900\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8443 - val_loss: 2.2035 - val_accuracy: 0.4633\n",
            "epochs : 901\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8400 - val_loss: 2.2076 - val_accuracy: 0.4733\n",
            "epochs : 902\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.8400 - val_loss: 2.1993 - val_accuracy: 0.4667\n",
            "epochs : 903\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.8386 - val_loss: 2.1906 - val_accuracy: 0.4767\n",
            "epochs : 904\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.8414 - val_loss: 2.2058 - val_accuracy: 0.4767\n",
            "epochs : 905\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8414 - val_loss: 2.1784 - val_accuracy: 0.4767\n",
            "epochs : 906\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8400 - val_loss: 2.2149 - val_accuracy: 0.4700\n",
            "epochs : 907\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8343 - val_loss: 2.1793 - val_accuracy: 0.4733\n",
            "epochs : 908\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8400 - val_loss: 2.1864 - val_accuracy: 0.4733\n",
            "epochs : 909\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.8371 - val_loss: 2.2139 - val_accuracy: 0.4667\n",
            "epochs : 910\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.8371 - val_loss: 2.1961 - val_accuracy: 0.4767\n",
            "epochs : 911\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.8400 - val_loss: 2.1967 - val_accuracy: 0.4767\n",
            "epochs : 912\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.8443 - val_loss: 2.1999 - val_accuracy: 0.4767\n",
            "epochs : 913\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8386 - val_loss: 2.2036 - val_accuracy: 0.4733\n",
            "epochs : 914\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8414 - val_loss: 2.2234 - val_accuracy: 0.4667\n",
            "epochs : 915\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8371 - val_loss: 2.1987 - val_accuracy: 0.4733\n",
            "epochs : 916\n",
            " 1/70 [..............................] - ETA: 0s - loss: 0.4110 - accuracy: 0.8000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0067s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8429 - val_loss: 2.2174 - val_accuracy: 0.4733\n",
            "epochs : 917\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8400 - val_loss: 2.2042 - val_accuracy: 0.4800\n",
            "epochs : 918\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.8386 - val_loss: 2.2064 - val_accuracy: 0.4767\n",
            "epochs : 919\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8400 - val_loss: 2.2256 - val_accuracy: 0.4767\n",
            "epochs : 920\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8429 - val_loss: 2.2054 - val_accuracy: 0.4800\n",
            "epochs : 921\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8429 - val_loss: 2.2195 - val_accuracy: 0.4733\n",
            "epochs : 922\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.8400 - val_loss: 2.2116 - val_accuracy: 0.4767\n",
            "epochs : 923\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.8443 - val_loss: 2.2260 - val_accuracy: 0.4667\n",
            "epochs : 924\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8400 - val_loss: 2.2121 - val_accuracy: 0.4767\n",
            "epochs : 925\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.8400 - val_loss: 2.2210 - val_accuracy: 0.4733\n",
            "epochs : 926\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8371 - val_loss: 2.2300 - val_accuracy: 0.4767\n",
            "epochs : 927\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8443 - val_loss: 2.2225 - val_accuracy: 0.4667\n",
            "epochs : 928\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8414 - val_loss: 2.2295 - val_accuracy: 0.4700\n",
            "epochs : 929\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8386 - val_loss: 2.2274 - val_accuracy: 0.4733\n",
            "epochs : 930\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8386 - val_loss: 2.2213 - val_accuracy: 0.4767\n",
            "epochs : 931\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8429 - val_loss: 2.2451 - val_accuracy: 0.4733\n",
            "epochs : 932\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.8400 - val_loss: 2.2356 - val_accuracy: 0.4633\n",
            "epochs : 933\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.8514 - val_loss: 2.2297 - val_accuracy: 0.4767\n",
            "epochs : 934\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8443 - val_loss: 2.2393 - val_accuracy: 0.4767\n",
            "epochs : 935\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8400 - val_loss: 2.2643 - val_accuracy: 0.4733\n",
            "epochs : 936\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8386 - val_loss: 2.2408 - val_accuracy: 0.4733\n",
            "epochs : 937\n",
            "48/70 [===================>..........] - ETA: 0s - loss: 0.5114 - accuracy: 0.8375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_test_batch_end` time: 0.0043s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.8386 - val_loss: 2.2542 - val_accuracy: 0.4700\n",
            "epochs : 938\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.8443 - val_loss: 2.2518 - val_accuracy: 0.4767\n",
            "epochs : 939\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8429 - val_loss: 2.2259 - val_accuracy: 0.4733\n",
            "epochs : 940\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8414 - val_loss: 2.2502 - val_accuracy: 0.4700\n",
            "epochs : 941\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.8400 - val_loss: 2.2448 - val_accuracy: 0.4767\n",
            "epochs : 942\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8429 - val_loss: 2.2561 - val_accuracy: 0.4700\n",
            "epochs : 943\n",
            "54/70 [======================>.......] - ETA: 0s - loss: 0.4787 - accuracy: 0.8537WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0015s). Check your callbacks.\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.8443 - val_loss: 2.2168 - val_accuracy: 0.4767\n",
            "epochs : 944\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8457 - val_loss: 2.2381 - val_accuracy: 0.4767\n",
            "epochs : 945\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.8414 - val_loss: 2.2431 - val_accuracy: 0.4767\n",
            "epochs : 946\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8429 - val_loss: 2.2629 - val_accuracy: 0.4700\n",
            "epochs : 947\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.8500 - val_loss: 2.2619 - val_accuracy: 0.4733\n",
            "epochs : 948\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8400 - val_loss: 2.2594 - val_accuracy: 0.4733\n",
            "epochs : 949\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8429 - val_loss: 2.2479 - val_accuracy: 0.4733\n",
            "epochs : 950\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8400 - val_loss: 2.2757 - val_accuracy: 0.4700\n",
            "epochs : 951\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8400 - val_loss: 2.2364 - val_accuracy: 0.4767\n",
            "epochs : 952\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8429 - val_loss: 2.2689 - val_accuracy: 0.4733\n",
            "epochs : 953\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8429 - val_loss: 2.2779 - val_accuracy: 0.4800\n",
            "epochs : 954\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.8414 - val_loss: 2.2715 - val_accuracy: 0.4767\n",
            "epochs : 955\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8400 - val_loss: 2.2771 - val_accuracy: 0.4767\n",
            "epochs : 956\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8414 - val_loss: 2.2632 - val_accuracy: 0.4733\n",
            "epochs : 957\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8471 - val_loss: 2.2774 - val_accuracy: 0.4767\n",
            "epochs : 958\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8443 - val_loss: 2.2697 - val_accuracy: 0.4767\n",
            "epochs : 959\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8457 - val_loss: 2.2740 - val_accuracy: 0.4700\n",
            "epochs : 960\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.8429 - val_loss: 2.2801 - val_accuracy: 0.4600\n",
            "epochs : 961\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8429 - val_loss: 2.2791 - val_accuracy: 0.4733\n",
            "epochs : 962\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8443 - val_loss: 2.2635 - val_accuracy: 0.4733\n",
            "epochs : 963\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8471 - val_loss: 2.2772 - val_accuracy: 0.4800\n",
            "epochs : 964\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8457 - val_loss: 2.2792 - val_accuracy: 0.4767\n",
            "epochs : 965\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.8429 - val_loss: 2.2512 - val_accuracy: 0.4733\n",
            "epochs : 966\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8471 - val_loss: 2.2829 - val_accuracy: 0.4767\n",
            "epochs : 967\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8443 - val_loss: 2.2768 - val_accuracy: 0.4767\n",
            "epochs : 968\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8443 - val_loss: 2.2925 - val_accuracy: 0.4767\n",
            "epochs : 969\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8471 - val_loss: 2.2854 - val_accuracy: 0.4767\n",
            "epochs : 970\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.8457 - val_loss: 2.2841 - val_accuracy: 0.4700\n",
            "epochs : 971\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8443 - val_loss: 2.2898 - val_accuracy: 0.4767\n",
            "epochs : 972\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8471 - val_loss: 2.2803 - val_accuracy: 0.4733\n",
            "epochs : 973\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8471 - val_loss: 2.2975 - val_accuracy: 0.4767\n",
            "epochs : 974\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8514 - val_loss: 2.3156 - val_accuracy: 0.4800\n",
            "epochs : 975\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8443 - val_loss: 2.2719 - val_accuracy: 0.4767\n",
            "epochs : 976\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8514 - val_loss: 2.2829 - val_accuracy: 0.4700\n",
            "epochs : 977\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8443 - val_loss: 2.2931 - val_accuracy: 0.4667\n",
            "epochs : 978\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8471 - val_loss: 2.3031 - val_accuracy: 0.4667\n",
            "epochs : 979\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8429 - val_loss: 2.2829 - val_accuracy: 0.4700\n",
            "epochs : 980\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8429 - val_loss: 2.2995 - val_accuracy: 0.4767\n",
            "epochs : 981\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8457 - val_loss: 2.2841 - val_accuracy: 0.4733\n",
            "epochs : 982\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8471 - val_loss: 2.2855 - val_accuracy: 0.4800\n",
            "epochs : 983\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8400 - val_loss: 2.2768 - val_accuracy: 0.4700\n",
            "epochs : 984\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8471 - val_loss: 2.2701 - val_accuracy: 0.4733\n",
            "epochs : 985\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8486 - val_loss: 2.2943 - val_accuracy: 0.4767\n",
            "epochs : 986\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8457 - val_loss: 2.2993 - val_accuracy: 0.4767\n",
            "epochs : 987\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8486 - val_loss: 2.2975 - val_accuracy: 0.4733\n",
            "epochs : 988\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8471 - val_loss: 2.2992 - val_accuracy: 0.4767\n",
            "epochs : 989\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8471 - val_loss: 2.3011 - val_accuracy: 0.4800\n",
            "epochs : 990\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8457 - val_loss: 2.3068 - val_accuracy: 0.4733\n",
            "epochs : 991\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8429 - val_loss: 2.2965 - val_accuracy: 0.4733\n",
            "epochs : 992\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8500 - val_loss: 2.3116 - val_accuracy: 0.4767\n",
            "epochs : 993\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8457 - val_loss: 2.3101 - val_accuracy: 0.4733\n",
            "epochs : 994\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8471 - val_loss: 2.3106 - val_accuracy: 0.4733\n",
            "epochs : 995\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8471 - val_loss: 2.3156 - val_accuracy: 0.4733\n",
            "epochs : 996\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8457 - val_loss: 2.2987 - val_accuracy: 0.4700\n",
            "epochs : 997\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8529 - val_loss: 2.3318 - val_accuracy: 0.4767\n",
            "epochs : 998\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8471 - val_loss: 2.3124 - val_accuracy: 0.4733\n",
            "epochs : 999\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8471 - val_loss: 2.3062 - val_accuracy: 0.4767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr1xTPq0bkN1",
        "colab_type": "text"
      },
      "source": [
        "![png](http://tykimos.github.io/warehouse/2017-7-9-Training_Monitoring_output_19_1.png)\n",
        "\n",
        "학습 모니터링 결과는 첫번째 예제와 유사하게 나옵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUSZ9K44bkN2",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### Q & A\n",
        "\n",
        "Q1) 그래프가 어떻게 나와야 정상이죠?\n",
        "\n",
        "A1) 데이터셋마다 모델마다 나오는 그래프가 다양합니다. 일반적으로는 에포크가 반복될수록 훈련 손실값을 계속 감소하고, 훈련 정확도는 계속 높아집니다. 훈련 정확도가 높을수록 과적합이 될 수 있기 때문에 반드시 모델이 좋다고는 얘기못하지만 반대로 에포크가 반복될수록 과적합이 일어나지 않는다면 훈련셋이나 모델 설계에 문제가 있을 수 있습니다. 즉 알고 있는 정답에 대해서도 제대로 학습이 안된다면, 훈련셋에 같은 입력인데도 다른 라벨값을 가지고 있다던지, 모델의 층이 낮거나 뉴런 수가 적어서 피팅이 제대로 안된다던지 등을 살펴봐야 합니다.\n",
        "\n",
        "Q2) 과적합 된 이후에 검증셋의 정확도는 변화가 없는 것 같은데, 검증셋의 손실값은 왜 계속해서 증가되나요?\n",
        "\n",
        "A2) 정확도 계산은 모델의 결과와 주어진 검증셋의 라벨값과 비교해서 계산됩니다. 이진분류로 예를 들어, 10개 샘플 중 10개 모두 맞으면 100%, 5개 맞으면 50%입니다. 모델은 에포크가 수행될 때마다 더욱더 훈련셋에 과적합되기 때문에 틀린 건 계속 틀리다고 얘기하고, 맞은 건 계속 맞다고 얘기합니다. 하지만 손실값인 경우에는 손실을 정의하는 함수에 따라 에러율이 계산되기 때문에 과적합되기 직전이 극소값이고 그 외에는 모두 증가합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrBTg0NibkN2",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### 요약\n",
        "\n",
        "딥러닝 모델 학습과정을 살펴보는 방법에 대해서 알아보았습니다. 간단하게는 케라스의 fit() 함수에서 반환하는 히스토리 객체를 이용하는 방법이 있고, 텐서보드라는 훌륭한 가시화 툴을 이용해서 보는 방법도 알아보았습니다. 또한 순환신경망 모델과 같이 기본적으로 제공하는 기능으로 모니터링이 안되는 경우 콜백함수를 직접 정의해서 사용하는 방법에 대해서도 알아보았습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "mWBTxxiFbkN4",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### 같이 보기\n",
        "\n",
        "* [강좌 목차](https://tykimos.github.io/lecture/)\n",
        "* 이전 : [학습과정 이야기](https://tykimos.github.io/2017/03/25/Fit_Talk/)\n",
        "* 다음 : [학습 조기종료 시키기](https://tykimos.github.io/2017/07/09/Early_Stopping/)"
      ]
    }
  ]
}